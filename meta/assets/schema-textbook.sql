SET SQL_MODE="NO_AUTO_VALUE_ON_ZERO";
--
-- Database: `schema_textbook`
--

-- --------------------------------------------------------

--
-- Table structure for table `bodymatter`
--

CREATE TABLE IF NOT EXISTS `bodymatter` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) DEFAULT NULL,
  `creator` varchar(255) DEFAULT NULL,
  `url` varchar(255) DEFAULT NULL,
  `description` text,
  `about` text,
  `image` varchar(140) DEFAULT NULL,
  `text` text,
  `mentions` text COMMENT 'footnote',
  `isPartOf` text COMMENT 'chapter -> section',
  `position` text COMMENT 'number for sort position',
  `articleSection` text COMMENT 'http://schema.org/Article',
  `publicationType` varchar(255) NOT NULL COMMENT 'http://schema.org/MedicalScholarlyArticle',
  `additionalType` varchar(255) DEFAULT NULL,
  `additionalType2` varchar(255) DEFAULT NULL,
  `isbn` varchar(40) DEFAULT NULL,
  `genre` varchar(140) DEFAULT NULL,
  `keywords` varchar(255) DEFAULT NULL,
  `publisher` varchar(255) DEFAULT NULL,
  `dateCreated` varchar(255) DEFAULT NULL,
  `dateModified` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `datePublished` varchar(255) DEFAULT NULL,
  `version` varchar(140) DEFAULT NULL,
  `learningResourceType` varchar(140) DEFAULT NULL,
  `inLanguage` varchar(5) DEFAULT NULL,
  PRIMARY KEY (`id`),
  FULLTEXT KEY `search` (`name`,`creator`,`description`,`genre`,`keywords`,`dateCreated`)
) ENGINE=MyISAM  DEFAULT CHARSET=utf8 AUTO_INCREMENT=64 ;

--
-- Dumping data for table `bodymatter`
--

INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(1, 'Acknowledgements', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>We would like to thank all the students and instructors who have provided input in the development of STAT 217 and how we try to teach these topics. Dr. Jim Robison-Cox initially developed this course using R and much of this work retains his ideas. Many years of teaching these topics and helping researchers use these topics has helped to refine their presentation. Observing students years after the course has also helped to refine what we try to teach in the course, trying to prepare these students for the next levels of statistics courses that they might encounter.</p>\r\n<p>I (Greenwood) have intentionally taken a first person perspective at times to be able to include stories from some of those interactions to try to help you avoid some of their pitfalls in your current or future usage of statistics. I would like to thank my wife, Teresa, for allowing me the time to complete the first version and then update the book. I would also like to acknowledge Dr. Gordon Bril (Luther College) who introduced me to statistics while I was an undergraduate and Dr. Snehalata Huzurbazar (University of Wyoming) that guided me to completing my Master''s and Ph.D. in Statistics.</p>\r\n<p>The development of STAT 217 was initially supported with funding from Montana State University''s Instructional Innovation Grant Program with a grant titled <em>Towards more active learning in STAT 217</em>. That project was designed to create a set of daily activities and collect some of the instructional knowledge that is lost every time one of the graduate teaching assistants moves on. We initially planned to just adopt some other author''s text written for a second semester course, but couldn''t find one that was suitable and under $150. So we wrote this book.</p> \r\n<p>This is Version 2.0 of the book, prepared for Spring 2015, which involves some moderate changes in the content and writing, updates to R code, and some added "exercises" at the end of each chapter to allow students to practice what is being discussed.</p>\r\n<p>Banner would have more to note in the acknowledgments in this version if she weren''t working hard on completing her doctoral degree.</p>\r\n<p>We have made every attempt to keep costs as low as possible by printing the text in black and white as much as possible. The text (in full color and with working links) is also available as a free digital download from Montana State University''s ScholarWorks repository at <a href="https://scholarworks.montana.edu/xmlui/handle/1/2999">https://scholarworks.montana.edu/xmlui/handle/1/2999</a>.</p>\r\n\r\n<p>Enjoy your journey from introductory to intermediate statistics!</p>\r\n\r\n</br> \r\n<p>This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/ or send a letter to Creative Commons, 444 Castro Street, Suite 900, Mountain View, California, 94041, USA.</p>\r\n', NULL, 'Front matter', '0.000', NULL, 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:54:45', 'Spring 2015', '2.0', NULL, NULL),
(3, 'Overview of methods', 'Mark Greenwood and Katharine Banner', NULL, NULL, '', NULL, '<p>After an introduction to statistics, a wide array of statistical methods become available. This course re-iterates a variety of themes from the first semester course including the basics of statistical inference and statistical thinking - and it assumes you remember the general framework of ideas from that previous experience. The methods explored focus on assessing (estimating and testing for) relationships between variables - which is where statistics gets really interesting and useful. Early statistical analyses (approximately 100 years ago) were focused on describing a single variable. Your introductory statistics course should have heavily explored methods for summarizing and doing inference in situations with one or two groups of observations. Now, we get to consider more complicated situations - culminating in a set of tools for working with situations with multiple explanatory variables, some of which might be categorical. Throughout the methods, it will be important to retain a focus on how the appropriate statistical analysis depends on the research question and data collection process as well as the types of variables measured. </p>\r\n<figure>\r\n<img src="../meta/img/Figure0.1.jpg" alt="Figure0.1">\r\n<figcaption><em>Figure 0-1: Flow chart of methods.</em></figcaption>\r\n</figure>\r\n<p>Figure 0-1 frames the topics we will discuss. Taking a broad vision of the methods we will consider, there are basically two scenarios - one when the response is quantitative (meaningful numerical quantity for each case) and one when the response is categorical (divides the cases into groups, placing each case into one and only one category. Examples of quantitative responses we will see later involve <em>suggested jail sentence </em>(in years) and <em>body fat </em>(percentage. Examples of categorical variables include <em>improvement </em>(none, some, or marked) in a clinical trial or whether a student has turned in copied work (never, exam or paper, or both. There are going to be some more nuanced aspects to all of these analyses as the complexity of two trees suggest, but note that near the bottom, each tree converges on a single procedure, using a <strong><em>linear model </strong></em> for quantitative response variables and a <strong><em>Chi-square test </strong></em> for a categorical response. After selecting the appropriate procedure and completing the necessary technical steps to get results for a given data set, the final step involves assessing the scope of inference and types of conclusions that are appropriate based on the design of the study.</p>\r\n<p>The number of analysis techniques is directly proportional to our focus in this class, and we will be spending most of the semester working on methods for quantitative response variables (the left side of Figure 0-1 covered in Chapters 1, 2, 3, 5, 6, and 7) and stepping over to handle the situation with a categorical response variable (right side of Figure 0-1 discussed in Chapter 4). The final chapter contains case studies illustrating all of the methods discussed previously, providing an opportunity to see how finding your way through the paths in Figure 0-1 leads to the appropriate analysis.</p>\r\n<p>The first topics (Chapters 0 and 1) will be more familiar as we start with single and two group situations with a quantitative response. In your previous statistics course, you should have seen methods for estimating and quantifying uncertainty for differences in two groups. Once we have briefly reviewed these methods and introduced the statistical software that we will use throughout the course, we will consider the first truly new material in Chapter 2. It involves the situation where there are more than 2 groups to compare with a quantitative response - this is what we call the <strong><em>One-Way ANOVA </strong></em>situation. It generalizes the 2 independent sample test to handle situations where more than 2 groups are being studied. When we learn this method, we will begin discussing model assumptions and methods for assessing those assumptions that will be present in every analysis involving a quantitative response. The <strong><em>Two-Way ANOVA </strong></em>(Chapter 3) considers situations with two categorical explanatory variables and a quantitative response. To make this somewhat concrete, suppose we are interested in assessing differences in <em>biomass</em> based on the amount of <em>fertilizer</em> applied (none, low, or high) and <em>species</em> of plant (two types). Here, <em>biomass</em> is a quantitative response variable and there are two categorical explanatory variables, <em>fertilizer</em>, with 3 levels, and <em>species</em>, with two levels. In this material, we introduce the idea of an <strong><em>interaction </strong></em>between the two explanatory variables: the relationship between one categorical variable and the mean of the response changes depending on the levels of the other categorical variable. For example, extra fertilizer might enhance the growth of one species and hinder the growth of another so fertilizer has different impacts based on the level of species. Given that this interaction may or may not be present, we will consider two versions of the model in Two-Way ANOVAs, what are called the <strong><em>additive</strong></em> (no interaction) and the <strong><em>interaction </strong></em>models.</p>\r\n<p>Following the methods for two categorical variables and a quantitative response, we explore a method for analyzing data where the response is categorical, called the <strong><em>Chi-square test</strong></em> in Chapter 4. This most closely matches the One-Way ANOVA situation with a single categorical explanatory variable, except now the response variable is categorical. For example, we will assess whether taking a drug (vs taking a <em>placebo</em><sup><a id="1top" href="#1ft">1</a></sup>) has an <em>effect<sup><a id="2top" href="#2ft">2</a></sup></em> on the type of improvement the subjects demonstrate. There are two different scenarios for study design that impact the analysis technique and hypotheses tested in Chapter 4. If the explanatory variable reflects the group that subjects were obtained from, either through randomization of the treatment level to the subjects or by taking samples from separate populations, this is called a <strong><em>Chi-square Homogeneity test</strong></em>. It is also possible to analyze data using the same Chi-square test that was generated by taking a single sample from a population and then obtaining information on the levels of the explanatory variable for each subject. We will analyze these results using what is called a <strong><em>Chi-square Independence test</strong></em>.</p> \r\n<p>If the predictor and response variables are both quantitative, we start with correlation and <strong><em>simple linear regression</strong></em> models (Chapters 5 and 6) - things you should have seen, at least to some degree, previously. If there is more than one quantitative explanatory variable, then we say that we are <strong><em>doing multiple linear regression</strong></em> (Chapter 7) - the "multiple" part of the name reflects that there will be more than one explanatory variable. If the situation suggests the use of a mix of categorical and quantitative predictor variables, then we also call the models multiple linear regression models. In the situation with one categorical predictor and one quantitative predictor, we revisit the idea of an interaction. It allows us to consider situations where the estimated relationship between a quantitative predictor and the mean response varies among different levels of the categorical variable.</p>\r\n<p>At the end of the course, you should be able to identify, perform using the statistical software R (R Core Team, 2014), and interpret the results from each of these methods. There is a lot to learn, but many of the tools for using R and interpreting results of the analyses accumulate during the semester. If you work hard to understand the initial methods, it will help you when the methods get much more complicated. All of the methods you will learn require you to carefully consider how the data were collected, how that pertains to the population of interest, and how that impacts inferences that can be made. The <strong><em>scope of inference</strong></em> is our shorthand term for remembering to think about two aspects of the study - <strong><em>random assignment </strong></em>and <strong><em>random sampling</strong></em>. One aspect of this assessment is to decide if the explanatory variable was randomly assigned to study units (allowing for <strong><em>causal inferences </strong></em> if differences are detected) or not (so no causal statements are possible). The other aspect concerns random sampling: If the data were obtained using a random sampling mechanism, then our inferences can be safely extended to the population that the sample was taken from. However, if we have random sample, our inference can only apply to the sample collected. You will often think you are done with your analysis when you get some numbers from R, but need to remember to think about the potential conclusions you can make based on the source of the data set you are analyzing. By the end of this course, you should have some basic R skills and abilities to create basic ANOVA and Regression models, as well as Chi-squared testing situations. Together, this should prepare you for future STAT courses or for other situations where you are expected to be able to do the calculations and effectively communicate interpretations for the methods discussed in this course.</p>', '  <p><sup><a id="1ft" href="#1top">1</a></sup>A placebo is a treatment level designed to mimic the potentially efficacious level(s) but that can have no actual effect. The placebo effect is the effect that thinking that an effective treatment was received has on subjects.</p>\r\n  <p><sup><a id="2ft" href="#2top">2</a></sup>We will reserve the term "effect" for situations where we could potentially infer causal impacts on the response of the explanatory variable which occurs in situations where the levels of the explanatory variable are randomly assigned to the subjects.</p>', 'Preface', '0.001', '0.0', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:55:04', NULL, NULL, NULL, NULL),
(8, 'Getting started in R', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>This book and access to a computer (PC, Mac, or just computer lab computers on campus) are the only required materials for the course. You will need to download the statistical software package called R and an enhanced interface to R called R-studio (Rstudio, 2014). They are open source and free to download and use (and will always be that way). This means that the skills you learn now can follow you the rest of your life. R is becoming the primary language of statistics and is being adopted across academia, government, and businesses to help manage and learn from the growing volume of data being obtained. Hopefully you will get a sense of some of the power of R this semester.</p>  \r\n<p>The next pages will walk you through the process of getting the software downloaded and provide you with an initial experience using R-studio to do things that should look familiar even though the interface will be a new experience. Do not expect to master R quickly - it takes years (sorry!) even if you know all the statistical methods being used. We will try to keep all of your interactions with R code in a similar coding form and that should help your learning how to use R as we move through various methods. Everyone that learns R starts with copying other people''s code and then making changes for specific applications - so expect to go back to examples and learn how to modify that code to work for your particular data set. In Chapter 1, we will exploit the power of R to compare quantitative responses from two groups, making some graphical displays, doing hypothesis testing and creating confidence intervals in a couple of different ways.</p>\r\n<p>You will have two downloading activities to complete before you can do anything more than read this book. First, you need to download R. It is the engine that will do all the computing for us, but you will only interact with it once. Go to <a href="http://cran.rstudio.com">http://cran.rstudio.com</a> and click on the <strong>"Download R for..." </strong> button that corresponds to your operating system. Second, you need to download R-studio. It is an enhanced interface that will make interacting with R less frustrating. Go to <a href="http://www.rstudio.com/products/rstudio/download/">http://www.rstudio.com/products/rstudio/download/</a> and select the "installer" for your operating system under the column for "Installers for all platforms". From this point forward, you should only open R-studio; it provides your interface with R. Note that both R and R-studio are updated frequently (up to four times a year) and if you downloaded either more than a few months previously, you should download the up-to-date versions, especially if something you are trying to do is not working. Sometimes code will not work in older versions of R and sometimes old code won''t work in new versions of R<sup><a id="3top" href="#3ft">3</a></sup>.</p>\r\n<p>Now we get to complete some basic tasks in R using the R-studio interface. When you open R-studio, you will see a screen like Figure 0-2. The added notes can help you get initially oriented to the software interface. R is command-line software - meaning that most of the time you have to create code and then execute it to get any results. R-studio makes the management and execution of code more efficient than the basic version of R. The lower left panel in R-studio is called the "console" window and is where you can type R code directly into R or where you will see the code you run and (most importantly!) where the results of your executed commands will show up. The most basic interaction with R is available once you get the cursor active at the command prompt ">". The upper left panel is for writing, saving, and running your R code. Once you have code available in this window, the "Run" button will execute the code for the line that your cursor is on or for any text that you have highlighted with your mouse. The "data management" or environment panel is in the upper right, providing information on what data sets have been loaded. It also contains the "Import Dataset" button that makes reading data into R easier. The lower right panel contains information on the "Packages" that are available and is where you will see plots that you make and requests for "Help".</p>\r\n<figure><img src="../meta/img/Figure0.2.jpg" alt="Figure0.2">\r\n<figcaption><em>Figure 0-2: Initial R-studio layout.</em></figcaption>\r\n</figure>\r\n<p>To interact with R, click near the command prompt (>) in the lower left "console" panel, type 3+4 and then hit enter. It should look like this:</p>\r\n<p><span class="code blue">> 3+4</span></p>\r\n<p><span class="code">[1] 7</span></p>\r\n<p>You can do more interesting calculations, like finding the mean of the numbers 3, 5, 7, and 8 by adding them up and dividing by 4:</p>\r\n<p><span class="code blue"> (-3+5+7+8)/4</span></p>\r\n<p><span class="code">[1] 4.25</span></p>\r\n<p>Note that the the parentheses help R to figure out your desired order of operations. If you drop that grouping, you get a very different result:</p>\r\n<p><span class="code blue">> -3+5+7+8/4</span></p>\r\n<p><span class="code"> [1] 11</span></p>\r\n<p>We could estimate the standard deviation similarly using the formula you might remember from introductory statistics, but that will only work in very limited situations. To use the real power of R this semester, we need to work with data sets that store the observations for our subjects in <em>variables</em>. Basically, we need to store observations in named vectors that contain a list of the observations. To create a vector containing the four numbers and assign it to a variable named <em>variable1</em>, we need to create a vector using the function <span class="code-font">c</span> which means combine the items that follow if they are inside parentheses and have commas separating the values:</p>\r\n<p><span class="code blue">> c(-3,5,7,8)</span></p>\r\n<p><span class="code">[1] -3  5  7  8</span></p>\r\n<p>To get this vector stored in a variable called <em>variable1</em> we need to use the assignment operator, "<-"(read as "stored as") that assigns in the information on the right into the variable that you are creating.</p>\r\n<p><span class="code blue">> variable1 <- c(-3,5,7,8)</span></p>\r\n<p>In R, the assignment operator, <-, is created by typing a less than symbol (<) followed by a minus sign (-) <strong>without a space between them</strong>. If you ever want to see what numbers are residing in an object in R, just type its name and hit enter. You can see how that variable contains the same information that was initially generated by c(-3,5,7,8) but is easier to access since we just need the text representing that vector.</p>\r\n<p><span class="code blue">> variable1</span></p> \r\n<p><span class="code">[1] -3  5  7  8</span></p> \r\n<p>You can see how that variable contains the same information that was initially generated by c(-3,5,7,8) but is easier to access since we just need the text representing that vector. Now we can use functions such as mean and sd to find the mean and standard deviation of the observations contained in <span class="code-font">variable1</span>:</p>\r\n<p><span class="code blue">> mean(variable1)</span></p>\r\n<p><span class="code">[1] 4.25</span></p>\r\n<p><span class="code blue">> sd(variable1)</span></p>\r\n<p><span class="code">[1] 4.99166</span></p>\r\n<p>When dealing with real data, we will often have information about more than one variable. We could enter all observations by hand for each variable but this is prone to error and onerous for all but the smallest data sets. If you are to ever utilize the power of statistics in the evolving data-centered world, data management has to be accomplished in a more sophisticated way. While you can manage data sets quite effectively in R, it is often easiest to start with your data set in something like Microsoft Excel or OpenOffice''s Calc. You want to make sure that observations are in the rows and the names of variables are in the columns and that there is no "extra stuff" in the spreadsheet. If you have missing observations, they should be represented with blank cells. The file should be saved as a ".csv" file (stands for comma-separated values although Excel calls it "CSV (Comma Delimited)", which basically strips off some of the junk that Excel adds to the necessary information in the file. Excel will tell you that this is a bad idea, but it actually creates a more stable long-term storage format and one that R can use directly. There will be a few words in the last chapter regarding why we use R in this course instead of Excel or other (commercial) statistical software. We''ll wait until we show you some of the cool things that R can do to discuss why we didn''t use other software.</p>\r\n<p>With a data set converted to a CSV file, we need to read the data set into R. There are two ways to do this, either using the GUI point-and-click interface in R-studio or modifying the <span class="code-font">read.csv</span> function to find the file of interest. To practice this, you can download an Excel (.xls) file from <a href="https://dl.dropboxusercontent.com/u/77307195/treadmill.xls">https://dl.dropboxusercontent.com/u/77307195/treadmill.xls</a> that contains observations on 31 males that volunteered for a study on methods for measuring fitness (Westfall and Young, 1993). In the spreadsheet, you will find:</p>\r\n<table class="border">\r\n<tr>\r\n<td>Subject</td>\r\n<td>TreadMillOx</td>\r\n<td>TreadMillMaxPulse</td>\r\n<td>RunTime</td>\r\n<td>RunPulse</td>\r\n<td>RestPulse</td>\r\n<td>BodyWeight</td>\r\n<td>Age</td>\r\n</tr>\r\n  <tr>\r\n    <td>1</td>\r\n	<td>60.05</td>\r\n	<td>186</td>\r\n	<td>8.63</td>\r\n	<td>170</td>\r\n	<td>48</td>\r\n	<td>81.87</td>\r\n	<td>38</td>\r\n	</tr>\r\n <tr>\r\n    <td>2</td>\r\n    <td>59.57</td>		\r\n    <td>172</td>\r\n<td>8.17</td>\r\n<td>166</td>\r\n<td>40</td>\r\n<td>68.15</td>\r\n<td>42</td>\r\n  </tr>\r\n <tr>\r\n    <td>...</td>\r\n    <td>...</td>		\r\n    <td>...</td>\r\n<td>...</td>\r\n<td>...</td>\r\n<td>...</td>\r\n<td>...</td>\r\n<td>....</td>\r\n  </tr>\r\n <tr>\r\n    <td>30</td>\r\n    <td>39.2</td>		\r\n    <td>172</td>\r\n<td>12.88</td>\r\n<td>168</td>\r\n<td>44</td>\r\n<td>91.63</td>\r\n<td>54</td>\r\n  </tr>\r\n  <tr>\r\n    <td>31</td>\r\n    <td>37.39</td>		\r\n    <td>192</td>\r\n<td>14.03</td>\r\n<td>186</td>\r\n<td>56</td>\r\n<td>87.66</td>\r\n<td>45</td>\r\n  </tr>\r\n</table>\r\n<p>The variables contain information on the subject number (<em>Subject</em>), subjects'' treadmill oxygen consumption (<em>TreadMillOx</em>, in ml per kg per minute) and maximum pulse rate (<em>TreadMillMaxPulse</em>, in beats per minute), minutes to run 1.5 miles (<em>Run Time</em>), maximum pulse during 1.5 mile run (<em>RunPulse</em>, in beats per minute), resting pulse rate (<em>RestPulse</em>, beats per minute), Body Weight (<em>BodyWeight</em>, in kg), and <em>Age</em> (in years). Open the file in Excel or equivalent software and then save it as a .csv file in a location you can find. Then go to R-studio and click on <strong>Tools</strong>, then <strong>Import Data Set</strong>, then <strong>From Text File</strong>...<sup><a id="4top" href="#4ft">4</a></sup>  Find your file and check "Import". R will store the data set as an object named whatever the .csv file was named. You could use another name as well, but it is often easiest just to keep the data set name in R related to the original file. You should see some text appear in the console like in Figure 0-3. The text that is created will look something like the following (depending on the location you stored the file) - if you had stored the file in a drive labeled D:/, it would be:\r\n<p><span class="code blue">treadmill <- read.csv("D:/treadmill.csv")</span></p>\r\n<p>What is put inside the " " will depend on the location of your saved .csv file. A version of the data set in what looks like a spreadsheet will appear in the upper left window due to the second line of code <span class="code-font">(View(treadmill))</span>. Just directly typing (or using) a line of code like this is actually the other way that we can read in files. If you choose to use this, you need to tell R where to look in your computer to find the data file. <span class="code-font">read.csv</span> is a function that takes a path as an argument. To use it, specify the path to your data file, put quotes around it, and put it as the input to <span class="code-font">read.csv(...)</span>. For some examples later in the book, you will be able to copy a command like this and read data sets and other code directly from my Dropbox folder using an internet connection.</p>\r\n<figure><img src="../meta/img/Figure0.3.jpg" alt="Figure0.3"><figcaption><em>Figure 0-3: R-studio with inital data set loaded.</em></figcaption></figure>\r\n<p>To verify that you read in the data set correctly, it is good to check its contents. We can view the first and last rows in the data set using the <span class="code-font">head</span> and <span class="code-font">tail</span> functions on the data set, which show the following results for the <span class="code-font">treadmill</span> data. Note that you will sometimes need to resize the console window in R-studio to get all the columns to display in a single row which can be performed by dragging the grey bars that separate the panels.</p>\r\n<p><span class="code blue">>head(treadmill)</span></p>\r\n<table class="code">\r\n<tr>\r\n<td> </td>\r\n<td>Subject</td>		\r\n<td>TreadMillOx</td>\r\n<td>TreadMillMaxPulse</td>\r\n<td>RunTime</td>\r\n<td>RunPulse</td>\r\n<td>RestPulse</td>\r\n<td>BodyWeight</td>\r\n<td>Age</td>		\r\n</tr>\r\n<tr>\r\n<td>1</td>\r\n<td>1</td>		\r\n<td>60.05</td>\r\n<td>186</td>\r\n<td>8.63</td>\r\n<td>170</td>\r\n<td>48</td>\r\n<td>81.87</td>\r\n<td>38</td>		\r\n</tr>\r\n<tr>\r\n<td>2</td>\r\n<td>2</td>		\r\n<td>59.57</td>\r\n<td>172</td>\r\n<td>8.17</td>\r\n<td>166</td>\r\n<td>40</td>\r\n<td>68.15</td>\r\n<td>42</td>\r\n</tr>\r\n<tr>\r\n<td>3</td>\r\n<td>3</td>		\r\n<td>54.62</td>\r\n<td>155</td>\r\n<td>8.92</td>\r\n<td>146</td>\r\n<td>48</td>\r\n<td>70.87</td>\r\n<td>50</td>\r\n</tr>\r\n<tr>\r\n<td>4</td>\r\n<td>4</td>		\r\n<td>54.30</td>\r\n<td>168</td>\r\n<td>8.65</td>\r\n<td>156</td>\r\n<td>45</td>\r\n<td>85.84</td>\r\n<td>44</td>\r\n</tr>\r\n<tr>\r\n<td>5</td>\r\n<td>5</td>		\r\n<td>51.85</td>\r\n<td>170</td>\r\n<td>10.33</td>\r\n<td>166</td>\r\n<td>50</td>\r\n<td>83.12</td>\r\n<td>54</td>\r\n</tr>\r\n<tr>\r\n<td>6</td>\r\n<td>6</td>		\r\n<td>50.55</td>\r\n<td>155</td>\r\n<td>9.93</td>\r\n<td>148</td>\r\n<td>49</td>\r\n<td>59.08</td>\r\n<td>57</td>\r\n</tr>\r\n</table>\r\n<p><span class="code blue">>tail(treadmill)</span></p>\r\n<table span class="code">\r\n<tr>\r\n<td> </td>\r\n<td>Subject</td>		\r\n<td>TreadMillOx</td>\r\n<td>TreadMillMaxPulse</td>\r\n<td>RunTime</td>\r\n<td>RunPulse</td>\r\n<td>RestPulse</td>\r\n<td>BodyWeight</td>\r\n<td>Age</td>		\r\n</tr>\r\n<tr>\r\n<td>26</td>\r\n<td>26</td>		\r\n<td>44.61</td>\r\n<td>182</td>\r\n<td>11.37</td>\r\n<td>178</td>\r\n<td>62</td>\r\n<td>89.47</td>\r\n<td>44</td>		\r\n</tr>\r\n<tr>\r\n<td>27</td>\r\n<td>27</td>		\r\n<td>40.84</td>\r\n<td>172</td>\r\n<td>10.95</td>\r\n<td>168</td>\r\n<td>57</td>\r\n<td>69.63</td>\r\n<td>51</td>\r\n</tr>\r\n<tr>\r\n<td>28</td>\r\n<td>28</td>		\r\n<td>39.44</td>\r\n<td>176</td>\r\n<td>13.08</td>\r\n<td>174</td>\r\n<td>63</td>\r\n<td>81.42</td>\r\n<td>44</td>\r\n</tr>\r\n<tr>\r\n<td>29</td>\r\n<td>29</td>		\r\n<td>39.41</td>\r\n<td>176</td>\r\n<td>12.63</td>\r\n<td>174</td>\r\n<td>58</td>\r\n<td>73.37</td>\r\n<td>57</td>\r\n</tr>\r\n<tr>\r\n<td>30</td>\r\n<td>30</td>		\r\n<td>39.20</td>\r\n<td>172</td>\r\n<td>12.88</td>\r\n<td>168</td>\r\n<td>44</td>\r\n<td>91.63</td>\r\n<td>54</td>\r\n</tr>\r\n<tr>\r\n<td>31</td>\r\n<td>31</td>		\r\n<td>37.39</td>\r\n<td>192</td>\r\n<td>14.03</td>\r\n<td>186</td>\r\n<td>56</td>\r\n<td>87.66</td>\r\n<td>45</td>\r\n</tr>\r\n</table>\r\n<p>While not always required, for many of the analyses, we will tap into a large suite of additional functions available in R packages by "installing" (basically downloading) and then "loading" the packages. There are some packages that we will use frequently, starting with the <span class="code-font">mosaic</span> package (Pruim, Kaplan, and Horton, 2014). To install a R package, go to the <strong>Packages</strong> tab in the lower right panel of R-studio. Click on the <strong>Install</strong> button and then type in the name of the package in the box (here type in <span class="code-font">mosaic</span>). R-studio will try to auto-complete the package name you are typing which should help you make sure you got it typed correctly. This will be the first of many times that we will mention that R is case sensitive - in other words, <span class="code-font">Mosaic</span> is different from <span class="code-font">mosaic</span> in R syntax. You should only need to install each R package once on a given computer. If you ever see a message that R can''t find a package, make sure it appears in the list in the Packages tab and if it doesn''t, repeat the previous steps to install it.</p>\r\n<p>After installing the <strong>package</strong>, we need to load it to make it active. We need to go to the command prompt and type (or copy and paste) <span class="code-font">require(mosaic)</span>:</p>\r\n<p><span class="code blue">> require(mosaic)</span></p>\r\n<p>You may see a warning message about versions of the package and versions of R - this is usually something you can ignore. Other warning messages could be more ominous for proceeding but before getting too concerned, there are couple of basic things to check. First, double check that the package is installed. Second, check for typographical errors in your code - especially for mis-spellings or unintended capilization. If you are still having issues, try repeating the installation process or find someone more used to using R to help you. Most computers in computer labs on campus at MSU have R and R-studio installed and provide another venue to use the software if you are having problems<sup><a id="5top" href="#5ft">5</a></sup>.</p>\r\n<p>To help you go from basic to intermediate R usage, you will want to learn how to manage and save your R code. The best way to do this is using the upper left panel in R-studio using what are called R-scripts and they have a file extension of .R. To start a new .R file to store your code, click on <strong>File</strong>, then <strong>New File</strong>, then <strong>R Script</strong>. This will create a blank page to enter and edit code - then save the file as MyFileName.R in your preferred location. Saving your code will mean that you can return to where you last were working by simply re-running the saved script file. With code in the script window, you can place the cursor on a line of code or highlight a chunk of code and hit the "Run" button on the upper part of the panel. It will appear in the console with results just like what you got if you typed it after the command prompt. Figure 0-4 shows the screen with the code used in this section in the upper left panel, saved in file called Ch0.R, with the results of highlighting and executing the first section of code using the "Run" button.</p>\r\n<figure><img src="../meta/img/Figure0.4.jpg" alt="Figure0.4" style="width:75%">\r\n<figcaption><em>Figure 0-4: R-studio with highlighted code run.</em></figcaption></figure>', '<p><sup><a id="3ft" href="#3top">3</a></sup>The need to keep the code up-to-date as R continues to evolve is one reason that this book is locally published...</p>\r\n<p><sup><a id="4ft" href="#4top">4</a></sup>If you are having trouble getting the file converted and read into R, copy and run the following code:  <span class="code blue code-font">treadmill=read.csv("http://dl.dropboxusercontent.com/u/77307195/treadmill.csv",header=T)</span></p>\r\n<p><sup><a id="5ft" href="#5top">5</a></sup>We highly recommend that you do not wait until the last minute to try to get R code to work for your own assignments. Even experienced R users can sometimes need a little time to find their errors.</p>', 'Preface', '0.002', '0.1', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-09-10 16:57:36', NULL, NULL, NULL, NULL),
(14, 'Basic summary statistics, histograms and boxplots using R', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>With R-studio running, the <span class="code-font">mosaic</span> package loaded, a place to write and save code, and the <span class="code-font">treadmill</span> data set loaded, we can (finally!) start to summarize the results of the study. The <span class="code-font">treadmill</span> object is what R calls a <em><strong>data.frame</em></strong> and contains columns corresponding to each variable in the spreadsheet. Every function in R will involve specifying the variable(s) of interest and how you want to use them. To access a particular variable (column) in a data.frame, you can use a $ between the data.frame name and the name of the variable of interest, as <span class="code-font">dataframename$variablename</span>. To identify the <span class="code-font">RunTime</span> variable here it would be <span class="code-font">treadmill$RunTime</span> and in the command would look like:</p>\r\n\r\n<p><span class="code blue">>treadmill$RunTime</span></p>\r\n<table class="code">  \r\n<tr>\r\n<td>[1]</td>\r\n<td>8.63</td>		\r\n<td>8.17</td>\r\n<td>8.92</td>\r\n<td>8.65</td>\r\n<td>10.33</td>\r\n<td>9.93</td>\r\n<td>10.13</td>\r\n<td>10.08</td>		\r\n<td>9.22</td>\r\n<td>8.95</td>\r\n<td>10.85</td>\r\n<td>9.40</td>\r\n<td>11.50</td>\r\n  </tr>\r\n  <tr>\r\n    <td>[14]</td>\r\n    <td>10.50</td>		\r\n    <td>10.60</td>\r\n<td>10.25</td>\r\n<td>10.00</td>\r\n<td>11.17</td>\r\n<td>10.47</td>\r\n<td>11.95</td>\r\n<td>9.63</td>\r\n    <td>10.07</td>		\r\n    <td>11.08</td>\r\n<td>11.63</td>\r\n<td>11.12</td>\r\n<td>11.37</td>\r\n  </tr>\r\n <tr>\r\n    <td>[27]</td>\r\n    <td>10.95</td>		\r\n    <td>13..08</td>\r\n<td>12.63</td>\r\n<td>12.88</td>\r\n<td>14.03</td>\r\n</table>\r\n<p>Just as in the previous section, we can generate summary statistics using functions like mean and sd:</p>\r\n<p><span class="code blue">> mean(treadmill$RunTime)</span></p>\r\n<p><span class="code">[1] 10.58613</span></p>\r\n<p><span class="code blue">> sd(treadmill$RunTime)</span></p>\r\n<p><span class="code">[1] 1.387414</span></p>\r\n<p>And now we know that the average running time for 1.5 miles for the subjects in the study was 10.6 minutes with a standard deviation (SD) of 1.39 minutes. But you should remember that the mean and SD are only appropriate summaries if the distribution is roughly <em><strong>symmetric</em></strong>. The <span class="code-font">mosaic</span> package provides a useful function called <span class="code-font">favstats</span> that provides the mean and SD as well as the <em><strong>5 number summary</em></strong>: the minimum (<span class="code-font">min</span>), the first quartile (Q1, the 25<sup>th</sup> percentile), the median (50<sup>th</sup> percentile), the third quartile (Q3, the 75<sup>th</sup> percentile), and the maximum (<span class="code-font">max</span>). It also provides the number of observation (n) which was 31, as noted above, and a count of whether any missing values were encountered (<span class="code-font">missing</span>), which was 0 here.</p>\r\n<p><span class= "code blue">> favstats(treadmill$RunTime)<span></p>\r\n<table class="code">\r\n<tr>\r\n<td>min</td>		\r\n<td>Q1</td>\r\n<td>median</td>\r\n<td>Q3</td>\r\n<td>max</td>\r\n<td>mean</td>\r\n<td>sd</td>\r\n<td>n</td>	\r\n<td>missing</td>		\r\n</tr>\r\n<tr>\r\n<td>8.17</td>\r\n<td>9.78</td>		\r\n<td>10.47</td>\r\n<td>11.27</td>\r\n<td>14.03</td>\r\n<td>10.58613</td>\r\n<td>1.387414</td>\r\n<td>31</td>\r\n<td>0</td>		\r\n</tr>\r\n</table>\r\n<p>We are starting to get somewhere with understanding that the runners were somewhat fit with worst runner covering 1.5 miles in 14 minutes (a 9.3 minute mile) and the best running a 5.4 minute mile. The limited variation in the results suggests that the sample was obtained from a restricted group with somewhat common characteristics. When you explore the ages and weights of the subjects in the Practice Problems in Section 0.5, you will get even more information about how similar all the subjects in this study were. A graphical display of these results will help us assess the shape of the distribution of run times - including considering the potential for the presence of a <em><strong>skew</em></strong> and <em><strong>outliers</em></strong>. A <em><strong>histogram</em></strong> is a good place to start. Histograms display connected bars with counts of observations defining the height of bars based on a set of bins of values of the quantitative variable. We will apply the <span class="code-font">hist</span> function to the <span class="code-font">RunTime</span> variable, which produces Figure 0-5. </p>\r\n<p><span class="code blue">> hist(treadmill$RunTime)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure0.5.jpg" alt="Figure0.5">\r\n<figcaption><em>Figure 0-5: Histogram of Run Times in minutes of n=31 subjects in Treadmill study.</em></figcaption>\r\n</figure>\r\n<p>I used the <strong>Export</strong> button found above the plot, followed by <strong>Copy to Clipboard</strong> and clicking on the <strong>Copy Plot</strong> button to make it available to paste the figure into your favorite word-processing program. You can see the first parts of this process in the screen grab in Figure 0-6.</p>\r\n<figure>\r\n<img src="../meta/img/Figure0.6.jpg" alt="Figure0.6" style="width:75%">\r\n<figcaption><em>Figure 0-6: R-studio while in the process of copying the histogram.</em></figcaption>\r\n</figure>\r\n<p>You can also directly save the figures as separate files using <strong>Save as image</strong> or <strong>Save as PDF</strong> and then insert them into other documents. </p>\r\n<p>The function defaults into providing a histogram on the <em><strong>frequency</em></strong> or count scale. In most R functions, there are the default options that will occur if we don''t make any specific choices and options that we can modify. One option we can modify here is to add labels to the bars to be able to see exactly how many observations fell into each bar. Specifically, we can turn the <span class="code-font">labels</span> option "on" with adding <span class="code-font">labels=T</span> to the previous call to the <span class="code-font">hist</span> function, separated by a comma:</p>\r\n<span class="code blue"> hist(treadmill$RunTime,labels=T)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure0.7.jpg" alt="Figure0.7">\r\n<figcaption><em>Figure 0-7: Histogram of Run Times with counts in bars labelled.</em></figcaption>\r\n</figure>\r\n<p>Based on this histogram, it does not appear that there any outliers in the responses since there are no bars that are separated from the other observations. However, the distribution does not look symmetric and there might be a skew to the distribution. Specifically, it appears to be <em><strong>skewed right</em></strong> (the right tail is longer than the left). But histograms can sometimes mask features of the data set by binning observations and it is hard to find the percentiles accurately from the plot.<p/>\r\n<p>When assessing outliers and skew, the <em><strong>boxplot</em></strong> (or <em>Box and Whiskers</em> plot) can also be helpful (Figure 0-8) to describe the shape of the distribution as it displays the 5-number summary and will also indicate observations that are "far" above the middle of the observations. R''s <span class="code-font">boxplot</span> function uses the standard rule to indicate an observation as a <em><strong>potential outlier</em></strong> if it falls more than 1.5 times the <em><strong>IQR</em></strong> (Inter-Quartile Range, calculated as Q3-Q1) below Q1 or above Q3. The potential outliers are plotted with circles and the <em>Whiskers</em> (lines that extend from Q1 and Q3 typically to the minimum and maximum) are shortened to only go as far as observations that are within 1.5*IQR of the upper and lower quartiles. The box part of the boxplot is a box that goes from Q1 to Q3 and the median is displayed as a line somewhere inside the box<sup><a id="6top" href="#6ft">6</a></sup>. Looking back at the summary statistics above, Q1=9.78 and Q3=11.27, providing an IQR of:</p>\r\n<p><span class="code blue">> IQR<-11.27-9.78</p>\r\n<span class="code blue">> IQR</span></p>\r\n<p><span class="code">[1] 1.49</span></p>\r\n<p>One observation (the maximum value of 14.03) is indicated as a potential outlier based on this result by being larger than Q3+1.5*IQR, which was 13.505:</p>\r\n<p><span class="code blue">> 11.27+1.5*IQR</span></p>\r\n<p><span class="code">[1] 13.505</span></p>\r\n<p>The boxplot also shows a slight indication of a right skew (skew towards larger values) with the distance from the minimum to the median being smaller than the distance from the median to the maximum. Additionally, the distance from Q1 to the median is smaller than the distance from the median to Q3. It is modest skew, but is worth noting. </p>\r\n<p><span class="code blue" > boxplot(treadmill$RunTime)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure0.8.jpg" alt="Figure0.8">\r\n<figcaption><em>Figure 0-8: Boxplot of 1.5 mile Run Times.</em></figcaption>\r\n</figure>\r\n<p>While the default boxplot is fine, it fails to provide good graphical labels, especially on the y-axis. Additionally, there is no title on the plot. The following code provides some enhancements to the plot by using the <span class="code-font">ylab</span> and <span class="code-font">main</span> options in the call to <span class="code-font">boxplot</span>, with the results displayed in Figure 0-9.\r\n<p><span class="code blue"> boxplot(treadmill$RunTime,ylab="1.5 Mile Run Time (minutes)",main="Boxplot of the Run Times of n=31 participants")</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure0.9.jpg" alt="Figure0.9">\r\n<figcaption><em>Figure 0-9: Boxplot of Run Times with improved labels.</em></figcaption>\r\n</figure>\r\n<p>Throughout the book, we will often use extra options to make figures that are easier for you to understand. There are often simpler versions of the functions that will suffice but the extra work to get better labeled figures is often worth it. I guess the point is that "a picture is worth a thousand words" if the reader can understand what is being displayed and if the information is worth displaying. </p>', '<p><sup><a id="6ft" href="#6top">6</a></sup>The median, quartiles and whiskers sometimes occur at the same values when there are many tied observations. If you can''t see all the components of the boxplot, produce the numerical summary to help you understand what happened.</p>', 'Preface', '0.003', '0.2', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-28 14:09:55', NULL, NULL, NULL, NULL),
(18, 'Chapter summary', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>You should have R and R-studio downloaded and working after going through this preliminary chapter. You should be able to read a data set into R and run some basic functions, all done using the R-studio interface. If you are struggling with this, you should seek additional help with these technical issues so that you are ready for more complicated statistical methods that are coming very soon. For most assignments, we will give you a seed of the basic R code that you need. Then you will modify it to work on your data set of interest. As mentioned previously, the way everyone learns and uses R involves starting with someone elses code and then modifying it. If you can complete the Practice Problems that follow, you are on your way to learning to use R.</p>\r\n<p>The statistical methods in this chapter were minimal and all should have been review. They involved a quick reminder of summarizing the center, spread, and shape of distributions using numerical summaries of the mean and SD and/or the min, Q1, median, Q3, and max and the histogram and boxplot as graphical summaries. The main point was really to get a start on using R to provide results you should be familiar with from your previous statistics experiences.</p>', NULL, 'Preface', '0.004', '0.3', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:56:09', NULL, NULL, NULL, NULL),
(39, 'Important R Code', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>At the end of each chapter, there will be a section highlighting the most important R code used. The dark text will never change but the lighter (red) text will need to be customized to your particular application. The sub-bullet for each function will discuss the use of the function and pertinent options or packages required. You can use this as a guide to finding the function names and some hints about options that will help you to get the code to work or you can revisit the worked examples using each of the functions.</p>\r\n\r\n<li><span class="red code-font">FILENAME</span><span class="code-font"><-read.csv("</span><span class="red code-font">path to save csv file</span><span class="code-font">/</span> <span class="red code-font">FILENAME</span><span class="code-font">.csv")</span><ul>\r\n<li>Can be generated using "Import Dataset" button or by modifying this text.</li></li></ul>\r\n<li><span class="red code-font">DATASETNAME</span>$<span class="red code-font">VARIABLENAME</span><ul>\r\n<li>To access a particular variable in a data.frame called <span class="red code-font">DATASETNAME</span>, use a $ and then the <span class="red code-font">VARIABLENAME</span>.</li></ul></li>\r\n<li><span class="code-font">head(</span><span class="red code-font">DATASETNAME</span><span class="code-font">)</span><ul>\r\n<li>Provides a list of the first few rows of the data set for all the variables in it.</li></ul></li>\r\n<li><span class="code-font">mean(</span><span class="red code-font">DATASETNAME</span>$<span class="red code-font">VARIABLENAME</span><span class="code-font">)</span><ul>\r\n<li>Calculates the mean of the observations in a variable.</li></ul></li>\r\n<li><span class="code-font">sd(</span><span class="red code-font">DATASETNAME</span>$<span class="red code-font">VARIABLENAME</span><span class="code-font">)</span><ul>\r\n<li>Calculates the SD of the observations in a variable.</li></ul></li>\r\n<li><span class="code-font">favstats(</span><span class="red code-font">DATASETNAME</span>$<span class="red code-font">VARIABLENAME</span><span class="code-font">)</span><ul>\r\n<li>Provides a suite of numerical summaries of the observations in a variable.</li>\r\n<li>Requires the mosaic package to be loaded (<span class="code-font">require(mosaic)</span>).</li></ul></li>\r\n<li><span class="code-font">hist(</span><span class="red code-font">DATASETNAME</span>$<span class="red code-font">VARIABLENAME</span><span class="code-font">)</span><ul>\r\n<li>Makes a histogram.</li></ul></li>\r\n<li><span class="code-font">boxplot(</span><span class="red code-font">DATASETNAME</span>$<span class="red code-font">VARIABLENAME</span><span class="code-font">)</span><ul>\r\n<li>Makes a boxplot.</li></ul></li>', NULL, 'Preface', '0.005', '0.4', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-09-16 15:17:58', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(40, 'Practice problems', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>At the end of each chapter, there is a section filled with questions related to the material. Your instructor has a file that contains the R code required to provide the results to answer all these questions. To practice learning R, it would be most useful for you to try to accomplish the requested tasks first yourself in R and then refer to the provided R code when you struggle. These questions provide a great venue to check what you are learning, see the methods applied to another data set, and to discuss in study groups, with your instructor, or at the Math Learning Center, especially if you have any questions about the correct responses.</p>\r\n<dd><p>0.1. Read in the treadmill data set discussed above and find the mean and SD of the Ages (<em>Age variable</em>) and Body Weights (<em>BodyWeight</em>). In studies involving human subjects, it is common to report a summaries of characteristics of the subjects. Why does this matter? Think about how your interpretation of any study of the fitness of subjects would change if the mean age had been 20 years older or 35 years younger.</dd></p>\r\n<dd><p>0.2. How does knowing about the distribution of results for <em>Age</em> and <em>BodyWeight</em> help you understand the results for the Run Times discussed above?</dd></p>\r\n<dd><p>0.3. The mean and SD are most useful as summary statistics only if the distribution is relatively symmetric. Make a histogram of <em>Age</em> responses and discuss the shape of the distribution (is it skewed right, skewed left, approximately symmetric?; are there outliers?). Approximately what range of ages does this study pertain to?</dd></p>\r\n<dd><p>0.4. The weight responses are in kilograms and you might prefer to see them in pounds. The conversion is lbs=2.205*kgs. Create a new variable in the <span class="code-font">treadmill</span> data.frame called <em>BWlb</em> using this code:</p>\r\n<p><span class="code-font">treadmill$BWlb <- 2.205*treadmill$BodyWeight</span></dd></p>\r\n<dd><p>and find the mean and SD of the new variable.</dd></p> \r\n<dd><p>0.5. Make histograms and boxplots of the original <em>BodyWeight</em> and new <em>BWlb</em> variables. Discuss aspects of the distributions that changed and those that remained the same with the transformation from kilograms to pounds.</dd></p> \r\n', NULL, 'Preface', '0.006', '0.5', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:56:48', NULL, NULL, NULL, NULL),
(41, '(R)e-introduction to statistics', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>The previous material served to get us started in R and to get a quick review of same basic descriptive statistics. Now we will begin to engage some new material and exploit the power of R to do some statistical inference. Because inference is one of the hardest topics to master in statistics, we will also review some basic terminology that is required to move forward in learning more sophisticated statistical methods. To keep this "review" as short as possible, we will not consider every situation you learned in introductory statistics and instead focus exclusively on the situation where we have a quantitative response variable measured on two groups.</p> ', NULL, 'Chapter 1', '1.001', '1', 'Textbook', 'Textbook', 'Statistics', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:37:08', NULL, NULL, NULL, NULL),
(42, 'Histograms, boxplots, and density curves', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>Part of learning statistics is learning to correctly use the terminology, some of which is used colloquially differently than it is used in formal statistical settings. The most commonly "misused" term is <em><strong>data</em></strong>. In statistical parlance, we want to note the plurality of data. Specifically, <em><strong>datum</em></strong> is a single measurement, possibly on multiple random variables, and so it is appropriate to say that "<strong>a datum is...</strong>". Once we move to discussing data, we are now referring to more than one observation, again on one, or possibly more than one, random variable, and so we need to use "<strong>data are...</strong>" when talking about our observations. We want to distinguish our use of the term "data" from its more colloquial<sup><a id="7top" href="#7ft">7</a></sup> usage that often involves treating it as singular and to refer to any sort of numerical information. We want to use "data" to specifically refer to measurements of our cases or units. When we summarize the results of a study (say providing the mean and SD), that information is not "data". We used our data to generate that information. Sometimes we also use the term "data set" to refer to all of our observations and this is a singular term to refer to the group of observations and this makes it really easy to make mistakes on the usage of this term.</p> \r\n<p>It is also really important to note that <em><strong>variables</em></strong> have to vary - if you measure the sex of your subjects but are only measuring females, then you do not have an interesting variable. The last, but probably most important, aspect of data is the context of the measurement. The who, what, when, and where of the collection of the observations is critical to the sort of conclusions we will make based on the observations. The information on the study design will provide the information required to assess the scope of inference of the study. Generally, remember to think about the research questions the researchers were trying to answer and whether their study actually would answer those questions. There are no formulas to help us sort some of these things out, just critical thinking about the context of the measurements.</p> \r\n<p>To make this concrete, consider the data collected from a study (Plaster, 1989) to investigate whether perceived physical attractiveness had an impact on the sentences or perceived seriousness of a crime that male jurors might give to female defendants. The researchers showed the participants in the study (men who volunteered from a prison) pictures of one of three young women. Each picture had previously been decided to be either beautiful, average, or unattractive by the researchers. Each "juror" was randomly assigned to one of three levels of this factor (which is a categorical predictor or explanatory variable) and then each rated their picture on a variety of traits such as how warm or sincere the woman appeared. Finally, they were told the women had committed a crime (also randomly assigned to either be told she committed a burglary or a swindle) and were asked to rate the seriousness of the crime and provide a suggested length of sentence. We will bypass some aspects of their research and just focus on differences in the sentence suggested among the three pictures. To get a sense of these data, let''s consider the first and last parts of the data set:</p>\r\n<table class="border" style="width:50%">\r\n  <tr>\r\n    <td>Subject</td>\r\n    <td>Attr</td>		\r\n    <td>Crime</td>\r\n<td>Years</td>\r\n<td>Serious</td>\r\n<td>independent</td>\r\n<td>Sincere</td>\r\n  </tr>\r\n  <tr>\r\n    <td>1</td>\r\n    <td>Beautiful</td>		\r\n    <td>Burglary</td>\r\n<td>10</td>\r\n<td>8</td>\r\n<td>9</td>\r\n<td>8</td>\r\n  </tr>\r\n <tr>\r\n    <td>2</td>\r\n    <td>Beautiful</td>		\r\n    <td>Burglary</td>\r\n<td>3</td>\r\n<td>8</td>\r\n<td>9</td>\r\n<td>3</td>\r\n  </tr>\r\n<tr>\r\n    <td>3</td>\r\n    <td>Beautiful</td>		\r\n    <td>Burglary</td>\r\n<td>5</td>\r\n<td>5</td>\r\n<td>6</td>\r\n<td>3</td>\r\n  </tr>\r\n<tr>\r\n    <td>4</td>\r\n    <td>Beautiful</td>		\r\n    <td>Burglary</td>\r\n<td>1</td>\r\n<td>3</td>\r\n<td>9</td>\r\n<td>8</td>\r\n  </tr>\r\n<tr>\r\n    <td>5</td>\r\n    <td>Beautiful</td>		\r\n    <td>Burglary</td>\r\n<td>7</td>\r\n<td>9</td>\r\n<td>5</td>\r\n<td>1</td>\r\n  </tr>\r\n <tr>\r\n    <td>...</td>\r\n    <td>...</td>		\r\n    <td>...</td>\r\n<td>...</td>\r\n<td>...</td>\r\n<td>...</td>\r\n<td>...</td>\r\n  </tr>\r\n <tr>\r\n    <td>108</td>\r\n    <td>Average</td>		\r\n    <td>Swindle</td>\r\n<td>3</td>\r\n<td>3</td>\r\n<td>5</td>\r\n<td>4</td>\r\n  </tr>\r\n  <tr>\r\n    <td>109</td>\r\n    <td>Average</td>		\r\n    <td>Swindle</td>\r\n<td>3</td>\r\n<td>2</td>\r\n<td>9</td>\r\n<td>9</td>\r\n  </tr>\r\n<tr>\r\n    <td>110</td>\r\n    <td>Average</td>		\r\n    <td>Swindle</td>\r\n<td>2</td>\r\n<td>1</td>\r\n<td>8</td>\r\n<td>8</td>\r\n  </tr>\r\n<tr>\r\n    <td>111</td>\r\n    <td>Average</td>		\r\n    <td>Swindle</td>\r\n<td>7</td>\r\n<td>4</td>\r\n<td>9</td>\r\n<td>1</td>\r\n  </tr>\r\n<tr>\r\n    <td>112</td>\r\n    <td>Average</td>		\r\n    <td>Swindle</td>\r\n<td>6</td>\r\n<td>3</td>\r\n<td>5</td>\r\n<td>2</td>\r\n  </tr>\r\n<tr>\r\n    <td>113</td>\r\n    <td>Average</td>		\r\n    <td>Swindle</td>\r\n<td>12</td>\r\n<td>9</td>\r\n<td>9</td>\r\n<td>1</td>\r\n  </tr>\r\n<tr>\r\n    <td>114</td>\r\n    <td>Average</td>		\r\n    <td>Swindle</td>\r\n<td>8</td>\r\n<td>8</td>\r\n<td>1</td>\r\n<td>5</td>\r\n  </tr>\r\n</table>\r\n<p>When working with data, we should always start with summarizing the sample size. We will use <em><strong>n</em></strong> for the number of subjects in the sample and denote the population size (if available) with <em><strong>N</em></strong>. Here, the sample size is <em><strong>n=114</em></strong>. In this situation, we do not have a random sample from a population (these were volunteers from the population of prisoners at the particular prison) so we can not make inferences to a larger group. But we can assess whether there is a <em><strong>causal effect</em></strong><sup><a id="8top" href="#8ft">8</a></sup>: if sufficient evidence is found to conclude that there is some difference in the responses across the treated groups, we can attribute those differences to the treatments applied, since the groups should be same otherwise due to the pictures being randomly assigned to the "jurors". The story of the data set - that it is was collected on prisoners - becomes pretty important in thinking about the ramifications of any results. Are male prisoners different from the population of college males or all residents of a state such as Montana? If so, then we should not assume that the detected differences, if detected, would also exist in some other group of male subjects. The lack of a random sample makes it impossible to assume that this set of prisoners might be like other prisoners. So there will be some serious caution with the following results. But it is still interesting to see if the pictures caused a difference in the suggested mean sentences, even though the inferences are limited to this group of prisoners. If this had been an observational study (suppose that the prisoners could select one of the three pictures), then we would have to avoid any of the "causal" language that we can consider here because the pictures were randomly assigned to the subjects. Without random assignment, the explanatory variable of picture choice could be <em><strong>confounded</em></strong> with another characteristic of prisoners that was related to which picture the selected, and that other variable might be the reason for the differences in the responses provided.</p>\r\n<p>Instead of loading this data set into R using the "Import Dataset" functionality, we can load a R package that contains the data, making for easy access to this data set. The package called <span class="code-font">heplots</span> (Fox, Friendly, and Monette, 2013) contains a data set called MockJury that contains the results of the study. We will also rely the R package called <span class="code-font">mosaic</span> (Pruim, Kaplan, and Horton, 2014) that was introduced previously. First (but only once), you need to install both packages, which can be done using the <span class="code-font">install.packages</span> function with quotes around the package name:</p>\r\n<p><span class="code-font code blue">> install.packages("heplots")</span>\r\n<p>After making sure that the packages are installed, we use the <span class="code-font">require</span> function around the package name (no quotes now!) to load the package.</p> \r\n<p><span class="code-font code blue">> require(heplots)</span></p>\r\n<p><span class="code-font code blue">> require(mosaic)</span></p>\r\n<p>To load the data set that is in a loaded package, we use the <span class="code-font">data</span> function.</p>\r\n<p><span class="code-font code blue">> data(MockJury)</span></p>\r\n<p>Now there will be a data.frame called <span class="code-font">MockJury</span> available for us to analyze. We can find out more about the data set as before in a couple of ways. First, we can use the <span class="code-font">View</span> function to provide a spreadsheet sort of view in the upper left panel. Second, we can use the <span class="code-font">head</span> and <span class="code-font">tail</span> functions to print out the beginning and end of the data set. Because there are so many variables, it may wrap around to show all the columns.</p>\r\n<p><span class="code-font code blue">> View(MockJury)</span></p>\r\n<p><span class="code-font code blue">> head(MockJury)</span></p>\r\n<table class="code code-font" style="width:50%">\r\n  <tr>\r\n<td>    </td>	\r\n    <td align="right">Attr</td>		\r\n    <td align="right">Crime</td>\r\n<td align="right">Years</td>\r\n<td align="right">Serious</td>\r\n<td align="right">exciting</td>\r\n<td align="right">calm</td> \r\n<td align="right">independent</td>\r\n<td align="right">Sincere</td>\r\n<td align="right">warm</td>\r\n<td align="right">phyattr</td>\r\n  </tr>\r\n <tr>\r\n    <td>1</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">Burglary</td>\r\n<td align="right">10</td>\r\n<td align="right">8</td>\r\n<td align="right">6</td>\r\n<td align="right">9</td>\r\n    <td align="right">9</td>\r\n    <td align="right">8</td>		\r\n    <td align="right">5</td>\r\n<td align="right">9</td>\r\n  </tr>\r\n<tr>\r\n    <td>2</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td>Burglary</td>\r\n<td align="right">3</td>\r\n<td align="right">8</td>\r\n<td align="right">9</td>\r\n<td align="right">5</td>\r\n<td align="right">9</td>\r\n    <td align="right">3</td>\r\n    <td align="right">5</td>		\r\n    <td align="right">9</td>\r\n  </tr>\r\n<tr>\r\n    <td>3</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">Burglary</td>\r\n<td align="right">5</td>\r\n<td align="right">5</td>\r\n<td align="right">3</td>\r\n<td align="right">4</td>\r\n<td align="right">6</td>\r\n    <td align="right">3</td>\r\n    <td align="right">6</td>		\r\n    <td align="right">7</td>\r\n  </tr>\r\n<tr>\r\n<td>4</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">Burglary</td>\r\n<td align="right">1</td>\r\n<td align="right">3</td>\r\n<td align="right">3</td>\r\n<td align="right">6</td>\r\n<td align="right">9</td>\r\n    <td align="right">8</td>\r\n    <td align="right">8</td>		\r\n    <td align="right">9</td>\r\n  </tr>\r\n<tr>\r\n<td>5</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">Burglary</td>\r\n<td align="right">7</td>\r\n<td align="right">9</td>\r\n<td align="right">1</td>\r\n<td align="right">1</td>\r\n<td align="right">5</td>\r\n    <td align="right">1</td>\r\n    <td align="right">8</td>		\r\n    <td align="right">8</td>\r\n  </tr>\r\n<tr>\r\n<td>6</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">Burglary</td>\r\n<td align="right">7</td>\r\n<td align="right">9</td>\r\n<td align="right">1</td>\r\n<td align="right">5</td>\r\n<td align="right">7</td>\r\n    <td align="right">5</td>\r\n    <td align="right">8</td>		\r\n    <td align="right">8</td>\r\n  </tr>\r\n    <tr>\r\n<td>    </td>\r\n    <td align="right">sociable</td>\r\n    <td align="right">kind</td>		\r\n    <td align="right">intelligent</td>\r\n<td align="right">strong</td>\r\n<td align="right">sophisticated</td>\r\n<td align="right">happy</td>\r\n<td align="right">ownPA</td>\r\n  </tr>\r\n <tr>\r\n    <td>1</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">9</td>\r\n<td align="right">6</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">5</td>\r\n<td align="right">9</td>\r\n  </tr>\r\n<tr>\r\n    <td>2</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">4</td>\r\n<td align="right">9</td>\r\n<td align="right">5</td>\r\n<td align="right">5</td>\r\n<td align="right">5</td>\r\n<td align="right">7</td>\r\n  </tr>\r\n<tr>\r\n    <td>3</td>\r\n    <td align="right">4</td>		\r\n    <td align="right">2</td>\r\n<td align="right">4</td>\r\n<td align="right">5</td>\r\n<td align="right">4</td>\r\n<td align="right">5</td>\r\n<td align="right">5</td>\r\n  </tr>\r\n<tr>\r\n    <td>4</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n  </tr>\r\n <tr>\r\n    <td>5</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">4</td>\r\n<td align="right">7</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">8</td>\r\n<td align="right">7</td>\r\n  </tr>\r\n <tr>\r\n    <td>6</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">5</td>\r\n<td align="right">8</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n  </tr>\r\n  </table>\r\n<span class="code blue">> tail(MockJury)</span>\r\n<table class="code code-font" style="width:50%">\r\n  <tr>\r\n<td>      </td>	\r\n    <td align="right">Attr</td>		\r\n    <td>Crime</td>\r\n<td align="right">Years</td>\r\n<td align="right">Serious</td>\r\n<td align="right">exciting</td>\r\n<td align="right">calm</td> \r\n<td align="right">independent</td>\r\n<td align="right">Sincere</td>\r\n<td align="right">warm</td>\r\n<td align="right">phyattr</td>\r\n  </tr>\r\n <tr>\r\n    <td>109</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">Swindle</td>\r\n<td align="right">3</td>\r\n<td align="right">2</td>\r\n<td align="right">7</td>\r\n<td align="right">6</td>\r\n    <td align="right">9</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">6</td>\r\n<td align="right">4</td>\r\n  </tr>\r\n<tr>\r\n    <td>110</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">Swindle</td>\r\n<td align="right">2</td>\r\n<td align="right">1</td>\r\n<td align="right">8</td>\r\n<td align="right">8</td>\r\n<td align="right">8</td>\r\n    <td align="right">8</td>\r\n    <td align="right">8</td>		\r\n    <td align="right">8</td>\r\n  </tr>\r\n<tr>\r\n    <td>111</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">Swindle</td>\r\n<td align="right">7</td>\r\n<td align="right">4</td>\r\n<td align="right">1</td>\r\n<td align="right">6</td>\r\n<td align="right">0</td>\r\n    <td align="right">1</td>\r\n    <td align="right">1</td>		\r\n    <td align="right">1</td>\r\n  </tr>\r\n<tr>\r\n<td>112</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">Swindle</td>\r\n<td align="right">6</td>\r\n<td align="right">3</td>\r\n<td align="right">5</td>\r\n<td align="right">3</td>\r\n<td align="right">5</td>\r\n    <td align="right">2</td>\r\n    <td align="right">4</td>		\r\n    <td align="right">1</td>\r\n  </tr>\r\n<tr>\r\n<td>113</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">Swindle</td>\r\n<td align="right">12</td>\r\n<td align="right">9</td>\r\n<td align="right">1</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n    <td align="right">1</td>\r\n    <td align="right">1</td>		\r\n    <td align="right">1</td>\r\n  </tr>\r\n<tr>\r\n<td>114</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">Swindle</td>\r\n<td align="right">8</td>\r\n<td align="right">8</td>\r\n<td align="right">1</td>\r\n<td align="right">9</td>\r\n<td align="right">1</td>\r\n    <td align="right">5</td>\r\n    <td align="right">1</td>		\r\n    <td align="right">1</td>\r\n  </tr>\r\n    <tr>\r\n<td>      </td>\r\n    <td align="right">sociable</td>\r\n    <td align="right">kind</td>		\r\n    <td align="right">intelligent</td>\r\n<td align="right">strong</td>\r\n<td align="right">sophisticated</td>\r\n<td align="right">happy</td>\r\n<td align="right">ownPA</td>\r\n  </tr>\r\n <tr>\r\n    <td>109</td>\r\n    <td align="right">7</td>		\r\n    <td align="right">6</td>\r\n<td align="right">8</td>\r\n<td align="right">6</td>\r\n<td align="right">5</td>\r\n<td align="right">7</td>\r\n<td align="right">2</td>\r\n  </tr>\r\n<tr>\r\n    <td>110</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">6</td>\r\n  </tr>\r\n<tr>\r\n    <td>111</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">4</td>\r\n<td align="right">1</td>\r\n<td align="right">1</td>\r\n<td align="right">1</td>\r\n<td align="right">9</td>\r\n<td align="right">6</td>\r\n  </tr>\r\n<tr>\r\n    <td>112</td>\r\n    <td align="right">4</td>		\r\n    <td align="right">9</td>\r\n<td align="right">3</td>\r\n<td align="right">3</td>\r\n<td align="right">9</td>\r\n<td align="right">5</td>\r\n<td align="right">3</td>\r\n  </tr>\r\n <tr>\r\n    <td>113</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">1</td>\r\n<td align="right">9</td>\r\n<td align="right">9</td>\r\n<td align="right">1</td>\r\n<td align="right">9</td>\r\n<td align="right">1</td>\r\n  </tr>\r\n <tr>\r\n    <td>114</td>\r\n    <td align="right">9</td>		\r\n    <td align="right">1</td>\r\n<td align="right">1</td>\r\n<td align="right">9</td>\r\n<td align="right">5</td>\r\n<td align="right">1</td>\r\n<td align="right">1</td>\r\n  </tr>\r\n  </table>\r\n<p>When data sets are loaded from packages, there is often extra documentation available about the data set which can be accessed using the help function.</p>\r\n<p><span class="code-font code blue">> help(MockJury)</span></p>\r\n<p>With many variables in a data set, it is often useful to get some quick information about all of them; the summary function provides useful information whether the variables are categorical or quantitative and notes if any values were missing.</p>\r\n<p><span class="code-font code blue">> summary(MockJury)</span></p>\r\n<table class="code code-font" style="width:66%">\r\n  <tr>\r\n<td align="right">Attr</td>		\r\n<td align="right">Crime</td>\r\n<td align="right">Years</td>\r\n<td align="right">Serious</td>\r\n<td align="right">exciting</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Beautiful :39</td>\r\n<td align="right">Burglary :59</td>		\r\n<td align="right">Min. :1.000</td>\r\n<td align="right">Min. :1.000</td>\r\n<td align="right">Min. :1.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Average :38</td>\r\n<td align="right">Swindle :55</td>\r\n<td align="right">1st Qu. 2.000</td>\r\n<td align="right">1st Qu. 3.000</td>\r\n<td align="right">1st Qu. 3.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Unattractive:37</td>\r\n<td>  </td>\r\n<td align="right">Median   :3.000</td>	\r\n<td align="right">Median   :5.000</td>\r\n<td align="right">Median   :5.000</td>\r\n</tr>\r\n<tr>\r\n<td> </td>\r\n<td> </td>\r\n<td align="right">Mean   :4.693</td>\r\n<td align="right">Mean   :5.010</td>\r\n<td align="right">Mean   :4.658</td>\r\n  </tr>\r\n<tr>\r\n<td> </td>\r\n<td> </td>\r\n<td align="right">3rd Qu.   :7.000</td>\r\n<td align="right">3rd Qu.   :6.750</td>\r\n<td align="right">3rd Qu.   :6.000</td>\r\n</tr>\r\n<tr>\r\n<td> </td>\r\n<td> </td>\r\n<td align="right">Max.     :15.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">calm</td> \r\n<td align="right">independent</td>\r\n<td align="right">Sincere</td>\r\n<td align="right">warm</td>\r\n<td align="right">phyattr</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">Min. :1.000</td>\r\n<td align="right">Min. :1.000</td>\r\n<td align="right">Min. :1.000</td>\r\n<td align="right">Min. :1.00</td>\r\n<td align="right">Min. :1.00</td>\r\n</tr>\r\n<tr>\r\n<td align="right">1st Qu.   :4.250</td>\r\n<td align="right">1st Qu.   :5.000</td>\r\n<td align="right">1st Qu.   :3.000</td>\r\n<td align="right">1st Qu.   :2.00</td>\r\n<td align="right">1st Qu.   :2.00</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Median   :6.500</td>\r\n<td align="right">Median   :5.000</td>\r\n<td align="right">Median   :5.000</td>\r\n<td align="right">Median   :5.00</td>\r\n<td align="right">Median   :5.00</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Mean   :5.982</td>\r\n<td align="right">Mean   :6.132</td>\r\n<td align="right">Mean   :4.789</td>\r\n<td align="right">Mean   :4.57</td>\r\n<td align="right">Mean   :4.93</td>\r\n</tr>\r\n<tr>\r\n<td align="right">3rd Qu.   :8.000</td>\r\n<td align="right">3rd Qu.   :8.000</td>\r\n<td align="right">3rd Qu.   :7.000</td>\r\n<td align="right">3rd Qu.   :7.00</td>\r\n<td align="right">3rd Qu.   :8.00</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.00</td>\r\n<td align="right">Max.     :9.00</td>\r\n</tr>\r\n<tr>\r\n    <td align="right">sociable</td>\r\n    <td align="right">kind</td>		\r\n    <td align="right">intelligent</td>\r\n<td align="right">strong</td>\r\n<td align="right">sophisticated</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Min.       :1.000</td>\r\n<td align="right">Min.       :1.000</td>\r\n<td align="right">Min.       :1.000</td>\r\n<td align="right">Min.       :1.00</td>\r\n<td align="right">Min.       :1.00</td>\r\n</tr>\r\n<tr>\r\n<td align="right">1st Qu.   :5.000</td>\r\n<td align="right">1st Qu.   :3.000</td>\r\n<td align="right">1st Qu.   :4.000</td>\r\n<td align="right">1st Qu.   :4.000</td>\r\n<td align="right">1st Qu.   :3.250</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Median   :7.000</td>\r\n<td align="right">Median   :5.000</td>\r\n<td align="right">Median   :7.000</td>\r\n<td align="right">Median   :6.000</td>\r\n<td align="right">Median   :5.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Mean   :6.132</td>\r\n<td align="right">Mean   :4.728</td>\r\n<td align="right">Mean   :6.096</td>\r\n<td align="right">Mean   :5.649</td>\r\n<td align="right">Mean   :5.061</td>\r\n</tr>\r\n<tr>\r\n<td align="right">3rd Qu.   :8.000</td>\r\n<td align="right">3rd Qu.   :7.000</td>\r\n<td align="right">3rd Qu.   :8.750</td>\r\n<td align="right">3rd Qu.   :7.000</td>\r\n<td align="right">3rd Qu.   :7.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">happy</td>\r\n<td align="right">ownPA</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">Min.       :1.000</td>\r\n<td align="right">Min.       :1.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">1st Qu.   :3.000</td>\r\n<td align="right">1st Qu.   :5.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Median   :5.000</td>\r\n<td align="right">Median   :6.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Mean   :5.061</td>\r\n<td align="right">Mean   :6.377</td>\r\n</tr>\r\n<tr>\r\n<td align="right">3rd Qu.   :7.000</td>\r\n<td align="right">3rd Qu.   :9.000</td>\r\n</tr>\r\n<tr>\r\n<td align="right">Max.     :9.000</td>\r\n<td align="right">Max.     :9.000</td>\r\n</tr>\r\n  </table>\r\n<p>This violates some rules about the amount of numbers to show versus useful information, but if we take a few moments to explore the output we can discover some useful aspects of the data set. The output is organized by variable, providing some summary information, either counts by category for categorical variables or the 5-number summary plus the mean for quantitative variables. For the first variable, called <span class="code-font">Attr</span> in the data.frame and that we might more explicitly name <em>Attractiveness</em>, we find counts of the number of subjects shown each picture: 37/114 viewed the "Unattractive" picture, 38 viewed "Average", and 39 viewed "Beautiful". We can also see that suggested sentences (data.frame variable <span class="code-font">Years</span>) ranged from 1 year to 15 years with a median of 3 years. It seems that all of the other variables except for <em>Crime</em> (type of crime that they were told the pictured woman committed) contained responses between 1 and 9 based on rating scales from 1=low to 9 =high.</p> \r\n<p>To accompany the numerical summaries, histograms and boxplots can provide some initial information on the shape of the distribution of the responses for the suggested sentences in <em>Years</em>. Figure 1-1 contains the histogram and boxplot of Years, ignoring any information on which picture the "jurors" were shown. The code is enhanced slightly to make it better labeled</p>\r\n<p><span class="code-font code blue">> hist(MockJury$Years,xlab="Years",labels=T,main="Histogram of Years")</span><p>\r\n<p><span class="code-font code blue">> boxplot(MockJury$Years,ylab="Years",main="Boxplot of Years")</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.1.jpg" alt="Figure1.1">\r\n<figcaption><em>Figure 1-1: Histogram and boxplot of suggested sentences in years.</em></figcaption>\r\n</figure>\r\n<p>The distribution appears to have a strong right skew with three observations at 15 years flagged as potential outliers. They seem to just be the upper edge of the overall pattern of a strongly right skewed distribution, so we certainly would want want to ignore them in the data set. In real data sets, outliers are common and the first step is to verify that they were not errors in recording. The next step is to study their impact on the statistical analyses performed, potentially considering reporting results with and without the influential observation(s) in the results. Sometimes the outliers are the most interesting part of the data set and should not always be discounted.</p>\r\n<p>Often when we think of distributions, we think of the smooth underlying shape that led to the data set realized in the histogram. Instead of binning up observations and making bars in the histogram, we can estimate what is called a <strong><em>density curve</strong></em> as a smooth curve that represents the observed distribution. Density curves can sometimes help us see features of the data sets more clearly. To understand the density curve, it is useful to initially see the histogram and density curve together. The density curve is scaled so that the total area<sup><a id="9top" href="#9ft">9</a></sup> under the curve is 1. To make a comparable histogram, the y-axis needs to be scaled so that the histogram is also on the "density" scale which makes the heights of the bars the height needed so that the proportion of the total data set in each bar is represented by the area in each bar (height times width). So the height depends on the width of the bars and the total area across all the bars is 1. In the <span class="code-font">hist</span> function, the <span class="code-font">freq=F</span> option does this required re-scaling. The density curve is added to the histogram using lines <span class="code-font">(density())</span>, producing the result in Figure 1-2 with added modifications of options for <span class="code-font">lwd</span> (line width) and <span class="code-font">col</span> (color) to make the plot more interesting. You can see how density curve somewhat matches the histogram bars but deals with the bumps up and down and edges a little differently. We can pick out the strong right skew using either display and will rarely make both together.</p>\r\n<p><span class="code-font code blue">> hist(MockJury$Years,freq=F,xlab="Years",main="Histogram of Years with density curve")</span></p>\r\n<p><span class="code-font code blue">> lines(density(MockJury$Years),lwd=3,col="red")</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.2.jpg" alt="Figure1.2">\r\n<figcaption><em>Figure 1-2: Histogram and density curve of Years data.</em></figcaption>\r\n</figure>\r\n<p>Histograms can be sensitive to the choice of the number of bars and even the cut-offs used to define the bins for a given number of bars. Small changes in the definition of cut-offs for the bins can have noticeable impacts on the shapes observed but this does not impact density curves. We are not going to over-ride the default choices for bars in histogram, but we can add information on the original observations being included in each bar. In the previous display, we can add what is called a <strong><em>rug</strong></em> to the plot, were a tick mark is made for each observation. Because the responses were provided as whole years (1, 2, 3, ..., 15), we need to use a graphical technique called <strong><em>jittering</strong></em> to add a little noise<sup><a id="10top" href="#10ft">10</a></sup> to each observation so all observations at each year value do not plot at the same points. In Figure 1-3, the added tick marks on the x-axis show the approximate locations of the original observations. We can clearly see how there are 3 observations at 15 (all were 15 and the noise added makes it possible to see them all. The limitations of the histogram arise around the 10 year sentence area where there are many responses at 10 years and just one at both 9 and 11 years, but the histogram bars sort of miss this that aspect of the data set. The density curve did show a small bump at 10 years. Density curves are, however, not perfect and this one shows area for sentences less than 0 years which is not possible here.</p> \r\n<p><span class="code-font code blue">> hist(MockJury$Years,freq=F,xlab="Years",main="Histogram of Years with density curve and rug")</span></p>\r\n<p><span class="code-font code blue">> lines(density(MockJury$Years),lwd=3,col="red")</span></p>\r\n<p><span class="code-font code blue">> rug(jitter(MockJury$Years),col="blue",lwd=2)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.3.jpg" alt="Figure1.3">\r\n<figcaption><em>Figure 1-3: Histogram and density curve and rug of the jittered responses.</em></figcaption>\r\n</figure>\r\n<p>The tools we''ve just discussed are going to help us move to comparing the distribution of responses across more than one group. We will have two displays that will help us make these comparisons. The simplest is the <strong><em>side-by-side boxplot</strong></em>, where a boxplot is displayed for each group of interest using the same y-axis scaling. In R, we can use its <strong><em>formula</strong></em> notation to see if the response (<span class="code-font">Years</span>) differs based on the group (<span class="code-font">Attr</span>) by using something like Y~X or, here,<span class="code-font">Years~Attr</span>. We also need to tell R where to find the variables and use the last option in the command, <span class="code-font">data=DATASETNAME</span>, to inform R of the data.frame to look in to find the variables. In this example, <span class="code-font">data=MockJury</span>. We will use the formula and <span class="code-font">data=</span>... options in almost every function we use from here forward. Figure 1-4 contains the side-by-side boxplots showing right skew for all the groups, slightly higher median and more variability for the <em>Unattractive</em> group along with some potential outliers indicated in two of the three groups.</p>\r\n<p><span class="code-font code blue">> boxplot(Years~Attr,data=MockJury)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.4.jpg" alt="Figure1.4">\r\n<figcaption><em>Figure 1-4: side-by-side boxplot of Years based on picture groups.</em></figcaption>\r\n</figure>\r\n<p>The "~" (the tilde symbol, which you can find in the upper left corner of your keyboard) notation will be used in two ways this semester. The formula use in R employed previously declares that the response variable here is Years and the explanatory variable is Attr. The other use for "~" is as shorthand for "is distributed as" and is used in the context of Y~N(0,1), which translates (in statistics) to defining the random variable Y as following a normal distribution with mean 0 and standard deviation of 1. In the current situation, we could ask whether the Years variable seems like it may follow a normal distribution, in other words, is Years~N(<strong><em>&mu;</strong></em>, <strong><em>&sigma;</strong></em>)? Since the responses are right skewed with some groups having outliers, it is not reasonable to assume that the Years variable for any of the three groups may follow a Normal distribution (more later on the issues this creates!). Remember that <strong><em>&mu;</strong></em> and <strong><em>&sigma;</strong></em> are parameters where <strong><em>&mu;</strong></em> is our standard symbol for the <strong><em>population mean</strong></em> and that <strong><em>&sigma;</strong></em> is the symbol of the <strong><em>population standard deviation</strong></em>.</p>\r\n', '<p><sup><a id="7ft" href="#7top">7</a></sup>You will more typically hear "data is" but that more often refers to information, sometimes even statistical summaries of data sets, than to observations collected as part of a study, suggesting the confusion of this term in the general public. We will explore a data set in Chapter 4 related to perceptions of this issue collected by researchers at <a href="http://fivethirtyeight.com">http://fivethirtyeight.com</a>.</p>\r\n<p><sup><a id="8ft" href="#8top">8</a></sup>We will try to reserve the term "effect" for situations where random assignment allows us to consider causality as the reason for the differences in the response variable among levels of the explanatory variable, if we find evidence against the null hypothesis of no difference.</p>\r\n<p><p><sup><a id="9ft" href="#9top">9</a></sup>If you''ve taken calculus, you will know that the curve is being constructed so that the integral from &#8722;&#8734; to &#8734; is 1.</p>\r\n<p><p><sup><a id="10ft" href="#10top">10</a></sup>Jittering typically involves adding random variability to each observation that is uniformly distributed in a range determined based on the spacing of the observations. If you re-run the <span class="code-font">jitter</span> function, the results will change. For more details, type <span class="code-font">help(jitter)</span> in R.</p>', 'Chapter 1', '1.002', '1.0', 'Textbook', 'Textbook', 'Histogram', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:38:24', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(43, 'Beanplots', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>The other graphical display for comparing multiple groups we will use is a newer display called a <strong><em>beanplot</strong></em> (Kampstra, 2008). It provides a side-by-side display that contains the density curve, the original observations that generated the density curve in a rug-plot, and the mean of each group. For each group the density curves are mirrored to aid in visual assessment of the shape of the distribution. This mirroring will often create a shape that resembles a violin with skewed distributions. Long, bold horizontal lines are placed at the mean for each group. All together this plot shows us information on the center (mean), spread, and shape of the distributions of the responses. Our inferences typically focus on the means of the groups and this plot allows us to compare those across the groups while gaining information on whether the mean is reasonable summary of the center of the distribution.</p>\r\n<p>To use the <span class="code-font">beanplot</span> function we need to install and load the <span class="code-font">beanplot</span> package. The function works like the boxplot used previously except that options for <span class="code-font">log, col</span>, and <span class="code-font">method</span> need to be specified. Use these options for any beanplots you make: <span class="code-font">log="",col="bisque", method="jitter".</span></p>\r\n<p><span class="code-font code blue">> require(beanplot)</span></p>\r\n<p><span class="code-font code blue">> beanplot(Years~Attr,data=MockJury,log="",col="bisque",method="jitter")</span></p>\r\n<p>Figure 1-5 reinforces the strong right skews that were also detected in the boxplots previously. The three large sentences of 15 years can now be clearly viewed, one in the <em>Beautiful</em> group and two in the <em>Unattractive</em> group. The <em>Unattractive</em> group seems to have more high observations than the other groups even though the <em>Beautiful</em> group had the largest number of observations around 10 years. The mean sentence was highest for the <em>Unattractive</em> group and the differences differences in the means between <em>Beautiful</em> and <em>Average</em> was small.</p>\r\n<figure>\r\n<img src="../meta/img/Figure1.5.jpg" alt="Figure1.5">\r\n<figcaption><em>Figure 1-5: Beanplot of Years by picture group. Long, bold lines correspond to mean of each group.</em></figcaption>\r\n</figure>\r\n<p>In this example, it appears that the mean for Unattractive is larger than the other two groups. But is this difference real? We will never know the answer to that question, but we can assess how likely we are to have seen a result as extreme or more extreme than our result, assuming that there is no difference in the means of the groups. And if the observed result is (extremely) unlikely to occur, then we can reject the hypothesis that the groups have the same mean and conclude that there is evidence of a real difference. We can get means and standard deviations by groups easily using the same formula notation with the <span class="code-font">mean</span> and <span class="code-font">sd</span> functions if the <span class="code-font">mosaic</span> package is loaded.</p>\r\n<p><span class="code-font code blue">> mean(Years~Attr,data=MockJuryR)</span></p>\r\n   <table class="code-font code">\r\n  <tr>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">Average</td>\r\n<td align="right">Unattractive</td>\r\n  </tr>\r\n <tr>\r\n    <td align="right">4.333333</td>\r\n    <td align="right">3.973684</td>		\r\n    <td align="right">5.810811</td>\r\n  </tr>\r\n</table>\r\n<p><span class="code-font code blue">> sd(Years~Attr,data=MockJuryR)</span></p>\r\n     <table class="code-font code">\r\n  <tr>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">Average</td>\r\n<td align="right">Unattractive</td>\r\n  </tr>\r\n <tr>\r\n    <td align="right">3.405362</td>\r\n    <td align="right">2.823519</td>		\r\n    <td align="right">4.364235</td>\r\n  </tr>\r\n</table>  \r\n<p>We can also use the favstats function to get those summaries and others.</p>\r\n<p><span class="code-font code blue">> favstats(Years~Attr,data=MockJuryR)</span></p>\r\n<table class="code-font code">\r\n  <tr>\r\n<td align="right">  </td>\r\n    <td align="right">min</td>		\r\n    <td align="right">Q1</td>\r\n<td align="right">median</td>\r\n<td align="right">Q3</td>\r\n<td align="right">max</td>\r\n<td align="right">mean</td>\r\n<td align="right">sd</td>\r\n<td align="right">n</td>\r\n<td align="right">missing</td>\r\n  </tr>\r\n <tr>\r\n<td align="right">Beautiful</td>\r\n<td align="right">1</td>\r\n<td align="right">2</td>\r\n<td align="right">3</td>\r\n    <td align="right">6.5</td>\r\n    <td align="right">15</td>		\r\n    <td align="right">4.333333</td>\r\n<td align="right">3.405362</td>\r\n<td align="right">39</td>\r\n<td align="right">0</td>\r\n  </tr>\r\n <tr>\r\n    <td align="right">Average</td>		\r\n    <td align="right">1</td>\r\n<td align="right">2</td>\r\n<td align="right">3</td>\r\n<td align="right">5.0</td>\r\n<td align="right">12</td>\r\n<td align="right">3.973684</td>\r\n<td align="right">2.823519</td>\r\n<td align="right">38</td>\r\n<td align="right">0</td>\r\n  </tr>\r\n <tr>\r\n <td align="right">Unattractive</td>		\r\n    <td align="right">1</td>\r\n<td align="right">2</td>\r\n<td align="right">5</td>\r\n    <td align="right">10</td>		\r\n    <td align="right">15</td>\r\n<td align="right">5.810811</td>\r\n <td align="right">4.364235</td>		\r\n    <td align="right">37</td>\r\n<td align="right">0</td>\r\n  </tr>\r\n</table>\r\n<p>We have an estimate of a difference of almost 2 years in the mean sentence between <em>Average</em> and <em>Unattractive</em> groups. Because there are three groups being compared in this study, we will have to wait to Chapter 2 and the One-Way ANOVA test to fully assess evidence related to some difference in the three groups. For now, we are going to focus on comparing the mean <em>Years</em> between <em>Average</em> and <em>Unattractive</em> groups - which is a <em><strong>2 independent sample mean</em></strong> situation and something you have seen before. We will use this simple scenario to review some basic statistical concepts and connect two frameworks for conducting statistical inference, randomization and parametric techniques. <em><strong>Parametric</em></strong> statistical methods involve making assumptions about the distribution of the responses and obtaining confidence intervals and/or p-values using a named distribution (like the z or t-distributions). Typically these results are generated using formulas and looking up areas under curves using a table or a computer. <em><strong>Randomization</em></strong>-based statistical methods use a computer to shuffle, sample, or simulate observations in ways that allow you to obtain p-values and confidence intervals without resorting to using tables and named distributions. Randomization methods are what are called <em><strong>nonparametric</em></strong> methods that often make fewer assumptions (they are <em><strong>not free of assumptions</em></strong>!) and so can handle a larger set of problems more easily than parametric methods. When the assumptions involved in the parametric procedures are met, the randomization methods often provide very similar results to those provided by the parametric techniques. To be a more sophisticated statistical consumer, it is useful to have some knowledge of both of these approaches to statistical inference and the fact that they can provide similar results might deepen your understanding of both approaches.</p>\r\n<p>Because comparing two groups is easier than comparing more than two groups, we will start with comparing the <em>Average</em> and <em>Unattractive</em> groups. We could remove the <em>Beautiful</em> group observations in a spreadsheet program and read that new data set back into R, but it is easier to use R to do data management once the data set is loaded. To remove the observations that came from the <em>Beautiful</em> group, we are going to generate a new variable that we will call <span class="code-font">NotBeautiful</span> that is true when observations came from another group (<em>Average</em> or <em>Unattractive</em>) and false for observations from the <em>Beautiful</em> group. To do this, we will apply the <em><strong>not equal</em></strong> logical function (!=) to the variable <span class="code-font">Attr</span>, inquiring whether it was different from the "<span class="code-font">Beautiful</span>" level.</p>\r\n<p><span class="code blue code-font">> NotBeautiful <- MockJury$Attr!="Beautiful"</span></p>\r\n<p><span class="code blue code-font">> NotBeautiful</span></p>\r\n<table class="code-font code">\r\n  <tr>\r\n<td align="right">[1]</td>\r\n    <td align="right">FALSE</td>\r\n    <td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n  </tr>\r\n <tr>\r\n<td align="right">[13]</td>\r\n    <td align="right">FALSE</td>		\r\n    <td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n  <tr>\r\n<td align="right">[25]</td>\r\n    <td align="right">TRUE</td>		\r\n    <td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">[37]</td>\r\n    <td align="right">TRUE</td>		\r\n    <td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n <tr>\r\n <td align="right">[49]</td>\r\n    <td align="right">TRUE</td>		\r\n    <td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">[61]</td>\r\n    <td align="right">TRUE</td>		\r\n    <td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">[73]</td>\r\n    <td align="right">TRUE</td>\r\n    <td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">[85]</td>\r\n    <td align="right">FALSE</td>\r\n    <td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">FALSE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">[97]</td>\r\n    <td align="right">TRUE</td>		\r\n    <td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n<td align="right">[109]</td>\r\n    <td align="right">TRUE</td>		\r\n    <td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n<td align="right">TRUE</td>\r\n  </tr>\r\n  </tr>\r\n</table>\r\n<p>This new variable is only <span class="code-font">FALSE</span> for the <em>Beautiful</em> responses as we can see if we compare some of the results from the original and new variable:</p>\r\n<p><span class="code-font code blue">> data.frame(MockJury$Attr,NotBeautiful)</span></p>\r\n <table class="code-font code">\r\n  <tr>\r\n<td align="right">  </td>\r\n    <td align="right">MockJury.Attr</td>\r\n    <td align="right">NotBeautiful</td>\r\n  </tr>\r\n <tr>\r\n<td align="right">1</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">FALSE</td>\r\n  </tr>\r\n  <tr>\r\n<td align="right">2</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">FALSE</td>\r\n  </tr>\r\n <tr>\r\n<td align="right">3</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">FALSE</td>\r\n  </tr>\r\n <tr>\r\n <td align="right">...</td>\r\n    <td align="right"> </td>		\r\n    <td align="right"> </td>\r\n  </tr>\r\n  <tr>\r\n<td align="right">20</td>\r\n    <td align="right">Beautiful</td>\r\n    <td align="right">FALSE</td>\r\n  </tr>\r\n <tr>\r\n<td align="right">21</td>\r\n    <td align="right">Beautiful</td>		\r\n    <td align="right">FALSE</td>\r\n  </tr>\r\n  <tr>\r\n<td align="right">22</td>\r\n    <td align="right">Unattractive</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n  <tr>\r\n<td align="right">23</td>\r\n    <td align="right">Unattractive</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n <tr>\r\n <td align="right">24</td>\r\n    <td align="right">Unattractive</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n <td align="right">25</td>\r\n    <td align="right">Unattractive</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n <td align="right">26</td>\r\n    <td align="right">Unattractive</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n <td align="right">...</td>\r\n    <td align="right"> </td>		\r\n    <td align="right"> </td>\r\n  </tr>\r\n<tr>\r\n <td align="right">112</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n <td align="right">113</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n<tr>\r\n <td align="right">114</td>\r\n    <td align="right">Average</td>		\r\n    <td align="right">TRUE</td>\r\n  </tr>\r\n</table>\r\n<p>To get rid of one of the groups, we need to learn a little bit about data management in R. <strong><em>Brackets</strong></em> <span class="code-font">([,])</span> are used to modify the rows or columns in a data.frame with entries before the comma operating on rows and entries after the comma on the columns. For example, if you want to see the results for the 5<sup>th</sup> subject we can reference the 5<sup>th</sup> row of the data.frame using <span class="code-font">[5,]</span> after the data.frame name:</p>\r\n<p><span class="code blue code-font">> MockJury[5,]</span></p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">  </td>\r\n<td align="right">Attr</td>\r\n    <td align="right">Crime</td>\r\n    <td align="right">Years</td>\r\n  <td align="right">Serious</td>\r\n    <td align="right">exciting</td>\r\n    <td align="right">calm</td>\r\n<td align="right">independent</td>\r\n    <td align="right">sincere</td>\r\n    <td align="right">warm</td>\r\n  </tr>\r\n  <tr>\r\n<td align="right">5</td>\r\n    <td align="right">Beautiful</td>\r\n    <td align="right">Burglary</td>\r\n <td align="right">7</td>\r\n    <td align="right">9</td>\r\n    <td align="right">1</td>\r\n <td align="right">1</td>\r\n    <td align="right">5</td>\r\n    <td align="right">1</td>\r\n <td align="right">8</td>\r\n    </tr>\r\n<tr>\r\n <td align="right"> </td>\r\n    <td align="right">phyattr</td>\r\n    <td align="right">sociable</td>\r\n <td align="right">kind</td>\r\n    <td align="right">intelligent</td>		\r\n    <td align="right">strong</td>\r\n <td align="right">sophisticated</td>\r\n    <td align="right">happy</td>\r\n    <td align="right">ownPA</td>\r\n  </tr>\r\n<tr>\r\n <td align="right">5</td>\r\n    <td align="right">8</td>		\r\n    <td align="right">9</td>\r\n <td align="right">4</td>\r\n    <td align="right">7</td>\r\n    <td align="right">9</td>\r\n <td align="right">9</td>\r\n    <td align="right">8</td>\r\n    <td align="right">7</td>\r\n  </tr>\r\n</table>\r\n<p>We could just extract the <em>Years</em> response for the 5th subject by incorporating information on the row and column of interest (<span class="code-font">Years</span> is the 3<sup>rd</sup> column):</p>\r\n<p><span class="code blue code-font">> MockJury[5,3]</p>\r\n<p><span class="code code-font">[1] 7</p>\r\n\r\n<p>In R, we can use logical vectors to keep any rows of the data.frame where the variable is true and drop any rows where it is false by placing the logical variable in the first element of the brackets. The reduced version of the data set should be saved with a different name such as <span class="code-font">MockJury2</span> that is used here:\r\n<p><span class="code blue code-font">> MockJury2 <- MockJury[NotBeautiful,]</p>\r\n\r\n<p>You will always want to check that the correct observations were dropped either using <span class="code-font">View(MockJury2)</span> or by doing a quick summary of the Attr variable in the new data.frame.</p>\r\n<p><span class="code blue code-font">> summary(MockJury2$Attr)</p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">Beautiful</td>\r\n<td align="right">Average</td>\r\n    <td align="right">Unattractive</td>\r\n</tr>\r\n<tr>\r\n    <td align="right">0</td>\r\n  <td align="right">38</td>\r\n    <td align="right">37</td>\r\n  </tr>\r\n</table>\r\n<p>It ends up that R remembers the <em>Beautiful</em> category even though there are 0 observations in it now and that can cause us some problems. When we remove a group of observations, we sometimes need to clean up categorical variables to just reflect the categories that are present. The <span class="code-font">factor</span> function creates categorical variables based on the levels of the variables that are observed and is useful to run here to clean up <span class="code-font">Attr.</span></p>\r\n<p><span class="code blue code-font">> MockJury2$Attr <- factor(MockJury2$Attr)</p>\r\n<p><span class="code blue code-font">> summary(MockJury2$Attr)</p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">Average</td>\r\n    <td align="right">Unattractive</td>\r\n</tr>\r\n<tr>\r\n  <td align="right">38</td>\r\n    <td align="right">37</td>\r\n  </tr>\r\n</table>\r\n<p>Now the boxplot and beanplots only contain results for the two groups of interest here as seen in Figure 1-6. </p>\r\n<p><span class="code blue code-font">> boxplot(Years~Attr,data=MockJury2)</p>\r\n<p><span class="code blue code-font">> beanplot(Years~Attr,data=MockJury2,log="",col="bisque",method="jitter")</p>\r\n\r\n<p>The two-sample mean techniques you learned in your previous course start with comparing the means the two groups. We can obtain the two means using the mean function or directly obtain the difference in the means using the <span class="code-font">compareMean</span> function (both require the <span class="code-font">mosaic</span> package). The compareMean function provides <span style="text-decoration: overline">x</span><sub><em>Unattractive</sub></em>&#8722;<span style="text-decoration: overline">x</span><sub><em>Average</sub></em> where <span style="text-decoration: overline">x</span> is the sample mean of observations in the subscripted group. Note that there are two directions to compare the means and this function chooses to take the mean from the second group name alphabetically and subtracts the mean from the first alphabetical group name. It is always good to check the direction of this calculation as having a difference of -1.84 years versus 1.84 years could be important to note.</p> \r\n<p><span class="code blue code-font">> mean(Years~Attr,data=MockJury2)</p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">Average</td>\r\n    <td align="right">Unattractive</td>\r\n</tr>\r\n<tr>\r\n  <td align="right"> 3.973684</td>\r\n    <td align="right">5.810811</td>\r\n  </tr>\r\n</table> \r\n<p><span class="code blue code-font">> compareMean(Years ~ Attr, data=MockJury2)</p>\r\n<p><span class="code code-font">[1] 1.837127</p>\r\n<figure>\r\n<img src="../meta/img/Figure1.6.jpg" alt="Figure1.6">\r\n<figcaption><em>Figure 1-6: Boxplot and beanplot of the Years responses on the reduced data set.</em></figcaption>\r\n</figure>', NULL, 'Chapter 1', '1.003', '1.1', 'Textbook', 'Textbook', 'Violin plot', NULL, NULL, NULL, NULL, NULL, '2015-09-15 17:06:09', NULL, NULL, NULL, NULL),
(44, 'Models, hypotheses, and permutations for the 2 sample mean situation', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>There appears to be some evidence that the <em>Unattractive</em> group is getting higher average lengths of sentences from the mock jurors than the <em>Average</em> group, but we want to make sure that the difference is real - that there is evidence to reject the assumption that the means are the same "in the population". First, a <em><strong>null hypothesis</em></strong><sup><a id="11top" href="#11ft">11</a></sup> which defines a <em><strong>null model</em></strong><sup><a id="12top" href="#12ft">12</a></sup> needs to be determined in terms of <em><strong>parameters</em></strong> (the true values in the population). The research question should help you determine the form of the hypotheses for the assumed population. In the 2 independent sample mean problem, the interest is in testing a null hypothesis of H<sub>0</sub>: &#956;<sub>1</sub>=&#956;<sub>2</sub> versus the alternative hypothesis of H<sub>A</sub>: <em>&#956;<sub>1</sub>&#8800;&#956;<sub>2</sub></em>, where <em>&#956;<sub>1</sub></em> is the parameter for the true mean of the first group and &#956;<sub>2</sub> is the parameter for the true mean of the second group. The alternative hypothesis involves assuming a statistical model for the i<sup>th</sup> (i=1,...,n<sub>j</sub>) response from the j<sup>th</sup> group (j=1,2), &#947;<sub>ij</sub>, is modeled as <em>&#947;<sub>ij</sub> = &#956;<sub>j</sub> + &#949;<sub>ij</sub></em>, where we typically assume that <em>&#949;<sub>ij</sub> ~ N(0,&#963;<sup>2</sup>)</em>. For the moment, focus on the models that assuming the means are the same (null)  or different (alternative) imply:</p>\r\n<table>\r\n<tr>\r\n<th>&#8226;</th> <th>Null Model: <em>&#947;<sub>ij</sub> = &#956; + &#949;<sub>ij</sub> </th></em><th>There is no difference in true means for the two groups.</th>\r\n</tr>\r\n<tr>\r\n<th>&#8226;</th> <th>Alternative Model: <em>yij = &#956;<sub>j</sub> + &#949;<sub>ij</sub></th></em>	<th>There is a difference in true means for the two groups.</th>\r\n</tr>\r\n</table>\r\n<p>Suppose we are considering the alternative model for the 4th observation (i=4) from the second group (j=2), then the model for this observation is <em>&#947;<sub>42</sub> = &#956;<sub>2</sub> + &#949;<sub>42</sub></em>. And for, say, the 5<sup>th</sup> observation from the first group (j=1), the model is <em>&#947;<sub>51</sub> = &#956;<sub>1</sub> + &#949;<sub>51</sub></em>. If we were working with the null model, the mean is always the same (&#956;) and the group specified does not change that aspect of the model.</p>\r\n<p>It can be helpful to think about the null and alternative models graphically. By assuming the null hypothesis is true (means are equal) and that the random errors around the mean follow a normal distribution, we assume that the truth is as displayed in the left panel of Figure 1-7 - two normal distributions with the same mean and variability. The alternative model allows the two groups to potentially have different means, such as those displayed in the right panel of Figure 1-7, but otherwise assumes that the responses have the same distribution. We assume that the observations (&#947;<sub>ij</sub>) would either have been generated as samples from the null or alternative model - imagine drawing observations at random from the pictured distributions. The hypothesis testing task in this situation involves first assuming that the null model is true and then assessing how unusual the actual result was relative to that assumption so that we can conclude that the alternative model is likely correct. The researchers obviously would have hoped to encounter some sort of noticeable difference in the sentences provided for the different pictures and been able to find enough evidence to reject the null model where the groups "looked the same".</p>\r\n<figure>\r\n<img src="../meta/img/Figure1.7.jpg" alt="Figure1.7">\r\n<figcaption><em>Figure 1-7: Illustration of the assumed situations under the null (left) and a single possibility that could occur if the alternative were true (right).</em></figcaption>\r\n</figure>\r\n<p>In statistical inference, null hypotheses (and their implied models) are set up as "straw men" with every interest in rejecting them even though we assume they are true to be able to assess the evidence <u>against them</u>. Consider the original study design here, the pictures were randomly assigned to the subjects. If the null hypothesis were true, then we would have no difference in the population means of the groups. And this would apply if we had done a different random assignment of the pictures to the subjects. So let''s try this: assume that the null hypothesis is true and randomly re-assign the treatments (pictures) to the observations that were obtained. In other words, keep the sentences (<em>Years</em>) the same and shuffle the group labels randomly. The technical term for this is doing a <strong><em>permutation</strong></em> (a random shuffling of the treatments relative to the responses). If the null is true and the means in the two groups are the same, then we should be able to re-shuffle the groups to the observed sentences (<em>Years</em>) and get results similar to those we actually observed. If the null is false and the means are really different in the two groups, then what we observed should differ from what we get under other random permutations. The differences between the two groups should be more noticeable in the observed data set than in (most) of the shuffled data sets. It helps to see this to understand what a permutation means in this context.</p>\r\n<p>In the <span class="code-font">mosaic R</span> package, the <span class="code-font">shuffle</span> function allows us to easily perform a permutation<sup><a id="13top" href="#13ft">13</a></sup>. Just one time, we can explore what a permutation of the treatment labels could look like.</p>\r\n<p><span class="code blue code-font">> Perm1 <- with(MockJury2,data.frame(Years,Attr,PermutedAttr=shuffle(Attr)))</span></p>\r\n<p><span class="code blue code-font">> Perm1</span></p>\r\n<table class="code code-font">\r\n<tr>\r\n<th align="right"> </th>   \r\n<th align="right">Years</th>      \r\n<th align="right">Attr</th> \r\n<th align="right">PermutedAttr</th></tr>\r\n<tr>\r\n<th align="right">1</th>      <th align="right">1</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr>\r\n<th align="right">2</th>      <th align="right">4</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr>\r\n<tr><th align="right">3</th>     <th align="right">3</th> <th align="right">Unattractive</th>    <th align="right">Average</th></tr>\r\n<tr><th align="right">4</th>     <th align="right">2</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">5</th>      <th align="right">8</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">6</th>      <th align="right">8</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">7</th>      <th align="right">1</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">8</th>      <th align="right">1</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">9</th>     <th align="right">5</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">10</th>     <th align="right">7</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">11</th>     <th align="right">1</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">12</th>     <th align="right">5</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">13</th>     <th align="right">2</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">14</th>    <th align="right">12</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">15</th>   <th align="right">10</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">16</th>     <th align="right">1</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">17</th>     <th align="right">6</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">18</th>     <th align="right">2</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">19</th>     <th align="right">5</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">20</th>    <th align="right">12</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">21</th>     <th align="right">6</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">22</th>     <th align="right">3</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">23</th>     <th align="right">8</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">24</th>     <th align="right">4</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">25</th>    <th align="right">10</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">26</th>    <th align="right">10</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">27</th>    <th align="right">15</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">28</th>    <th align="right">15</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">29</th>     <th align="right">3</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<th align="right">30</th>     <th align="right">3</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">31</th>     <th align="right">3</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">32</th>    <th align="right">11</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">33</th>    <th align="right">12</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">34 </th>    <th align="right">2</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">35</th>     <th align="right">1</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">36</th>     <th align="right">1</th> <th align="right">Unattractive</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">37</th>    <th align="right">12</th> <th align="right">Unattractive</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">38</th>     <th align="right">5</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">39</th>     <th align="right">5</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">40</th>     <th align="right">4</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">41</th>     <th align="right">3</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">42</th>     <th align="right">6</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">43</th>     <th align="right">4</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">44</th>     <th align="right">9</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">45</th>     <th align="right">8</th>     <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">46</th>     <th align="right">3</th>     <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">47</th>     <th align="right">2</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">48</th>    <th align="right">10</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">49</th>     <th align="right">1</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">50</th>     <th align="right">1</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">51</th>     <th align="right">3</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">52</th>     <th align="right">1</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">53</th>     <th align="right">3</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">54</th>     <th align="right">5</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">55</th>     <th align="right">8</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">56</th>     <th align="right">3</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">57</th>     <th align="right">1</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">58</th>     <th align="right">1</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">59</th>     <th align="right">1</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">60</th>     <th align="right">2</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">61</th>     <th align="right">2</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">62</th>     <th align="right">1</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">63</th>     <th align="right">1</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">64</th>     <th align="right">2</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">65</th>     <th align="right">3</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">66</th>     <th align="right">4</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">67</th>     <th align="right">5</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">68</th>     <th align="right">3</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">69</th>     <th align="right">3</th>      <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">70</th>     <th align="right">3</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">71</th>     <th align="right">2</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n<tr><th align="right">72</th>     <th align="right">7</th>     <th align="right">Average</th> <th align="right">Unattractive</th></tr>\r\n<tr><th align="right">73</th>     <th align="right">6</th>     <th align="right">Average</th>     <th align="right">Average</th></tr>\r\n<tr><th align="right">74</th>    <th align="right">12</th>      <th align="right">Average</th>     <th align="right"> Average</th></tr>\r\n<tr><th align="right">75</th>     <th align="right">8</th>      <th align="right">Average</th>      <th align="right">Average</th></tr>\r\n</table>\r\n\r\n<p>If you count up the number of subjects in each group by counting the number of times each label (Average, Unattractive) occurs, it is the same in both the <span class="code-font">Attr</span> and <span class="code-font">PermutedAttr</span> columns. Permutations involve randomly re-ordering the values of a variable - here the <span class="code-font">Attr</span> group labels. This result can also be generated using what is called <strong><em>sampling without replacement</strong></em>: sequentially select <em>n</em> labels from the original variable, removing each used label and making sure that each original <span class="code-font">Attr</span> label is selected once and only once. The new, randomly selected order of selected labels provides the permuted labels. Stepping through the process helps us understand how it works: after the initial random sample of one label, there would <em>n</em>-1 choices possible; on the <em>n</em><sup>th</sup> selection, there would only be one label remaining to select. This makes sure that all original labels are re-used but that the order is random. Sampling without replacement is like picking names out of a hat, one-at-a-time, and not putting the names back in after they are selected. <strong><em>Sampling with replacement</strong></em> involves sampling from the specified list with each observation having an equal chance of selection for each sampled observation - in other words, observations can be selected more than once. This is like picking n names out of a hat that contains n names, except that every time a name is selected, it goes back into the hat - we''ll use this technique later in the Chapter to do what is called <strong><em>bootstrapping</strong></em>. Both sampling mechanisms can be used to generate inferences but each has particular situations where they are most useful.</p>\r\n<p>The comparison of the beanplots for the real data set and permuted version of the labels is what is really interesting (Figure 1-8). The original difference in the sample means of the two groups was 1.84 years (Unattractive minus Average). The sample means are the <strong><em>statistics</strong></em> that estimate the parameters for the true means of the two groups. In the permuted data set, the difference in the means is 0.66 years. </p>\r\n<p><span class="code blue code-font">> mean(Years ~ PermutedAttr, data=Perm1)</span></p>\r\n<table class="code code-font">\r\n<tr>\r\n<th>Average</th>\r\n<th>Unattractive</th>\r\n</tr>\r\n<tr>\r\n<th>4.552632</th>\r\n<th>5.216216 </th>\r\n</tr>\r\n</table>     \r\n<p><span class="code blue code-font">> compareMean(Years ~ PermutedAttr, data=Perm1)</span></p>\r\n<p><span class="code code-font">[1] 0.6635846</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.8.jpg" alt="Figure1.8">\r\n<figcaption><em>Figure 1-8: Boxplots of Years responses versus actual treatment groups and permuted groups.</em></figcaption>\r\n</figure>\r\n<p>These results suggest that the observed difference was larger than what we got when we did a single permutation. The important aspect of this is that the permutation is valid if the null hypothesis is true - this is a technique to generate results that we might have gotten if the null hypothesis were true. We just need to repeat the permutation process many times and track how unusual our observed result is relative to this distribution of responses. If the observed differences are unusual relative to the results under permutations, then there is evidence against the null hypothesis, the null hypothesis should be rejected (Reject H<sub>0</sub>) and a conclusion should be made, in the direction of the alternative hypothesis, that there is evidence that the true means differ. If the observed differences are similar to (or at least not unusual relative to) what we get under random shuffling under the null model, we would have a tough time concluding that there is any real difference between the groups based on our observed data set.</p>\r\n', '<p><sup><a id="11ft" href="#11top">11</a></sup>The hypothesis of no difference that is typically generated in the hopes of being rejected in favor of the alternative hypothesis which contains the sort of difference that is of interest in the application.</p>\r\n <p><sup><a id="12ft" href="#12top">12</a></sup>The null model is the statistical model that is implied by the chosen null hypothesis. Here, a null hypothesis of no difference will translate to having a model with the same mean for both groups.\r\n<p><sup><a id="13ft" href="#13top">13</a></sup>We''ll see the <span class="code-font">shuffle</span> function in a more common usage below; while the code to generate <span class="code-font">Perm1</span> is provided, it isn''t something to worry about right now: <span class="code-font">Perm1<-with(MockJury2,data.frame(Years,Attr,PermutedAttr=shuffle(Attr)))</span></p>', 'Chapter 1', '1.004', '1.2', 'Textbook', 'Textbook', 'Permutation', NULL, NULL, NULL, NULL, NULL, '2015-08-31 16:24:09', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(45, 'Permutation testing for the 2 sample mean situation', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In any testing situation, you must define some function of the observations that gives us a single number that addresses our question of interest. This quantity is called a test statistic. These often take on complicated forms and have names like t or z statistics that relate to their parametric (named) distributions so we know where to look up p-values. In randomization settings, they can have simpler forms because we use the data set to find the distribution of the statistic. We will label our test statistic <em>T</em> (for <em><strong>T</em></strong>est statistic) unless the test statistic has a commonly used name. Since we are interested in comparing the means of the two groups, we can define <em>T</em>=<span style="text-decoration: overline">x</span><sub><em>Unattractive</em></sub>&#8722;<span style="text-decoration: overline">x</span><sub><em>Average</sub></em>, which coincidentally is what the <span class="code-font">compareMean function</span> provided us previously. We label our observed test statistic (the one from the original data set) as <em>T</em><sub>obs</sub>=<span style="text-decoration: overline">x</span><sub><em>Unattractive</em></sub>&#8722;<span style="text-decoration: overline">x</span><sub><em>Average</sub></em> which happened to be 1.84 years here. We will compare this result to the results for the test statistic that we obtain from permuting the group labels. To denote permuted results, we will add a * to the labels:\r\n <em>T</em><sup>*</sup>=<span style="text-decoration: overline">x</span><sub><em>Unattractive*</em></sub>&#8722;<span style="text-decoration: overline">x</span><sub><em>Average*</sub></em>. We then compare the <em>T</em><sub>obs</sub>=<span style="text-decoration: overline">x</span><sub><em>Unattractive</em></sub>&#8722;<span style="text-decoration: overline">x</span><sub><em>Average</sub></em>= 1.84 to the distribution of results that are possible for the permuted results (T*) which corresponds to assuming the null hypothesis is true. </p>\r\n<p>To do permutations, we are going to learn how to write a <strong><em>for loop</strong></em> in R to be able to repeatedly generate the permuted data sets and record <em>T</em>*. Loops are a basic programming task that make randomization methods possible as well as potentially simplifying any repetitive computing task. To write a "for loop", we need to choose how many times we want to do the loop (call that B) and decide on a counter to keep track of where we are at in the loops (call that b, which goes from 1 to B). The simplest loop would just involve printing out the index, <span class="code-font">print(b)</span>. This is our first use of curly braces, { and }, that are used to group the code we want to repeatedly run as we proceed through the loop. The code in the script window is:</p>\r\n<p><span class="code-font">for (b in (1:B)){</span></p>\r\n  <p><span class="code-font">print(b)</span></p>\r\n <p><span class="code-font">  }</span><p/>\r\n<p>And when you highlight and run the code, it will look about the same with "+" printed after the first line to indicate that all the code is connected, looking like this:</p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   print(b)</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p>When you run these three lines of code, the console will show you the following output:</p>\r\n <table class="code-font code">\r\n<tr>\r\n<td align="right">[1]</td>\r\n    <td align="right">1</td>\r\n</tr>\r\n<tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">2</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">3</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">4</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">5</td>\r\n  </tr>\r\n</table>\r\n<p>This is basically the result of running the <span class="code-font">print</span> function on <span class="code-font">b</span> as it has values from 1 to 5.</p>\r\n<p>Instead of printing the counter, we want to use the loop to repeatedly compute our test statistic when permuting observations. The <span class="code-font">shuffle</span> function will perform permutations of the group labels relative to responses and the compareMean function will calculate the difference in two group means. For a single permutation, the combination of shuffling <span class="code-font">Attr</span> and finding the difference in the means, storing it in a variable called <span class="code-font">T</span>s is:</p>\r\n<p><span class="code blue code-font">> Ts<-compareMean(Years ~ shuffle(Attr), data=MockJury2)</span></p>\r\n<p><span class="code blue code-font">> Ts</span></p>\r\n<p><span class="code blue code-font">[1] 0.3968706</span></p>\r\n<p>And putting this inside the print function allows us to find the test statistic under 5 different permutations easily:</p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Ts<-compareMean(Years ~ shuffle(Attr), data=MockJury2)</span></p>\r\n<p><span class="code blue code-font">+   print(Ts)</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">[1]</td>\r\n    <td align="right">0.9302987</td>\r\n</tr>\r\n<tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">0.6635846</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">0.7702703</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">-1.203414</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[1]</td>\r\n    <td align="right">-0.7766714</td>\r\n  </tr>\r\n</table>\r\n<p>Finally, we would like to store the values of the test statistic instead of just printing them out on each pass through the loop. To do this, we need to create a variable to store the results, let''s call it <span class="code-font">Tstar</span>. We know that we need to store B results so will create a vector of length B, containing B elements, full of missing values (NA) using the <span class="code-font">matrix</span> function:</p>\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> Tstar</span></p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">   </td>\r\n    <td align="right">[,1]</td>\r\n</tr>\r\n<tr>\r\n<td align="right">[1,]</td>\r\n    <td align="right">NA</td>\r\n</tr>\r\n<tr>\r\n  <td align="right">[2,]</td>\r\n    <td align="right">NA</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[3,]</td>\r\n    <td align="right">NA</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[4,]</td>\r\n    <td align="right">NA</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[5,]</td>\r\n    <td align="right">NA</td>\r\n  </tr>\r\n</table>\r\n<p>Now we can run our loop B times and store the results in <span class="code-font">Tstar</span>:</p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-compareMean(Years ~ shuffle(Attr), data=MockJury2)</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p><span class="code blue code-font">> Tstar</span></p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">   </td>\r\n    <td align="right">[,1]</td>\r\n</tr>\r\n<tr>\r\n<td align="right">[1,]</td>\r\n    <td align="right">1.1436700</td>\r\n</tr>\r\n<tr>\r\n  <td align="right">[2,]</td>\r\n    <td align="right">-0.7233286</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[3,]</td>\r\n    <td align="right">1.3036984</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[4,]</td>\r\n    <td align="right">-1.1500711</td>\r\n  </tr>\r\n  <tr>\r\n  <td align="right">[5,]</td>\r\n    <td align="right">-1.0433855</td>\r\n  </tr>\r\n</table>\r\n<p>The <span class="code-font">Tstar</span> vector when we set B to be large, say <em>B</em>=1,000, generate the permutation distribution for the selected test statistic under<sup><a id="14top" href="#14ft">14</a></sup>the null hypothesis - what is called the <strong><em>null distribution</strong></em> of the statistic and also its <strong><em>sampling distribution</strong></em>. We want to visualize this distribution and use it to assess how unusual our <em>T</em><sub>obs</sub> result of 1.84 years was relative to all the possibilities under permutations (under the null hypothesis). So we repeat the loop, now with B=1000 and generate a histogram, density curve and summary statistics of the results:</p>\r\n<p><span class="code blue code-font">> B<-1000</span></p>\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-compareMean(Years ~ shuffle(Attr), data=MockJury2)</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> favstats(Tstar)</span></p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">min</td>\r\n    <td align="right">Q1</td>\r\n<td align="right">median</td>\r\n    <td align="right">Q3</td>\r\n  <td align="right">max</td>\r\n    <td align="right">mean</td>\r\n  <td align="right">sd</td>\r\n    <td align="right">n</td>\r\n    <td align="right">missing</td>\r\n	</tr>\r\n	<tr>\r\n    <td align="right">-2.536984</td>\r\n  <td align="right">-0.5633001</td>\r\n    <td align="right">0.02347084</td>\r\n	<td align="right">0.6102418</td>\r\n    <td align="right">2.903983</td>\r\n<td align="right">0.01829659</td>\r\n    <td align="right">0.8625767</td>\r\n  <td align="right">1000</td>\r\n    <td align="right">0</td>\r\n  </tr>\r\n</table>\r\n<p>Figure 1-9 contains visualizations of the results for the distribution of <em>T*</em> and the favstats summary provides the related numerical summaries. Our observed <em>T</em><sub>obs</sub> of 1.837 seems fairly unusual relative to these results with only 11 <em>T</em>* values over 2 based on the histogram. We need to make more specific assessments of the permuted results versus our observed result to be able to clearly decide whether our observed result is really unusual.</p>\r\n<figure>\r\n<img src="../meta/img/Figure1.9.jpg" alt="Figure1.9">\r\n<figcaption><em>Figure 1-9: Histogram (with counts in bars) and density curve of values of test statistic for 1,000 permutations.</em></figcaption>\r\n</figure>\r\n<p>We can enhance the previous graphs by adding the value of the test statistic from the real data set, as shown in Figure 1-10, using the <span class="code-font">abline</span> function.</p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,lwd=2,col="red")</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,lwd=2,col="red")</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.10.jpg" alt="Figure1.10">\r\n<figcaption><em>Figure 1-10: Histogram and density curve of values of test statistic for 1,000 permutations with bold line for value of observed test statistic.</em></figcaption>\r\n</figure>\r\n<p>Second, we can calculate the exact number of permuted results that were larger than what we observed. To calculate the proportion of the 1,000 values that were larger than what we observed, we will use the pdata function. To use this function, we need to provide the cut-off point (<span class="code-font">Tobs</span>), the distribution of values to compare to the cut-off (<span class="code-font">Tstar</span>), and whether we want the lower or upper tail of the distribution (<span class="code-font">lower.tail=F</span> option provides the proportion of values above).</p> \r\n<p><span class="code blue code-font">> pdata(Tobs,Tstar,lower.tail=F)</span></p>\r\n<p><span class="code code-font">[1] 0.016</span></p>\r\n<p>The proportion of 0.016 tells us that 16 of the 1,000 permuted results (1.6%) were larger than what we observed. This type of work is how we can generate <strong><em>p-values</strong></em> using permutation distributions. P-values are the probability of getting a result as extreme or more extreme than what we observed, <u>given that the null is true</u>. Finding only 16 permutations of 1,000 that were larger than our observed result suggests that it is hard to find a result like what we observed if there really were no difference, although it is not impossible.</p> \r\n<p>When testing hypotheses for two groups, there are two types of alternative hypotheses, one-sided or two-sided. <strong><em>One-sided tests</strong></em> involve only considering differences in one-direction (like &#956;<sub>1</sub>>&#956;<sub>2</sub>) and are performed when researchers can decide <strong><em>a priori</strong></em><sup><a id="15top" href="#15ft">15</a></sup> which group should have a larger mean. We did not know enough about the potential impacts of the pictures to know which group should be larger than the other and without much knowledge we could have gotten the direction wrong relative to the observed results and we can''t look at the responses to decide on the hypotheses. It is often safer and more <strong><em>conservative</strong></em><sup><a id="16top" href="#16ft">16</a></sup> to start with a <strong><em>two-sided alternative</strong></em> (H<sub>A</sub>: &#956;<sub>1</sub>&#8800;&#956;<sub>2</sub>). To do a 2-sided test, find the area larger than what we observed as above. We also need to add the area in the other tail (here the left tail) similar to what we observed in the right tail. Here we need to also find how many of the permuted results were smaller than -1.84 years, using <span class="code-font">pdata</span> with <span class="code-font">-Tobs</span> as the cut-off and <span class=" code-font">lower.tail=T</span>:</p>\r\n<p><span class="code blue code-font">> pdata(-Tobs,Tstar,lower.tail=T)</span></p>\r\n<p><span class="code code-font">[1] 0.015</span></p>\r\n<p>So the p-value to test our null hypothesis of no difference in the true means between the groups is 0.016+0.015, providing a p-value of 0.031. Figure 1-11 shows both cut-offs on the histogram and density curve.</p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> abline(v=c(-1,1)*Tobs,lwd=2,col="red")</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=c(-1,1)*Tobs,lwd=2,col="red")</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.11.jpg" alt="Figure1.11">\r\n<figcaption><em>Figure 1-11: Histogram and density curve of values of test statistic for 1,000 permutations with bold lines for value of observed test statistic and its opposite value required for performing two-sided test.</em></figcaption>\r\n</figure>\r\n<p>In general, the one-sided test p-value is the proportion of the permuted results that are more extreme than observed in the direction of the alternative hypothesis (lower or upper tail, which also depends on the direction of the difference taken). For the 2-sided test, the p-value is the proportion of the permuted results that are less than the negative version of the observed statistic and greater than the positive version of the observed statistic. Using absolute values, we can simplify this: the two-sided p-value is the proportion of the <em>|permuted statistics|</em> that are larger than <em>|observed statistic|</em>. This will always work and finds areas in both tails regardless of whether the observed statistic is positive or negative. In R, the <span class="code-font">abs</span> function provides the <strong>absolute value</strong> and we can again use <span class="code-font">pdata</span> to find our p-value:</p>\r\n<p><span class="code blue code-font">> pdata(abs(Tobs),abs(Tstar),lower.tail=F)</span></p>\r\n<p><span class="code code-font">[1] 0.031</span></p>\r\n<p>We will discuss the choice of significance level below, but for the moment, assume a <strong><em>significance level</strong></em> (&#945;) of 0.05. Since the p-value is smaller than &#945;, this suggests that we can <strong><em>reject the null hypothesis</strong></em> and conclude that there is evidence of some difference in the true mean sentences given between the two types of pictures.</p> \r\n<p>Before we move on, let''s note some interesting features of the permutation distribution of the difference in the sample means shown in Figure 1-11.</p>\r\n	\r\n	<li>1)  It is basically centered at 0. Since we are performing permutations assuming the null model is true, we are assuming that &#956;<sub>1</sub>=&#956;<sub>2</sub> which implies that &#956;<sub>1</sub>&#8722;&#956;<sub>2</sub>= 0 and 0 is always the center of the permutation distribution.</li>\r\n	<li>2)  It is approximately normally distributed. This is due to the <strong><em>Central Limit Theorem</strong></em><sup><a id="17top" href="#17ft">17</a></sup>, where the sampling distribution of the difference in the sample means (<span style="text-decoration: overline">x</span><sub>1</sub>-<span style="text-decoration: overline">x</span><sub>2</sub>) will be approximately normal if the sample sizes are large enough. This result will allow us to use a parametric method to approximate this distribution under the null model if some assumptions are met, as we''ll discuss below.</li>\r\n	<li>3)  Our observed difference in the sample means (1.84 years) is a fairly unusual result relative to the rest of these results but there are some permuted data sets that produce more extreme differences in the sample means. When the observed differences are really large, we may not see any permuted results that are as extreme as what we observed. When pdata gives you 0, the p-value should be reported to be smaller than 0.001 (<strong><em>not 0!</strong></em>) since it happened in less than 1 in 1000 tries.</li>\r\n	<li>4)  Since our null model is not specific about the direction of the difference, considering a result like ours but in the other direction (-1.84 years) needs to be included. The observed result seems to put about the same area in both tails of the distribution but it is not exactly the same. The small difference in the tails is a useful aspect of this approach compared to the parametric method discussed below as it accounts for slight asymmetry in the sampling distribution.</li>\r\n\r\n<p>Earlier, we decided that the p-value was small enough to reject the null hypothesis since it was smaller than our chosen level of significance. In this course, you will often be allowed to use your own judgement about an appropriate significance level in a particular situation (in other words, if we forget to tell you an &#945;-level, you can still make a decision using a reasonably selected significance level). Remembering that the p-value is the probability you would observe a result like you did (or more extreme), assuming the null hypothesis is true, this tells you that the smaller the p-value is, the more evidence you have against the null. The next section provides a more formal review of the hypothesis testing infrastructure, terminology, and some of things that can happen when testing hypotheses.</p>', '<p><sup><a id="14ft" href="#14top">14</a></sup>We often say "under" in statistics and we mean "given that the following is true".</p>\r\n<p><sup><a id="15ft" href="#15top">15</a></sup>This is a fancy way of saying "in advance", here in advance of seeing the observations.</p>\r\n<p><sup><a id="16ft" href="#16top">16</a></sup>Statistically, a conservative method is one that provides less chance of rejecting the null hypothesis in comparison to some other method or some pre-defined standard.</p>\r\n<p><sup><a id="17ft" href="#17top">17</a></sup>We''ll leave the discussion of the CLT to your previous stat coursework or an internet search.</p>', 'Chapter 1', '1.005', '1.3', 'Textbook', 'Textbook', 'Permutation', NULL, NULL, NULL, NULL, NULL, '2015-09-16 16:53:16', NULL, NULL, NULL, NULL),
(46, 'Hypothesis testing (general)', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In hypothesis testing, it is formulated to answer a specific question about a population or ture parameter(s) using a statistic based on a data set. In your previous statistics course, you (hopefully) considered one-sample hypotheses about population means and proportions and the two sample mean situation we are focused on here. Our hypotheses relate to trying to answer the question about whether the population mean sentences between the two groups are different, with an initial assumption of no difference.</p> \r\n<p>Hypothesis testing is much like a criminal trial where you are in the role of a jury member (or judge if no jury is present). Initially, the defendant is assumed innocent. In our situation, the true means are assumed to be equal between the groups. Then evidence is presented and, as a juror, you analyze it. In statistical hypothesis testing, data are collected and analyzed. Then you have to decide if we had "enough" evidence to reject the initial assumption ("innocence" is initially assumed). To make this decision, you want to have previously decided on the standard of evidence required to reject the initial assumption. In criminal cases, "beyond a reasonable doubt" is used. Wikipedia''s definition suggests that this standard is that "there can still be a doubt, but only to the extent that it would not affect a reasonable person''s belief regarding whether or not the defendant is guilty". In civil trials, a lower standard called a "preponderance of evidence" is used. Based on that defined and pre-decided (<em>a priori</em>) measure, you decide that the defendant is guilty or not guilty. In statistics, we compare our p-value to a significance level, &#945;, which is most often 5%. If our p-value is less than &#945;, we reject the null hypothesis. The choice of the significance level is like the variation in standards of evidence between criminal and civil trials - and in all situations everyone should know the standards required for rejecting the initial assumption before any information is "analyzed". Once someone is found guilty, then there is the matter of sentencing which is related to the impacts ("size") of the crime. In statistics, this is similar to the estimated size of differences and the related judgements about whether the differences are practically important or not. If the crime is proven beyond a reasonable doubt but it is a minor crime, then the sentence will be small. With the same level of evidence and a more serious crime, the sentence will be more dramatic.</p> \r\n<p>There are some important aspects of the testing process to note that inform how we interpret statistical hypothesis test results. When someone is found "not guilty", it does not mean "innocent", it just means that there was not enough evidence to find the person guilty "beyond a reasonable doubt". Not finding enough evidence to reject the null hypothesis does not imply that the true means are equal, just that there was not enough evidence to conclude that they were different. There are many potential reasons why we might fail to reject the null, but the most common one is that our sample size was too small (which is related to having too little evidence).</p> \r\n<p>Throughout the semester, we will continue to re-iterate the distinctions between parameters and statistics and want you to be clear about the distinctions between estimates based on the sample and inferences for the population or true values of the parameters of interest. Remember that statistics are summaries of the sample information and parameters are characteristics of populations (which we rarely know). In the two-sample mean situation, the sample means are always at least a little different - that is not an interesting conclusion. What is interesting is whether we have enough evidence to prove that the population means differ "beyond a reasonable doubt".</p>\r\n<p>The scope of any inferences is constrained based on whether there is a <strong><em>random sample</strong></em> (RS) and/or <strong><em>random assignment</strong></em> (RA). Table 1-1 contains the four possible combinations of these two characteristics of a given study. Random assignment allows for causal inferences for differences that are observed - the different in treatment levels causes differences in the mean responses. Random sampling (or at least some sort of representative sample) allows inferences to be made to the population of interest. If we do not have RA, then causal inferences cannot be made. If we do not have a representative sample, then our inferences are limited to the sampled subjects.</p>\r\n<p>A simple example helps to clarify how the scope of inference can change. Suppose we are interested in studying the GPA of students and have a sample mean GPA and a confidence interval for the population mean GPA available. If we had taken a random sample from, say, the STAT 217 students in a given semester, our scope of inference would be the population of 217 students in that semester. If we had taken a random sample from the entire MSU population, then the inferences would be to the entire MSU population in that semester. These are similar types of problems but the two populations are very different and the group you are trying to make conclusions about should be noted carefully in your results - it does matter! If we did not have a representative sample, say the students could choose to provide this information or not, then we can only make inferences to volunteers. These volunteers might differ in systematic ways from the entire population of STAT 217 students so we cannot safely extend our inferences beyond the group that volunteered.</p> \r\n<table class="border">\r\n<caption><em>Table 1-1: Scope of inference summary.</em></caption>\r\n<tr>\r\n<td><strong>Random Sampling/Random Assignment</strong></td>\r\n<td><strong>Random Assignment (RA) - Yes\r\n(controlled experiment)\r\n</strong></td>\r\n<td><strong>Random Assignment (RA) - No\r\n(observational study)\r\n</strong></td>\r\n</tr>\r\n<tr>\r\n<td><strong>Random Sampling (RS) - Yes\r\n(or some method that results in a representative sample of population of interest)\r\n</strong></td>\r\n<td>Because we have RS, we can generalize inferences to the population the RS was taken from. Because we have RA we can assume the groups were equivalent on all aspects except for the treatment and can establish causal inference.</td>\r\n<td>Can generalize inference to population RS was taken from but cannot establish causal inference (no RA - cannot isolate treatment variable as only difference among groups, could be confounding variables). </td>\r\n</tr>\r\n<tr>\r\n<td><strong>Random Sampling (RS) - No \r\n(usually a convenience sample )\r\n</strong></td>\r\n<td>Cannot generalize inference to the population of interest because the sample was not random and could be biased - may not be "representative" of the population of interest. Can establish causal inference due to RA &#8594; the inference from this type of study applies only to the sample.</td>\r\n<td>Cannot generalize inference to the population of interest because the sample was not random and could be biased - may not be "representative" of the population of interest. Cannot establish causal inference due to lack of RA of the treatment.</td>\r\n</tr>\r\n</table>\r\n<p>To consider the impacts of RA versus observational studies, we need to be comparing groups. Suppose that we are interested in differences in the mean GPAs for different sections of STAT 217 and that we take a random sample of students from each section and compare the results and find evidence of some difference. In this scenario, we can conclude that there is some difference in the population of STAT 217 students but we can''t say that being in different sections caused the differences in the mean GPAs. Now suppose that we randomly assigned every 217 student to get extra training in one of three different study techniques and found evidence of differences among the training methods. We could conclude that the training methods caused the differences in these students. These conclusions would only apply to STAT 217 students and could not be generalized to a larger population of students. If we took a random sample of STAT 217 students (say only 10 from each section) and then randomly assigned them to one of three training programs. If evidence of differences is found, then we can say that the training programs caused the differences and we can say that we have evidence that those differences pertain to the population of STAT 217 students. This seems similar to the scenario where all 217 students participated in the training programs except that by using random sampling, only a fraction of the population needs to actually be studied to make inferences to the entire population of interest - saving time and money.</p>  \r\n<p>A quick summary of the terminology of hypothesis testing is useful at this point. The null hypothesis (H<sub>0</sub>) states that there is no difference or no relationship in the population. This is the statement of no effect or no difference and the claim that we are trying to find evidence against. In this chapter, it is always H<sub>0</sub>: &#956;<sub>1</sub> = &#956;<sub>2</sub>. When doing two-group problems, you always need to specify which group is 1 and which is 2. The alternative hypothesis (H<sub>1</sub> or H<sub>A</sub>) states a specific difference between parameters. This is the research hypothesis and the claim about the population that we hope to demonstrate is more reasonable to conclude than the null hypothesis. In the two-group situation, we can have one-sided alternatives of H<sub>A</sub>: &#956;<sub>1</sub> > &#956;<sub>2</sub> (greater than) or H<sub>A</sub>: &#956;<sub>1</sub> < &#956;<sub>2</sub> (less than) or, the more common, two-sided alternative of H<sub>A</sub>: &#956;<sub>1</sub> &#8800; &#956;<sub>2</sub> (not equal to). We usually default to using two-sided tests because we often do not know enough to know the direction of a difference in advance, especially in more complicated situations. The sampling distribution is the distribution of a statistic under the assumption that H<sub>0</sub> is true and is used to calculate the <strong><em>p-value</strong></em>, the probability of obtaining a result as extreme or more extreme than what we observed given that the null hypothesis is true. We will find sampling distributions using <strong><em>nonparametric</strong></em> approaches (like the permutation approach used above) and <strong><em>parametric methods</strong></em> (using "named" distributions like the <em>t</em>, F, and &#967;<sup>2</sup>).</p> \r\n<p>Small p-values are evidence against the null hypothesis because the the observed result is unlikely due to chance if H<sub>0</sub> is true. Large p-values provide no evidence against H<sub>0</sub> but do not allow us to conclude that there is no difference. The <strong><em>level of significance</strong></em> is an a priori definition of how small the p-value needs to be to provide "enough" (sufficient) evidence against H<sub>0</sub>. This is most useful to prevent sliding the standards after the results are found. We compare the p-value to the level of significance to decide if the p-value is small enough to constitute sufficient evidence to reject the null hypothesis. We use a to denote the level of significance and most typically use 0.05 which we refer to as the 5% significance level. We compare the p-value to this level and make a decision. The two options for decisions are to either reject the <em>null hypothesis</em> if the p-value &#8804; &#945; or fail to reject the null hypothesis if the p-value > &#945;. When interpreting hypothesis testing results, remember that the p-value is a measure of how unlikely the observed outcome was, assuming that the null hypothesis is true. It is <strong>NOT</strong> the probability of the data or the probability of either hypothesis being true. The p-value is a measure of evidence against the null hypothesis.</p> \r\n<p>The specific definition of a is that it is the probability of rejecting H<sub>0</sub> when H<sub>0</sub> is true, the probability of what is called a <strong><em>Type I error</strong></em>. Type I errors are also called <strong><em>false rejections</strong></em>. In the two-group mean situation, a Type I error would be concluding that there is a difference in the true means between the groups when none really exists in the population. In the courtroom setting, this is like falsely finding someone guilty. We don''t want to do this very often, so we use small values of the significance level, allowing us to control the rate of Type of I errors at &#945;. We also have to worry about <strong><em>Type II errors</strong></em>, which are failing to reject the null hypothesis when it''s false. In a courtroom, this is the same as failing to convict a guilty person. This most often occurs due to a lack of evidence. You can use the Table 1-2 to help you remember all the possibilities.</p> \r\n<table class="border">\r\n<caption><em>Table 1-2: Table of decisions and truth scenarios in a hypothesis testing situation. We never know the truth in a real situation.</em></caption>\r\n<tr>\r\n<td>  </td>\r\n<td><strong>H<sub>0</sub> True</strong></td>\r\n<td><strong>H<sub>0</sub> False</strong></td>\r\n</tr>\r\n<tr>\r\n<td><strong>FTR H<sub>0</sub></strong></td>\r\n<td>Correct decision</td>\r\n<td>Type II error</td>\r\n</tr>\r\n<tr>\r\n<td><strong>Reject H<sub>0</sub></strong></td>\r\n<td>Type I error</td>\r\n<td>Correct decision</td>\r\n</tr>\r\n</table>\r\n<p>In comparing different procedures, there is an interest in studying the rate or probability of Type I and II errors. The probability of a Type I error was defined previously as &#945;, the significance level. The <em>power</em> of a procedure is the probability of rejecting the null hypothesis when it is false. Power is defined as power = 1 - Probability(Type II error) = Probability(Reject H<sub>0</sub> | H<sub>0</sub> is false), or, in words, the probability of detecting a difference when it actually exists. We want to use a statistical procedure that controls the Type I error rate at the pre-specified level and has high power to detect false null alternatives. Increasing the sample size is one of the most commonly used methods for increasing the power in a given situation but sometimes we can choose among different procedures and use the power of the procedures to help us make that selection. Note that there are many ways to make H<sub>0</sub> false and the power changes based on how false the null hypothesis actually is. To make this concrete, suppose that the true mean sentences differed by either 1 or 20 years in previous example. The chances of rejecting the null hypothesis are much larger when the groups actually differ by 20 years than if they differ by just 1 year. </p>\r\n<p>After making a decision (was there enough evidence to reject the null or not), we want to make the conclusions specific to the problem of interest. If we reject H<sub>0</sub>, then we can conclude that there was sufficient evidence at the &#945;-level that the null hypothesis is wrong (and the results point in the direction of the alternative). If we fail to reject H<sub>0</sub> (FTR H<sub>0</sub>), then we can conclude that there was insufficient evidence at the &#945;-level to say that the null hypothesis is wrong. We are <strong>NOT</strong> saying that the null is correct and we <strong>NEVER</strong> accept the null hypothesis. We just failed to find enough evidence to say it''s wrong. If we find sufficient evidence to reject the null, then we need to revisit the method of data collection and design of the study. This allows us to consider the scope of the inferences we can make. Can we discuss causality (due to RA) and/or make inferences to a larger group than those in the sample (due to RS)?</p> \r\n<p>To perform a hypothesis test, there are some steps to remember to complete to make sure you have thought through all the aspects of the results.</p> \r\n<strong>Outline of 6+ steps to perform a Hypothesis Test</strong>\r\n	<p>Isolate the claim to be proved, method to use (define a test statistic T), and significance level</p>\r\n	<p>1) Write the null and alternative hypotheses</p>\r\n	<p>2) Assess the "Things To Check" for the procedure being used (discussed below)</p>\r\n	<p>3) Find the value of the appropriate test statistic</p>\r\n	<p>4) Find the p-value</p>\r\n	<p>5) Make a decision</p>\r\n	<p>6) Write a conclusion specific to the problem, including scope of inference discussion</p>', NULL, 'Chapter 1', '1.006', '1.4', 'Textbook', 'Textbook', 'Statistical hypothesis testing', NULL, NULL, NULL, NULL, NULL, '2015-09-15 17:17:58', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(47, 'Connecting randomization (nonparametric) and parametric tests', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In developing statistical inference techniques, we need to define the test statistic, <em>T</em>, that measures the quantity of interest. To compare the means of two groups, a statistic is needed that measures their differences. In general, for comparing two groups, the choices are simple - a difference in the means often works well and is a natural choice. There are other options such as tracking the ratio of means or possibly the difference in medians. Instead of just using the difference in the means, we could "standardize" the difference in the means by dividing by an appropriate quantity. It ends up that there are many possibilities for testing using the randomization (nonparametric) techniques introduced previously. Parametric statistical methods focus on means because the statistical theory surrounding means is quite a bit easier (not easy, just easier) than other options. Randomization techniques allow inference for other quantities but our focus here will be on using randomization for inferences on means to see the similarities with the more traditional parametric procedures. </p>\r\n<p>In two-sample mean situations, instead of working with the difference in the means, we often calculate a test statistic that is called the <em><strong>equal variance two-independent samples t-statistic</em></strong>. The test statistic is</p>\r\n<figure>\r\n<img src="../meta/img/Equation1.1.jpg" alt="Equation1.1">\r\n</figure>\r\n<p>where s<sub>1</sub><sup>2</sup> and s<sub>2</sub><sup>2</sup> are the sample variances for the two groups, n<sub>1</sub> and n<sub>2</sub> are the sample sizes for the two groups, and the <em><strong>pooled sample standard devation</em></strong>,</p>\r\n<figure>\r\n<img src="../meta/img/Equation1.2.jpg" alt="Equation1.2">\r\n</figure>\r\n<p>The t-statistic keeps the important comparison between the means in the numerator that we used before and standardizes (re-scales) that difference so that t will follow a t-distribution (a parametric "named" distribution) if certain assumptions are met. But first we should see if standardizing the difference in the means had an impact on our permutation test results. Instead of using the <span class="code-font">compareMean</span> function, we will use the <span class="code-font">t.test</span> function (see its full use below) and have it calculate the formula for t for us. The R code <span class="code-font">"$statistic"</span> is basically a way of extracting just the number we want to use for <em>T</em> from a larger set of output the <span class="code-font">t.test</span> function wants to provide you. We will see below that <span class="code-font">t.test</span> switches the order of the difference (now it is <em>Average - Unattractive</em>) - always carefully check for the direction of the difference in the results. Since we are doing a two-sided test, the code resembles the permutation test code in Section 1.3 with the new t-statistic replacing the difference in the sample means.</p>\r\n<p>The permutation distribution in Figure 1-12 looks similar to the previous results with slightly different x-axis scaling. The observed t-statistic was -2.17 and the proportion of permuted results that were more extreme than the observed result was 0.034. This difference is due to a different set of random permutations being selected. If you run permutation code, you will often get slightly different results each time you run it. If you are uncomfortable with the variation in the results, you can run more than <em>B</em>=1,000 permutations (say 10,000) and the variability will be reduced further. Usually this uncertainty will not cause any substantive problems - but do not be surprised if your results vary from a colleagues if you are both analyzing the same data set.</p>\r\n<p><span class="code blue code-font">> Tobs <- t.test(Years ~ Attr, data=MockJury2,var.equal=T)$statistic</span></p>\r\n<p><span class="code blue code-font">> Tobs</span></p>\r\n<p><span class="code code-font">      t </span></p>\r\n<p><span class="code code-font">-2.17023 </span></p>\r\n\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-t.test(Years ~ shuffle(Attr), data=MockJury2,var.equal=T)$statistic</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> abline(v=c(-1,1)*Tobs,lwd=2,col="red")</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=c(-1,1)*Tobs,lwd=2,col="red")</span></p>\r\n<p><span class="code blue code-font">> </span></p>\r\n<p><span class="code blue code-font">> pdata(abs(Tobs),abs(Tstar),lower.tail=F)</span></p>\r\n<p><span class="code code-font">    t </span></p>\r\n<p><span class="code code-font">0.034</span></p>\r\n \r\n<figure>\r\n<img src="../meta/img/Figure1.12.jpg" alt="Figure1.12">\r\n<figcaption><em>Figure 1-12: Permutation distribution of the t-statistic.</em></figcaption>\r\n</figure> \r\n\r\n<p>The parametric version of these results is based on using what is called the two-independent sample t-test. There are actually two versions of this test, one that assumes that variances are equal in the groups and one that does not. There is a rule of thumb that if the ratio of the larger standard deviation over the smaller standard deviation is less than 2, the equal variance procedure is ok. It ends up that this assumption is less important if the sample sizes in the groups are approximately equal and more important if the groups contain different numbers of observations. In comparing the two potential test statistics, the procedure that assumes equal variances has a complicated denominator (see the formula above for  <em>t</em> involving <em>s<sub>p</sub></em>) but a simple formula for degrees of freedom (<em>df</em>) for the t-distribution (<em>df</em>=n<sub>1</sub>+n<sub>2</sub>&#8722;2) that approximates the distribution of the test statistic, <em>t</em>, under the null hypothesis. The procedure that assumes unequal variances has a simpler test statistic and a very complicated degrees of freedom formula. The equal variance procedure is most similar to the ANOVA methods we will consider later this semester so that will be our focus here. Fortunately, both of these methods are readily available in the t.test function in R if needed.</p>\r\n<p>If the assumptions for the equal variance t-test are met and the null hypothesis is true, then the sampling distribution of the test statistic should follow a t-distribution with n<sub>1</sub>+n<sub>2</sub>&#8722;2 degrees of freedom. The t-distribution is a bell-shaped curve that is more spread out for smaller values of degrees of freedom as shown in Figure 1-13. The <em>t</em>-distribution looks more and more like a standard normal distribution (N(0,1)) as the degrees of freedom increase.</p> \r\n \r\n<figure>\r\n<img src="../meta/img/Figure1.13.jpg" alt="Figure1.13">\r\n<figcaption><em>Figure 1-13: Plots of t and normal distributions.</em></figcaption>\r\n</figure>\r\n\r\n<p>To get the p-value from the parametric <em>t</em>-test, we need to calculate the test statistic and <em>df</em>, then look up the areas in the tails of the t-distribution relative to the observed t-statistic. We''ll learn how to use R to do this below, but for now we will allow the <span class="code-font">t.test</span> function to take care of this for us. The t.test function uses our formula notation (<span class="code-font">Years ~ Attr</span>) and then <span class="code-font">data=</span>... as we saw before for making plots. To get the equal-variance test result, the <span class="code-font">var.equal=T</span> option needs to be turned on. Then <span class="code-font">t.test</span> provides us with lots of useful output. We highlighted the three results we''ve been discussing - the test statistic value (-2.17), <em>df</em>=73, and the p-value, from the t-distribution with 73 degrees of freedom, of 0.033. </p>\r\n<p><span class="code blue code-font">> t.test(Years ~ Attr, data=MockJury2,var.equal=T)\r\n<p><span class="code code-font">	Two Sample t-test</span></p>\r\n<p><span class="code code-font">data:  Years by Attr</span></p>\r\n<p><strong><span class="code code-font">t = -2.1702, df = 73, p-value = 0.03324</span></strong></p>\r\n<p><span class="code code-font">alternative hypothesis: true difference in means is not equal to 0</span></p>\r\n<p><span class="code code-font">95 percent confidence interval:</span></p>\r\n<p><span class="code code-font"> -3.5242237 -0.1500295</span></p>\r\n<p><span class="code code-font">sample estimates:</span></p>\r\n    <table class="code">\r\n<tr>\r\n<th>mean in group Average</th> <th>mean in group Unattractive </th></tr>\r\n<tr><th align="right">3.973684 </th> <th align="right">5.810811 </th></tr>\r\n</table>\r\n\r\n<p>So the parametric <em>t</em>-test gives a p-value of 0.033 from a test statistic of -2.1702. The negative sign on the statistic occurred because the function took <em>Average - Unattractive</em> which is the opposite direction as <span class="code-font">compareMeans</span>. The p-value is very similar to the two permutation results found before. The reason for this similarity is that the permutation distribution looks an awful lot like a <em>t</em>-distribution with 73 degrees of freedom. Figure 1-14 shows how similar the two distributions happened to be here.</p> \r\n \r\n<figure>\r\n<img src="../meta/img/Figure1.14.jpg" alt="Figure1.14">\r\n<figcaption><em>Figure 1-14: Plot of permutation and t distribution with df=73.</em></figcaption>\r\n</figure>\r\n\r\n<p>In your previous statistics course, you might have used an applet or a table to find p-values such as what was provided in the previous R output. When not directly provided by a function, we will use R to find p-values <sup><a id="18top" href="#18ft">18</a></sup>  from named distributions such as the t-distribution. In this case, the distribution is a <em>t</em>(73) or a t with 73 degrees of freedom. We will use the pt function to get p-values from the <em>t</em>-distribution in the same manner as we used pdata to find p-values from the permutation distribution. We need to provide the df=... and specify the tail of the distribution of interest using the lower.tail option. If we want the area to the left of -2.17:</p>\r\n<p><span class="code blue code-font">> pt(-2.1702,df=73,lower.tail=T)</span></p>\r\n<p><span class="code code-font">[1] 0.01662286</span></p>\r\n\r\n<p>And we can double it to get the p-value that t.test provided earlier, because the t-distribution is symmetric:</p>\r\n<p><span class="code blue code-font">> 2*pt(-2.1702,df=73,lower.tail=T)</span></p>\r\n<p><span class="code code-font">[1] 0.03324571</span></p>\r\n\r\n<p>More generally, we could always make the test statistic positive using the absolute value, find the area to the right of it, and then double that for a two-side test p-value:</p>\r\n<p><span class="code blue code-font">> 2*pt(abs(-2.1702),df=73,lower.tail=F)</span></p>\r\n<p><span class="code code-font">[1] 0.03324571</span></p>\r\n\r\n	<p>Permutation distributions do not need to match the named parametric distribution to work correctly, although this happened in the previous example. The parametric approach, the t-test, requires the certain conditions to be met for the sampling distribution of the statistic to follow the named distribution and provide accurate p-values. The conditions for the equal variance t-test are:</p>\r\n	<p>1) <strong>Independent observations:</strong> Each observation obtained is unrelated to all other observations. To assess this, consider whether there anything in the data collection might lead to clustered or related observations that are un-related to the differences in the groups. For example, was the same person measured more than once?<sup><a id="19top" href="#19ft">19</a></sup></p>\r\n	<p>2) <strong>Equal variances</strong> in the groups (because we used a procedure that assumes equal variances! - there is another procedure that allows you to relax this assumption if needed...). To assess this, compare the standard deviations and see if they look noticeably different, especially if the sample sizes differ between groups.</p>\r\n	<p>3) <strong>Normal distributions</strong> of the observations in each group. We''ll learn more diagnostics later, but the boxplots and beanplots are a good place to start to help you look for skews or outliers, which were both present here. If you find skew and/or outliers, that would suggest a problem with this condition.</p>\r\n\r\n<p>For the permutation test, we relax the third condition:</p>\r\n	<p>3) <span class="red">Similar distributions between the groups:</span> The permutation approach helps us with this assumption and allows valid inferences as long as the two groups have similar shapes and only possibly differ in their centers. In other words, the distributions need not look normal for the procedure to work well.</p>\r\n\r\n<p>In the mock jury study, we can assume that the independent observation condition is met because there is no information suggesting that the same subjects were measured more than once or that some other type of grouping in the responses was present (like the subjects were divided in groups and placed in the same room discussing their responses). The equal variance condition might be violated although we do get some lee-way in this assumption and are still able to get reasonable results. The standard deviations are 2.8 vs 4.4, so this difference is not "large" according to the rule of thumb. It is, however, close to being considered problematic. It would be difficult to reasonably assume that the the normality condition is met here (Figure 1-6), that is assumed in the derivation of the parametric procedure, with clear right skews in both groups and potential outliers. The shapes look similar for the two groups so there is less reason to be concerned with using the permutation approach as compared to the parametric approach.</p>\r\n	<p>The permutation approach is resistant to impacts of violations of the normality assumption. It is not resistant to impact of violations of any of the other assumptions. In fact, it can be quite sensitive to unequal variances as it will detect differences in the variances of the groups instead of differences in the means. Its scope of inference is limited just like the parametric approach and can lead to similarly inaccurate conclusions in the presence of non-independent observations as for the parametric approach. For our purposes, we hope that seeing the similarity in the methods can help you understand both methods better. In this example, we discover that parametric and permutation approaches provide very similar inferences.</p>', '<p><sup><a id="18ft" href="#18top">18</a></sup>  On exams, you will be asked to describe the area of interest, sketch a picture of the area of interest and/or note the distribution you would use.</p>\r\n<p><sup><a id="19ft" href="#19top">19</a></sup> In some studies, the same subject might be measured in both conditions and this violates the assumptions of this procedure.</p>', 'Chapter 1', '1.007', '1.5', 'Textbook', 'Textbook', 'Resampling (statistics)', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:40:29', NULL, NULL, NULL, NULL),
(48, 'Second example of permutation tests', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In every chapter, we will follow the first example used to explain the methods with a "worked" example where we focus on the results provided. In a previous semester, some of the STAT 217 students (<strong><em>n</strong></em>=79) provided information on their <em>gender</em>, <em>Age</em>, and <em>current GPA</em>. We might be interested in whether Males and Females had different average GPAs. First, we can take a look at the difference in the responses by groups as displayed in Figure 1-15.</p>\r\n<p><span class="code-font code blue">> s217=read.csv( <a href="http://dl.dropboxusercontent.com/u/77307195/s217.csv">http://dl.dropboxusercontent.com/u/77307195/s217.csv</a>)</span></p>\r\n<p><span class="code-font code blue">> require(mosaic)</span></p>\r\n<p><span class="code-font code blue">> par(mfrow=c(1,2))</span></p>\r\n<p><span class="code-font code blue">> boxplot(GPA~Sex,data=s217)</span></p>\r\n<p><span class="code-font code blue">> require(beanplot)</span></p>\r\n<p><span class="code-font code blue">> beanplot(GPA~Sex,data=s217, log="",col="lightblue",method="jitter")</span></p>\r\n<p><span class="code-font code blue">> </span></p>\r\n<p><span class="code-font code blue">> mean(GPA~Sex,data=s217)</span></p>\r\n<table class="code code-font">\r\n<tr>\r\n<td align="right">F</td><td align="right">M</td>\r\n</tr> \r\n<tr>\r\n<td align="right">3.338378</td> <td align="right">3.088571</td>\r\n</tr>\r\n</table> \r\n<p><span class="code-font code blue">> favstats(GPA~Sex,data=s217)</span></p>\r\n<table class="code-font code">\r\n<tr>\r\n<td align="right">  </td>\r\n<td align="right">.group</td>\r\n<td align="right">min</td>\r\n    <td align="right">Q1</td>\r\n<td align="right">median</td>\r\n    <td align="right">Q3</td>\r\n  <td align="right">max</td>\r\n    <td align="right">mean</td>\r\n  <td align="right">sd</td>\r\n    <td align="right">n</td>\r\n    <td align="right">missing</td>\r\n	</tr>\r\n	<tr>\r\n    <td align="right">1</td>\r\n  <td align="right">F</td>\r\n    <td align="right">2.50</td>\r\n	<td align="right">3.1</td>\r\n    <td align="right">3.400</td>\r\n<td align="right">3.70</td>\r\n    <td align="right">4</td>\r\n  <td align="right">3.338378</td>\r\n    <td align="right">0.4074549</td>\r\n	<td align="right">37</td>\r\n	<td align="right">0</td>\r\n  </tr>\r\n  <tr>\r\n    <td align="right">2</td>\r\n  <td align="right">M</td>\r\n    <td align="right">1.96</td>\r\n	<td align="right">2.8</td>\r\n    <td align="right">3.175</td>\r\n<td align="right">3.46</td>\r\n    <td align="right">4</td>\r\n  <td align="right">3.088571</td>\r\n    <td align="right">0.4151789</td>\r\n	<td align="right">42</td>\r\n	<td align="right">0</td>\r\n  </tr>\r\n</table>\r\n<figure>\r\n<img src="../meta/img/Figure1.15.jpg" alt="Figure1.15">\r\n<figcaption><em>Figure 1-15: Side-by-side boxplot and beanplot of GPAs of STAT 217 students by sex.</em></figcaption>\r\n</figure>\r\n<p>In these data, the distributions of the GPAs look to be left skewed but maybe not as dramatically as the responses were right-skewed in the previous example. The Female GPAs look to be slightly higher than for Males (0.25 GPA difference in the means) but is that a "real" difference? We need our inference tools to more fully assess these differences.</p>\r\n<p><span class="code-font code blue">> compareMean(GPA~Sex,data=s217)</span></p>\r\n<p><span class="code-font code">[1] -0.2498069</span></p>\r\n<p>First, we can try the parametric approach:</p>\r\n<p><span class="code-font code blue">> t.test(GPA~Sex,data=s217,var.equal=T)</span></p>\r\n<p><span class="code-font code">&#160;&#160;&#160;Two Sample t-test</span></p>\r\n<p><span class="code-font code">data:  GPA by Sex</span></p>\r\n<p><span class="code-font code">t = 2.6919, df = 77, p-value = 0.008713</span></p>\r\n<p><span class="code-font code">alternative hypothesis: true difference in means is not equal to 0</span></p>\r\n<p><span class="code-font code">95 percent confidence interval:</span></p>\r\n<p><span class="code-font code"> 0.06501838 0.43459552</span></p>\r\n<p><span class="code-font code">sample estimates:</span></p>\r\n<table class="code-font code">\r\n<tr><td align="right">mean in group F</td> <td align="right">mean in group M</td></tr>\r\n<tr><td align="right">3.338378</td><td align="right">3.088571</td></tr></table>\r\n<p>So the test statistic was observed to be <em>t</em>=2.69 and it hopefully follows a <em>t</em>(77) distribution under the null hypothesis. This provides a p-value of 0.008713 that we can trust if all of the conditions are met. We can compare these results to the permutation approach, which relaxes that normality assumption, with the required code and results following. In the permutation test, <em>T</em>=2.692 and the p-value is 0.011 which is a little larger than the result provided by the parametric approach. The agreement of the two approaches provides some re-assurance about the use of either approach.</p>\r\n<p><span class="code-font code blue">> Tobs <- t.test(GPA~Sex,data=s217,var.equal=T)$statistic</span></p>\r\n<p><span class="code-font code blue">> Tobs</span></p>\r\n<p><span class="code-font code">&#160;&#160;t </span></p>\r\n<p><span class="code-font code">2.691883 </span></p>\r\n<p><span class="code-font code blue">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code-font code blue">> for (b in (1:B)){</span></p>\r\n<p><span class="code-font code blue">+   Tstar[b]<-t.test(GPA~shuffle(Sex),data=s217,var.equal=T)$statistic</span></p>\r\n<p><span class="code-font code blue">+   }</span></p>\r\n<p><span class="code-font code blue">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code-font code blue">> abline(v=c(-1,1)*Tobs,lwd=2,col="red")</span></p>\r\n<p><span class="code-font code blue">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code-font code blue">> abline(v=c(-1,1)*Tobs,lwd=2,col="red")</span></p>\r\n<p><span class="code-font code blue">> pdata(abs(Tobs),abs(Tstar),lower.tail=F)</span></p>\r\n<p><span class="code-font code">&#160;&#160;t </span></p>\r\n<p><span class="code-font code">0.011 </span></p>\r\n<figure>\r\n<img src="../meta/img/Figure1.16.jpg" alt="Figure1.16">\r\n<figcaption><em>Figure 1-16: Histogram and density curve of permutation distribution of test statistic for STAT 217 GPAs.</em></figcaption>\r\n</figure>\r\n<p>Here is a full write-up of the results using all 6+ hypothesis testing steps, using the permutation results:</p>\r\n&#160;&#160;&#160;Isolate the claim to be proved and method to use (<em>define a test statistic T</em>)</p>\r\n<p>We want to test for a difference in the means between males and females and will use the equal-variance two-sample t-test statistic to compare them, making a decision at the 5% significance level.</p>\r\n<p>1)	Write the null and alternative hypotheses</p>\r\n<ul>\r\n<li>&#8226;H<sub>0</sub>: &#956;<sub>Male</sub> = &#956;<sub>Female</sub>\r\n<ul>\r\n<li>&#9702;where &#956;<sub>Male</sub> is the true mean GPA for males and &#956;<sub>Female</sub> is true mean GPA for females</li></ul>\r\n<li>&#8226;H<sub>A</sub>: &#956;<sub>Male</sub> &#8800; &#956;<sub>Female</sub></li>\r\n</ul>\r\n<p>	2) Check conditions for the procedure being used</p>\r\n<ul>\r\n<li>&#8226;<strong>Independent observations condition</strong>: It appears that this assumption is met because there is no reason to assume any clustering or grouping of responses that might create dependence in the observations. The only possible consideration is that the observations were taken from different sections and there could be some differences between the sections. However, for overall GPA this not likely to be a big issue. The only way this could create a violation here is if certain sections tended to attract students with different GPA levels (such as the 9 am section had the best/worst GPA students...).</li>\r\n\r\n<li>&#8226;<strong>Equal variance condition</strong>: There is a small difference in the range of the observations in the two groups but the standard deviations are very similar so there is no evidence that this condition is violated.</li>\r\n\r\n<li>&#8226;<strong>Similar distribution condition</strong>: Based on the side-by-side boxplots and beanplots, it appears that both groups have slightly left-skewed distributions which could be problematic for the parametric approach but the permutation approach condition is not violated since the distributions look to have fairly similar shapes.</li>\r\n</ul>\r\n	<p>3) Find the value of the appropriate test statistic</p>\r\n<ul>\r\n<li>&#8226;<em>T</em>=2.69 from the previous R output</li>\r\n</ul>\r\n<p>4) Find the p-value</p>\r\n<ul>\r\n<li>&#8226;p-value=0.012 from the permutation distribution results. </li>\r\n<li>&#8226;This means that there is about a 1.2% chance we would observe a difference in mean GPA (female-male or male-female) of 0.25 points or more if there in fact no difference in true mean GPA between females and males in STAT 217 in a particular semester.</li>\r\n</ul>\r\n	<p>5) Decision</p>\r\n	<ul>\r\n<li>&#8226;Since the p-value is "small" (<em>a priori</em> 5% significance level selected), we can reject the null hypothesis.</li>\r\n</ul>\r\n	<p>6) Conclusion and scope of inference, specific to the problem</p>\r\n	<ul>\r\n<li>&#8226;There is evidence against the null hypothesis of no difference in the true mean GPA between males and females for the STAT 217 students in this semester and so we conclude that there is evidence of a difference in the mean GPAs between males and females.</li>\r\n<li>&#8226;Because this was not a randomized experiment, we can''t say that the difference in sex causes the difference in mean GPA and because it was not a random sample from a larger population, our inferences only pertain the STAT 217 students that responded to the survey in that semester.</li> \r\n</ul>', NULL, 'Chapter 1', '1.008', '1.6', 'Textbook', 'Textbook', 'Permutation', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:40:46', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(49, 'Confidence intervals and bootstrapping', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>Randomly shuffling the treatments between the observations is like randomly sampling the treatments without replacement. In other words, we randomly sample one observation at a time from the treatments until we have n observations. This provides us with a technique for testing hypotheses because it provides a new ordering of the observations that is valid if the null hypothesis is assumed true. In most situations, we also want to estimate parameters of interest and provide confidence intervals for those parameters (an interval where we are __% confident that the true parameter lies). As before, there are two options we will consider - a parametric and a nonparametric approach. The nonparametric approach will be using what is called bootstrapping and draws its name from "pull yourself up by your bootstraps" where you improve your situation based on your own efforts. In statistics, we make our situation or inferences better by re-using the observations we have by assuming that the sample represents the population. Since each observation represents other similar observations in the population, if we sample with replacement from our data set it mimics the process of taking repeated random samples from our population of interest. This process ends up giving us good distributions of statistics even when our standard normality assumption is violated, similar to what we encountered in the permutation tests. Bootstrapping is especially useful in situations where we are interested in statistics other than the mean (say we want a confidence interval for a median or a standard deviation) or when we consider functions of more than one parameter and don''t want to derive the distribution of the statistic (say the difference in two medians). Our uses for bootstrapping will be typically to use it when some of our assumptions (especially normality) might be violated for our regular procedure to provide more trustworthy inferences.</p>\r\n	<p>To perform bootstrapping, we will use the <span class="code-font">resample</span> function from the <span class="code-font">mosaic package</span>. We can apply this function to a data set and get a new version of the data set by sampling new observations with replacement from the original one. The new version of the data set contains a new variable called <span class="code-font">orig.ids</span> which is the number of the subject from the original data set. By summarizing how often each of these id''s occurred in a bootstrapped data set, we can see how the re-sampling works. The code is complicated for unimportant reasons, but the end result is the <span class="code-font">table</span> function providing counts of the number of times each original observation occurred, with the first row containing the observation number and the second row the count. In the first bootstrap sample shown, the 1<sup>st</sup>, 2<sup>nd</sup>, and 4<sup>th</sup> observations were sampled one time each and the 3<sup>rd</sup> observation was not sampled at all. The 5<sup>th</sup> observation was sampled two times. Observation 42 was sampled four times. This helps you understand what types of samples that sampling with replacement can generate.</p>\r\n<p><span class="code blue code-font">> table(as.numeric(resample(MockJury2)$orig.ids))</span></p>\r\n<table class="code code-font">\r\n<tr><td align="right">1</td><td align="right">2</td><td align="right">4</td><td align="right">5</td><td align="right">6</td><td align="right">7</td><td align="right">8</td><td align="right">9</td><td align="right">10</td><td align="right">11</td><td align="right">12</td><td align="right">14</td><td align="right">15</td><td align="right">17</td><td align="right">23</td><td align="right">24</td><td align="right">25</td><td align="right">26</td><td align="right">27</td><td align="right">28</td><td align="right">32</td><td align="right">33</td><td align="right">35</td><td align="right">36</td><td align="right">37</td></tr>\r\n<tr><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">2</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">2</td><td align="right">3</td><td align="right">1</td><td align="right">2</td><td align="right">3</td></tr> \r\n<tr><td align="right">39</td><td align="right">41</td><td align="right">42</td><td align="right">43</td><td align="right">44</td><td align="right">45</td><td align="right">47</td><td align="right">51</td><td align="right">54</td><td align="right">56</td><td align="right">57</td><td align="right">58</td><td align="right">59</td><td align="right">60</td><td align="right">61</td><td align="right">62</td><td align="right">63</td><td align="right">65</td><td align="right">66</td><td align="right">68</td><td align="right">70</td><td align="right">71</td><td align="right">73</td><td align="right">75</td></tr>\r\n<tr><td align="right">1</td><td align="right">2</td><td align="right">4</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">2</td><td align="right">2</td><td align="right">3</td></tr>\r\n</table>\r\n<p>A second bootstrap sample is also provided. It did not re-sample observations 1, 2, or 4 but does sample observation 5 three times. You can see other variations in the resulting re-sampling of subjects.</p> \r\n<p><span class="code blue code-font">> table(as.numeric(resample(MockJury2)$orig.ids))</span></p>\r\n<table class="code code-font">\r\n <tr><td align="right">3</td><td align="right">5</td><td align="right">6</td><td align="right">8</td><td align="right">10</td><td align="right">12</td><td align="right">15</td><td align="right">16</td><td align="right">17</td><td align="right">18</td><td align="right">19</td><td align="right">25</td><td align="right">26</td><td align="right">27</td><td align="right">29</td><td align="right">30</td><td align="right">32</td><td align="right">34</td><td align="right">36</td><td align="right">37</td><td align="right">38</td><td align="right">39</td><td align="right">40</td><td align="right">4</td><td align="right">42</td></tr>\r\n <tr><td align="right">1</td><td align="right">3</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">3</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">2</td><td align="right">1</td><td align="right">2</td><td align="right">2</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">2</td></td>\r\n<tr><td align="right">44</td><td align="right">45</td><td align="right">47</td><td align="right">48</td><td align="right">49</td><td align="right">52</td><td align="right">53</td><td align="right">55</td><td align="right">56</td><td align="right">57</td><td align="right">58</td><td align="right">60</td><td align="right">61</td><td align="right">63</td><td align="right">64</td><td align="right">65</td><td align="right">66</td><td align="right">67</td><td align="right">68</td><td align="right">69</td><td align="right">70</td><td align="right">71</td><td align="right">72</td><td align="right">73</td><td align="right">74</td></tr>\r\n<tr><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">3</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">3</td><td align="right">1</td><td align="right">1</td><td align="right">3</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">1</td><td align="right">2</td><td align="right">2</td><td align="right">2</td></tr>\r\n<tr><td align="right">75</td></tr>\r\n<tr><td align="right">1</td></tr>\r\n</table>\r\n<p>Each run of the <span class="code-font">resample</span> function provides a new version of the data set. Repeating this B times using another for loop, we will track our quantity of interest, say T, in all these new "data sets" and call those results T*. The distribution of the bootstrapped T* statistics will tell us about the range of results to expect for the statistic and the middle __% of the T*''s provides a <strong><em>bootstrap confidence interval</strong></em> for the true parameter - here the <em>difference</em> in the two population means. </p>\r\n<p>To make this concrete, we can revisit our previous examples, starting with the <span class="code-font">MockJury2</span> data created before and our interest in comparing the mean sentences for the <em>Average</em> and <em>Unattractive</em> picture groups. The bootstrapping code is very similar to the permutation code except that we apply the <span class="code-font">resample</span> function to the entire data set as opposed to the <span class="code-font">shuffle</span> function being applied to the explanatory variable. </p>\r\n<p><span class="code blue code-font">> Tobs <- compareMean(Years ~ Attr, data=MockJury2); Tobs</span></p>\r\n<p><span class="code code-font">[1] 1.837127</span></p>\r\n<p><span class="code blue code-font">> B<- 1000</span></p>\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-compareMean(Years ~ Attr, data=resample(MockJury2))</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> favstats(Tstar)</span></p>\r\n<table class="code code-font">\r\n<tr><td align="right">min</td><td align="right">Q1</td>\r\n<td align="right">median</td><td align="right">Q3</td>\r\n<td align="right">max</td><td align="right">mean</td>\r\n<td align="right">sd</td><td align="right">n</td>\r\n<td align="right">missing</td></tr>\r\n<tr><td align="right">-1.252137</td>\r\n<td align="right">1.262018</td><td align="right">1.853615</td>\r\n<td align="right">2.407143</td><td align="right">5.462006</td>\r\n<td align="right">1.839887</td><td align="right">0.8426969</td>\r\n<td align="right">1000</td><td align="right">0</td></tr>\r\n</table>\r\n<p>In this situation, the observed difference in the mean sentences is 1.84 years (Unattractive-Average), which is the vertical line in Figure 1-17. The bootstrap distribution shows the results for the difference in the sample means when fake data sets are re-constructed by sampling from the data set with replacement. The bootstrap distribution is approximately centered at the observed value and relatively symmetric. </p>\r\n<figure>\r\n<img src="../meta/img/Figure1.17.jpg" alt="Figure1.17">\r\n<figcaption><em>Figure 1-17: Histogram and density curve of bootstrap distributions of difference in sample mean Years with vertical line for the observed difference in the means.</em></figcaption>\r\n</figure>\r\n<p>The permutation distribution in the same situation (Figure 1-12) had a similar shape but was centered at 0. Permutations create distributions based on assuming the null hypothesis is true, which is useful for hypothesis testing. Bootstrapping creates distributions centered at the observed result, sort of like distributions under the alternative; bootstrap distributions are useful for generating intervals for the true parameter values. </p>\r\n<p>To create a 95% bootstrap confidence interval for the difference in the true mean sentences (&#956;<sub>Unattr</sub> - &#956;<sub>Ave</sub>), we select the middle 95% of results from the bootstrap distribution. Specifically, we find the 2.5<sup>th</sup> percentile and the 97.5<sup>th</sup> percentile (values that put 2.5 and 97.5% of the results to the left), which leaves 95% in the middle. To find percentiles in a distribution, we will use functions that are <span class="code-font">q[Name of distribution]</span> and from the bootstrap results we will use the <span class="code-font">qdata</span> function on the <span class="code-font">Tstar</span> results. </p>\r\n<p><span class="code blue code-font">> qdata(.025,Tstar)</span></p>\r\n<p><span class="code code-font">       p  quantile </span></p>\r\n<p><span class="code code-font">0.0250000 0.1914578 </span></p>\r\n<p><span class="code blue code-font">> qdata(.975,Tstar)</span></p>\r\n<p><span class="code code-font">       p quantile </span></p>\r\n<p><span class="code code-font">0.975000 3.484155 </span></p>\r\n<p>These results tell us that the 2.5<sup>th</sup> percentile of the bootstrap distribution is at 0.19 years and the 97.5<sup>th</sup> percentile is at 3.48 years. We can combine these results to provide a 95% confidence for &#956;<sub>Unattr</sub> - &#956;<sub>Ave</sub> that is between 0.19 and 3.48. We can interpret this as with any confidence interval, that we are 95% confident that the difference in the true means (Unattractive minus Average) is between 0.19 and 3.48 years. We can also obtain both percentiles in one line of code using:</p>\r\n<p><span class="code blue code-font">> quantiles<-qdata(c(.025,.975),Tstar)</span></p>\r\n<p><span class="code blue code-font">> quantiles</span></p>\r\n<p><span class="code code-font">       quantile     p</span></p>\r\n<p><span class="code code-font">2.5%  0.1914578 0.025</span></p>\r\n<p><span class="code code-font">97.5% 3.4841547 0.975</span></p>\r\n\r\n<p>Figure 1-18 displays those same percentiles on the same bootstrap distribution. </p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> abline(v=quantiles$quantile,col="blue",lwd=3)</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=quantiles$quantile,col="blue",lwd=3)</span></p>\r\n\r\n<figure>\r\n<img src="../meta/img/Figure1.18.jpg" alt="Figure1.18">\r\n<figcaption>Figure 1-18: Histogram and density curve of bootstrap distribution with 95% bootstrap confidence intervals displayed (vertical lines).<em></em></figcaption></figure> \r\n\r\n<p>Although confidence intervals can exist without referencing hypotheses, we can revisit our previous hypotheses and see what this confidence interval tells us about the test of H<sub>0</sub>: &#956;<sub>Unattr</sub> = &#956;<sub>Ave</sub>. This null hypothesis is equivalent to testing H<sub>0</sub>: &#956;<sub>Unattr</sub> - &#956;<sub>Ave</sub>=0, that the difference in the true means is equal to 0 years. And the difference in the means was the scale for our confidence interval, which did not contain 0 years. We will call 0 an interesting <strong><em>reference value</strong></em> for the confidence interval, because here it is the value where the true means are equal other (have a difference of 0 years). In general, if our confidence interval does not contain 0, then it is saying that 0 is not one of our likely values for the difference in the true means. This implies that we should reject a claim that they are equal. This provides the same inferences for the hypotheses that we considered previously using both a parametric and permutation approach. The general summary is that we can use confidence intervals to test hypotheses by assessing whether the reference value under the null hypothesis is in the confidence interval (FTR H<sub>0</sub>) or outside the confidence interval (Reject H<sub>0</sub>).</p>\r\n<p>As in the previous situation, we also want to consider the parametric approach for comparison purposes and to have that method available for the rest of the semester. The parametric confidence interval is called the equal variance, <strong><em>two-sample t-based confidence interval</strong></em> and assumes that the populations being sampled from are normally distributed and leads to using a t-distribution to form the interval. The output from the <span class="code-font">t.test</span> function provides the parametric 95% confidence interval calculated for you:</p>\r\n<p><span class="code blue code-font">> t.test(Years ~ Attr, data=MockJury2,var.equal=T)</span></p>\r\n<p><span class="code code-font">	Two Sample t-test</span></p>\r\n<p><span class="code code-font">data:  Years by Attr</span></p>\r\n<p><span class="code code-font">t = -2.1702, df = 73, p-value = 0.03324</span></p>\r\n<p><span class="code code-font">alternative hypothesis: true difference in means is not equal to 0</span></p>\r\n<p><span class="code code-font">9</span></p>\r\n<p><span class="code code-font">5 percent confidence interval:</span></p>\r\n<p><span class="code code-font">-3.5242237 -0.1500295</span></p>\r\n<p><span class="code code-font">sample estimates:</span></p>\r\n <table class="code code-font">\r\n<tr><td>mean in group Average</td><td>mean in group Unattractive</td></tr>\r\n<tr><td align="right">3.973684</td><td align="right">5.810811</td></tr>\r\n</table>\r\n<p>The <span class="code-font">t.test</span> function again switched the order of the groups and provides slightly different end-points than our bootstrap confidence interval (both made at the 95% confidence level), which was slightly narrower. Both intervals have the same interpretation, only the methods for calculating the intervals and the assumptions differ. Specifically, the bootstrap interval can tolerate different distribution shapes other than normal and still provide intervals that work well. The other assumptions are all the same as for the hypothesis test, where we continue to assume that we have independent observations with equal variances for the two groups.</p>\r\n<p>The formula that <span class="code-font">t.test</span> is using to calculate the parametric <strong><em>equal-variance two-sample t-based confidence interval</strong></em> is:</p>\r\n<figure>\r\n<img src="../meta/img/Equation1.3.jpg" alt="Equation1.3">\r\n</figure>\r\n<p>In this situation, the <em>df</em> is again n<sub>1</sub>+n<sub>2</sub>&#8722;2 and <img src="../meta/img/Equation1.4.jpg"  alt="Equation1.4" style="vertical-align:middle">\r\nThe <em>t</em>*<sub>df</sub> is a multiplier that comes from finding the percentile from the <em>t</em>-distribution that puts C% in the middle of the distribution with C being the confidence level. It is important to note that this <em>t</em>* has nothing to do with the previous test statistic <em>t</em>. It is confusing and many of you will, at some point, happily take the result from a test statistic calculation and use it for a multiplier in a <em>t</em>-based confidence interval. Figure 1-19 shows the <em>t</em>-distribution with 73 degrees of freedom and the cut-offs that put 95% of the area in the middle.<p>\r\n<figure>\r\n<img src="../meta/img/Figure1.19.jpg" alt="Figure1.19">\r\n<figcaption>Figure 1-19: Plot of t(73) with cut-offs for putting 95% of distributions in the middle.<em></em></figcaption></figure> \r\n<p>For 95% confidence intervals, the multiplier is going to be close to 2 - anything else is a sign of a mistake. We can use R to get the multipliers for us using the <span class="code-font">qt</span> function in a similar fashion to how we used <span class="code-font">qdata</span> in the bootstrap results, except that this new value must be used in the previous formula. This function produces values for requested percentiles. So if we want to put 95% in the middle, we place 2.5% in each tail of the distribution and need to request the 97.5<sup>th</sup> percentile. Because the t-distribution is always symmetric around 0, we merely need to look up the value for the 97.5<sup>th</sup> percentile. The t* multiplier to form the confidence interval is 1.993 for a 95% confidence interval when the df=73 based on the results from <span class="code-font">qt</span>:</p>\r\n<p><span class="code blue code-font">> qt(.975,df=73)</span></p>\r\n<p><span class="code code-font">[1] 1.992997</span></p>\r\n<p>Note that the 2.5th percentile is just the negative of this value due to symmetry and the real source of the minus in the plus/minus in the formula for the confidence interval.</p>\r\n<p><span class="code blue code-font">> qt(.025,df=73)</span></p>  \r\n<p><span class="code code-font">[1] -1.992997</span></p>\r\n<p>We can also re-write the general confidence interval formula more simply as</p>\r\n<figure>\r\n<img src="../meta/img/Equation1.5.jpg" alt="Equation1.5">\r\n</figure> \r\n<p>where <img src="../meta/img/Equation1.6.jpg"  alt="Equation1.6" style="vertical-align:middle"> In some situations, researchers will report the <em><strong>standard error</em></strong> (SE) or <em><strong>margin of error</em></strong> (ME) as a method of quantifying the uncertainty in a statistic. The SE is an estimate of the standard deviation of the statistic (here <span style="text-decoration: overline">x</span><sub>1</sub>&#8722;<span style="text-decoration: overline">x</span><sub>2</sub>) and the ME is an estimate of the precision of a statistic that can be used to directly form a confidence interval. The ME depends on the choice of confidence level although 95% is almost always selected.</p>\r\n<p>To finish this example, we can use R to help us do calculations much like a calculator except with much more power "under the hood". You have to make sure you are careful with using <span class="code-font">( )</span> to group items and remember that the asterisk (*) is used for multiplication. To do this, we need the pertinent information which is available from the bolded parts of the <span class="code-font">favstats</span> output repeated below.</p>\r\n<p><span class="code blue code-font">> favstats(Years~Attr,data=MockJury2)</p>\r\n<table class="code code-font">\r\n<tr><td align="right"> </td><td align="right">min</td><td align="right">Q1\r\n</td><td align="right">median</td><td align="right">Q3</td><td align="right">max</td><td align="right">mean</td><td align="right">sd</td><td align="right">n</td><td align="right">missing</td></tr>\r\n<tr><td align="right">Average</td><td align="right">1</td><td align="right">2</td><td align="right">3</td><td align="right">5</td><td align="right">12</td><td align="right">3.973684</td><td align="right">2.823519</td><td align="right">38</td><td align="right">0</td></tr>\r\n<tr>\r\n<td align="right">Unattractive</td><td align="right">1</td><td align="right">2</td><td align="right">5</td><td align="right">10</td><td align="right">15</td><td align="right">5.810811</td><td align="right">4.364235</td><td align="right">37</td><td align="right">0</td></tr>\r\n</table>\r\n\r\n<p>We can start with typing the following command to calculate s<sub>p</sub>:</p>\r\n<p><span class="code blue code-font">> sp <- sqrt(((38-1)*(2.8235^2)+(37-1)*(4.364^2))/(38+37-2))</span></p>\r\n<p><span class="code blue code-font">> sp</span></p>\r\n<p><span class="code code-font">[1] 3.665036</span></p>\r\n\r\n<p>So then we can calculate the confidence interval that <span class="code-font">t.test</span> provided using:</p>\r\n<p><span class="code blue code-font">> 3.974-5.811+c(-1,1)*qt(.975,df=73)*sp*sqrt(1/38+1/37)</span></p>\r\n<p><span class="code code-font">[1] -3.5240302 -0.1499698</span></p>\r\n\r\n<p>The previous code uses c(-1,1) times the margin of error to subtract and add the ME to the difference in the sample means <span class="code-font">(3.974-5.811)</span> to generate the lower and then upper bounds of the confidence interval. If desired, we can also use just the last portion of the previous calculation to find the margin of error, which is 1.69 here.</p>\r\n<p><span class="code blue code-font">> qt(.975,df=73)*sp*sqrt(1/38+1/37)</span></p>\r\n<p><span class="code code-font">[1] 1.68703</span></p>', NULL, 'Chapter 1', '1.009', '1.7', 'Textbook', 'Textbook', 'Bootstrapping', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:41:05', NULL, NULL, NULL, NULL),
(50, 'Bootstrap confidence interval for difference in GPAs', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>We can now repeat the methods on the STAT 217 grade data. This time we can start with the parametric 95% confidence interval "by hand" and then using <span class="code-font">t.test</span>. The <span class="code-font">favstats</span> output provides us with the required information to do this ourselves:</p>\r\n<p><span class="code blue code-font"> favstats(GPA~Sex,data=s217)</span></p>\r\n<table class="code code-font">\r\n  <tr><td align="right"> </td><td align="right"> .group</td><td align="right">min</td><td align="right">Q1</td><td align="right">median</td><td align="right">Q3</td><td align="right">max</td><td align="right">mean</td><td align="right">sd</td><td align="right">n</td><td align="right">missing</td></tr>\r\n  <tr><td align="right">1</td><td align="right">F</td><td align="right">2.50</td><td align="right">3.1</td><td align="right">3.400</td><td align="right">3.70</td><td align="right">4</td><td align="right">3.338378</td><td align="right">0.4074549</td><td align="right">37</td><td align="right">0</td></tr>\r\n  <tr><td align="right">2</td><td align="right">M</td><td align="right">1.96</td><td align="right">2.8</td><td align="right">3.175</td><td align="right">3.46</td><td align="right">4</td><td align="right">3.088571</td><td align="right">0.4151789</td><td align="right">42</td><td align="right">0</td></tr>\r\n  </table>\r\n<p>The <em>df</em> are 37+42-2 = 77. Using the SDs from the two groups and their sample sizes, we can calculate s<sub>p</sub>:</p>\r\n<p><span class="code blue code-font">> sp=sqrt(((37-1)*(0.4075^2)+(42-1)*(0.41518^2))/(37+42-2))</span></p>\r\n<p><span class="code code-font">> sp</span></p>\r\n<p><span class="code code-font">[1] 0.4116072</span></p>\r\n\r\n<p>The margin of error is:</p>\r\n<p><span class="code blue code-font">> qt(.975,df=77)*sp*sqrt(1/37+1/42)</span></p>\r\n<p><span class="code code-font">[1] 0.1847982</span></p>\r\n\r\n<p>All together, the 95% confidence interval is:</p>\r\n<p><span class="code blue code-font">> 3.338-3.0886+c(-1,1)*qt(.975,df=77)*sp*sqrt(1/37+1/42)</span></p>\r\n<p><span class="code code-font">[1] 0.0646018 0.4341982</span></p>\r\n\r\n<p>So we are 95% confident that the difference in the true mean GPAs between females and males (femals minus males) is between 0.065 and 0.434 GPA points. We get a similar<sup><a id="20top" href="#20ft">20</a></sup> result from the bolded part of the <span class="code-font">t.test</span> output:</p>\r\n<p><span class="code blue code-font">> t.test(GPA~Sex,data=s217,var.equal=T)</span></p>\r\n<p><span class="code code-font">Two Sample t-test</span></p>\r\n\r\n<p><span class="code code-font">data:  GPA by Sex</span></p>\r\n<p><span class="code code-font">t = 2.6919, df = 77, p-value = 0.008713</span></p>\r\n<p><span class="code code-font">alternative hypothesis: true difference in means is not equal to 0</span></p>\r\n<p><span class="code code-font">95 percent confidence interval:</span></p>\r\n<p><span class="code code-font">0.06501838 0.43459552</span></p>\r\n<p><span class="code code-font">sample estimates:</span></p>            \r\n<table class="code code-font"><tr><td align="right">mean in group F</td><td align="right">mean in group M</td></tr>\r\n<tr><td align="right">3.338378</td><td align="right">3.088571</td></tr>\r\n</table> \r\n<p>Note that we can easily switch to 90% or 99% confidence intervals by simply changing the percentile in <span class="code-font">qt</span> or changing <span class="code-font">conf.level</span> in the <span class="code-font">t.test</span> function. In the following two lines of code, we added <strong><em>hashtags</strong></em> (#) and then some text to explain what is being calculated. Hashtags provide a way of adding comments to R code as R will ignore any text after a hashtag on a given line.</p>\r\n<p><span class="code blue code-font">> qt(.95,df=77)      #For 90% confidence and 77 df</span></p>\r\n<p><span class="code code-font">1] 1.664885</span></p>\r\n<p><span class="code blue code-font">> qt(.995,df=77)     #For 99% confidence and 77 df</span></p>\r\n<p><span class="code code-font">[1] 2.641198</span></p>\r\n\r\n<p><span class="code blue code-font"> t.test(GPA~Sex,data=s217,var.equal=T,conf.level=.90)</span></p>\r\n<p><span class="code code-font">t = 2.6919, df = 77, p-value = 0.008713</span></p>\r\n<p><span class="code code-font">alternative hypothesis: true difference in means is not equal to 0</span></p>\r\n<p><span class="code code-font">90 percent confidence interval:</span></p>\r\n<p><span class="code code-font">0.09530553 0.40430837</span></p>\r\n\r\n<p><span class="code blue code-font">> t.test(GPA~Sex,data=s217,var.equal=T,conf.level=.99)</span></p>\r\n<p><span class="code code-font">t = 2.6919, df = 77, p-value = 0.008713</span></p>\r\n<p><span class="code code-font">alternative hypothesis: true difference in means is not equal to 0</span></p>\r\n<p><span class="code code-font">99 percent confidence interval:</span></p>\r\n<p><span class="code code-font"> 0.004703598 0.494910301</span></p>\r\n\r\n<p>As a review of some basic ideas with confidence intervals make sure you can answer the following questions:</p>\r\n<ol>\r\n<li>1)	What is the impact of increasing the confidence level in this situation? </li>\r\n<li>2)	What happens to the width of the confidence interval if the size of the SE increases or decreases? </li>\r\n<li>3)	What about increasing the sample size - should that increase or decrease the width of the interval?</li>\r\n</ol> \r\n<p>All of the general results you learned before about impacts to widths of CIs hold in this situation whether we are considering the parametric or bootstrap methods.</p>\r\n<p>To finish this example, we will generate the comparable bootstrap 90% confidence interval using the bootstrap distribution in Figure 1-20.</p>\r\n<p><span class="code blue code-font">> Tobs <- compareMean(GPA ~ Sex, data=s217); Tobs</span></p>\r\n<p><span class="code code-font">[1] -0.2498069</span></p>\r\n<p><span class="code blue code-font">> par(mfrow=c(1,2))</span></p>\r\n<p><span class="code blue code-font">> B<- 1000</span></p>\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-compareMean(GPA ~ Sex, data=resample(s217))</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p><span class="code blue code-font">> qdata(.05,Tstar)</span></p>\r\n<table class="code code-font">\r\n<tr><td align="right">p</td><td align="right">quantile</td></tr>\r\n<tr><td align="right">0.0500000</td><td align="right">-0.3974425</td></tr>\r\n</table> \r\n<p><span class="code blue code-font">> qdata(.95,Tstar)</span></p>\r\n<table class="code code-font">\r\n<tr><td align="right">p</td><td align="right">quantile</td></tr>\r\n<tr><td align="right">0.9500000</td><td align="right">-0.1147324</td></tr>\r\n</table>\r\n\r\n<p><span class="code blue code-font">> quantiles<-qdata(c(.05,.95),Tstar)</span></p>\r\n<p><span class="code blue code-font">> quantiles</span></p>\r\n<table class="code code-font"><tr><td align="right"> </td><td align="right">quantile</td><td align="right">p</td></tr>\r\n<tr><td align="right">5%</td><td align="right">-0.3974425</td><td align="right">0.05</td></tr>\r\n<tr><td align="right">95%</td><td align="right">-0.1147324</td><td align="right">0.95</td></tr>\r\n</table>\r\n\r\n<p>The output tells us that the 90% confidence interval is from -0.397 to -0.115 GPA points. The bootstrap distribution with the observed difference in the sample means and these cut-offs is displayed in Figure 1-20 using this code:</p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=2)</span></p>\r\n<p><span class="code blue code-font">> abline(v=quantiles$quantile,col="blue",lwd=3,lty=2)</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=2)</span></p>\r\n<p><span class="code blue code-font">> abline(v=quantiles$quantile,col="blue",lwd=3,lty=2)</span></p>\r\n\r\n<p>In the previous output, the parametric 90% confidence interval is from 0.095 to 0.404, suggesting similar results again from the two approaches once you account for the two different orders of differencing. There was a slight left skew in the bootstrap distribution with one much smaller difference observed which generated some of the observed difference in the results. Based on the bootstrap CI, we can say that we are 90% confident that the difference in the true mean GPAs for STAT 217 students is between -0.397 to -0.115 GPA points (male minus females). Because sex cannot be assigned to the subjects, we cannot infer that sex is causing this difference and because this was a voluntary response sample of STAT 217 students in a given semester, we cannot infer that a difference of this size would apply to all STAT 217 students or even students in another semester.</p>\r\n<figure>\r\n<img src="../meta/img/Figure1.20.jpg" alt="Figure1.20">\r\n<figcaption><em>Figure 1-20: Histogram and density curve of bootstrap distribution of difference in sample mean GPAs (male minus female) with observed difference (solid vertical line) and quantiles that delineate the 90% confidence intervals (dashed vertical lines).</em></figcaption>\r\n</figure>\r\n\r\n<p>Throughout the semester, pay attention to the distinctions between parameters and statistics, focusing on the differences between estimates based on the sample and inferences for the population of interest in the form of the parameters of interest. Remember that statistics are summaries of the sample information and parameters are characteristics of populations (which we rarely know). And that our inferences are limited to the population that we randomly sampled from, if we randomly sampled.</p>', '<p><sup><a id="20ft" href="#20top">20</a></sup>We rounded the means a little and that caused the small difference in results.</p>', 'Chapter 1', '1.010', '1.8a', 'Textbook', 'Textbook', 'Confidence interval', NULL, NULL, NULL, NULL, NULL, '2015-09-16 14:39:35', NULL, NULL, NULL, NULL),
(51, 'Chapter summary', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In this chapter, we reviewed basic statistical inference methods in the context of a two-sample mean problem. You were introduced to using R to do permutation testing and generate bootstrap confidence intervals as well as obtaining parametric t-test and confidence intervals in this same situation. You should have learned how to use a <span class="code-font">for</span> loop for doing the nonparametric inferences and the <span class="code-font">t.test</span> function for generating parametric inferences. In the two examples considered, the parametric and nonparametric methods provided similar results, suggesting that the assumptions were at least close to being met for the parametric procedures. When parametric and nonparametric approaches disagree, the nonparametric methods are likely to be more trustworthy since they have less restrictive assumptions but can still have problems. When the noted conditions are not met in a hypothesis testing situation, the Type I error rates can be inflated, meaning that we reject the null hypothesis more often than we have allowed to occur by chance. Specifically, we could have a situation where our assumed 5% significance level test might actually reject the null when it is true 20% of the time. If this is occurring, we call a procedure <strong><em>liberal</strong></em> (it rejects too easily) and if the procedure is liberal, how could we trust a small p-value to be a "real" result and not just an artifact of violating the assumptions of the procedure? Likewise, for confidence intervals we hope that our 95% confidence level procedure, when repeated, will contain the true parameter 95% of the time. If our assumptions are violated, we might actually have an 80% confidence level procedure and it makes it hard to trust the reported results for our observed data set. Statistical inference relies on a belief in the methods underlying our inferences. If we don''t trust our assumptions, we shouldn''t trust the conclusions to perform the way we want them to. As sample sizes increase and violations of conditions lessen, then the procedures will perform better. In Chapter 2, we''ll learn some new tools for doing diagnostics to help us assess how much those conditions are violated.</p>', NULL, 'Chapter 1', '1.011', '1.8b', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:43:07', NULL, NULL, NULL, NULL),
(52, 'Summary of important R code', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>The main components of R code used in this chapter follow with components to modify in red, remembering that any R packages mentioned need to be installed and loaded for this code to have a chance of working:</p>\r\n<li>&#8226;	<span class="code-font">summary(<span class="red">DATASETNAME</span>)</span>\r\n<ul>\r\n<li>&#9702;	Provides numerical summaries of all variables in the data set.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">t.test(<span class="red">Y</span>~<span class="red">X</span>,data=<span class="red">DATASETNAME</span>,conf.level=0.95)</span>\r\n<ul>\r\n<li>&#9702;	Provides two-sample t-test test statistic, df, p-value, and 95% confidence interval.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">2*pt(abs(<span class="red">Tobs</span>),df=<span class="red">DF</span>,lower.tail=F)</span>\r\n<ul>\r\n<li>&#9702;	Finds the two-sided test p-value for an observed 2-sample t-test statistic of Tobs.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">hist(<span class="red">DATASETNAME$Y</span>)</span>\r\n<ul>\r\n<li>&#9702;	Makes a histogram of a variable named Y from the data set of interest.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">boxplot(<span class="red">Y</span>~<span class="red">X</span>,data=<span class="red">DATASETNAME</span>)</span>\r\n<ul>\r\n<li>&#9702;	Makes a boxplot of a variable named Y for groups in X from the data set.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">beanplot(<span class="red">Y</span>~<span class="red">X</span>,data=<span class="red">DATASETNAME</span>)</span>\r\n<ul>\r\n<li>&#9702;	Makes a beanplot of a variable named Y for groups in X from the data set.</li>\r\n<li>&#9702;	Requires the beanplot package is loaded.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">mean(<span class="red">Y</span>~<span class="red">X</span>,data=<span class="red">DATASETNAME</span>); sd(Y</span>~X</span>,data=<span class="red">DATASETNAME</span>)</span>\r\n<ul> \r\n<li>&#9702;	Provides the mean and sd of responses of Y for each group described in X.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">favstats(<span class="red">Y</span>~<span class="red">X</span>,data=<span class="red">DATASETNAME</span>)</span>\r\n<ul>\r\n<li>&#9702;	Provides numerical summaries of Y by groups described in X.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">Tobs <- t.test(<span class="red">Y</span>~<span class="red">X</span>,data=<span class="red">DATASETNAME</span>,var.equal=T)$statistic; Tobs</span>\r\n<p><span class="code-font">B<-1000</span></p>\r\n<p><span class="code-font">Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code-font">for (b in (1:B)){</span></p>\r\n<p><span class="code-font"> Tstar[b]<-t.test(<span class="red">Y</span>~shuffle(<span class="red">X</span>),data=<span class="red">DATASETNAME</span>,var.equal=T)$statistic</span></p>\r\n<p><span class="code-font"> }</span></p>\r\n<ul>\r\n<li>&#9702;	Code to run a <span class="code-font">for</span> loop to generate 1000 permuted versions of the test statistic using the <span class="code-font">shuffle</span> function and keep track of the results in <span class="code-font">Tstar</span>.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">pdata(abs(<span class="red">Tobs</span>),Tstar,lower.tail=F)</span>\r\n<ul>\r\n<li>&#9702;	Finds the proportion of the permuted test statistics in Tstar that are less than -|Tobs| or greater than |Tobs|,</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">Tobs <- compareMeans(<span class="red">Y</span>~<span class="red">X</span>,data= <span class="red">DATASETNAME</span>); Tobs</span>\r\n<p><span class="code-font">B<-1000</span></p>\r\n<p><span class="code-font">Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code-font">for (b in (1:B)){</span></p>\r\n<p><span class="code-font">  Tstar[b]<-compareMeans(<span class="red">Y</span>~<span class="red">X</span>,data=resample(<span class="red">DATASETNAME</span>))</span></p>\r\n <p><span class="code-font"> }</span></p>\r\n<ul>\r\n<li>&#9702;	Code to run a <span class="code-font">for</span> loop to generate 1000 bootstrapped versions of the data set using the <span class="code-font">resample</span> function and keep track of the results of the statistic in <span class="code-font">Tstar</span>.</li></ul></li>\r\n\r\n<li>&#8226;	<span class="code-font">qdata(c(0.025,0.975),Tstar)</span>\r\n<ul>\r\n<li>&#9702;	Provides the values that delineate the middle 95% of the results in the bootstrap distribution (<span class="code-font">Tstar</span>).</li></ul></li>', NULL, 'Chapter 1', '1.012', '1.9', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-09-16 15:25:10', NULL, NULL, NULL, NULL),
(53, 'Practice problems', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>Load the <span class="code-font">HELPrct</span> data set from the <span class="code-font">mosaicData</span> package. The <span class="code-font">HELP</span> study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomly assigned to receive a multidisciplinary assessment and a brief motivational intervention or usual care and various outcomes were observed. Two of the variables in the dataset are <span class="code-font">sex</span>, a factor with levels (male and female) and <span class="code-font">daysanysub</span>, time (in days) to first use of any substance post-detox. We are interested in the difference in mean number of days to first use of any substance post-detox between males and females. There are some missing responses and the following code will produce <span class="code-font">favstats</span> with the missing values and then provide a data set that for complete observations by applying the <span class="code-font">na.omit</span> function that removes any observations with missing values.</p>\r\n<p><span class="code-font">require(mosaicData) #load the dataset</span></p>\r\n<p><span class="code-font">data(HELPrct)</span></p>\r\n<p><span class="code-font">HELPrct2<-HELPrct[,c("daysanysub","sex")] #Just focus on two variables</span></p>\r\n<p><span class="code-font">HELPrct3<-na.omit(HELPrct2) #Removes subjects with missing</span></p>\r\n<p><span class="code-font">favstats(daysanysub~sex, data = HELPrct2)</span></p>\r\n<p><span class="code-font">favstats(daysanysub~sex, data = HELPrct3)</span></p>\r\n<dd><p>1.1. Based on the results provided, how many observations were missing for males and females. Missing values here likely mean that the subjects didn''t use any substances post-detox in the time of the study. This is called censoring. What is the problem with the numerical summaries if the missing responses were all something larger than the largest observation?</dd></p>\r\n<dd><p>1.2. Make a beanplot and a boxplot of <span class="code-font">daysanysub ~ sex</span> using the <span class="code-font">HELPrct3</span> data set created above. Compare the distributions, recommending parametric or nonparametric inferences.</dd></p>\r\n<dd><p>1.3. Generate the permutation results and write out the 6+ steps of the hypothesis test, making sure to note the numerical value of observed test statistic you are using. Include scope of inference.</dd></p>\r\n<dd><p>1.4. Interpret the p-value for these results.</dd></p>\r\n<dd><p>1.5. Generate the parametric t.test results, reporting the test-statistic, its distribution under the null hypothesis, and compare the p-value to those observed using the permutation approach.</dd></p>\r\n<dd><p>1.6. Make and interpret a 95% bootstrap confidence interval for the difference in the means.</dd></p>\r\n', NULL, 'Chapter 1', '1.013', '1.10', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-27 23:43:50', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(54, 'One-Way ANOVA', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In Chapter 1, tools for comparing the means of two groups were considered. More generally, these methods are used for a quantitative response and a categorical explanatory variable (group) which had two and only two levels. The MockJury data set actually contained three groups (Figure 2-1) with <em>Beautiful</em>, <em>Average</em>, and <em>Unattractive</em> rated pictures randomly assigned to the subjects for sentence ratings. In a situation with more than two groups, we have two choices. First, we could rely on our two group comparisons, performing tests for every possible pair (<em>Beautiful</em> vs <em>Average</em>, <em>Beautiful</em> vs <em>Unattractive</em>, and <em>Average</em> vs <em>Unattractive</em>). We spent Chapter 1 doing inferences for differences between <em>Average</em> and <em>Unattractive</em>. The other two comparisons would lead us to initially end up with three p-values and no direct answer about our initial question of interest - is there some overall difference in the average sentences provided across the groups? In this chapter, we will learn a new method, called <em><strong>Analysis of Variance, ANOVA</em></strong>, that directly assesses whether there is evidence of some overall difference in the means among the groups. This version of an ANOVA is called a <em><strong>One-Way ANOVA</em></strong> since there is just one <sup><a id="21ft" href="#21top">21</a></sup> grouping variable. After we perform our One-Way ANOVA test for overall evidence of a difference, we will revisit the comparisons similar to those considered in Chapter 1 to get more details on specific differences among the pairs of groups - what we call <em><strong>pair-wise comparisons</em></strong>. An issue is created when you perform many tests simultaneously and we will augment our previous methods with an adjusted method for pairwise comparisons to make our results valid called <em><strong>Tukey''s Honest Significant Difference</em></strong>. </p>\r\n<p>To make this more concrete, we return to the original MockJury data, making side-by-side boxplots and beanplots (Figure 2-1) as well summarizing the sentences for the three groups using <span class="code-font">favstats.</span></p>\r\n<p><span class="code blue code-font">> favstats(Years~Attr,data=MockJury)</span></p>\r\n<p><span class="code blue code-font">> require(heplots)</span></p>\r\n<p><span class="code blue code-font">> require(mosaic)</span></p>\r\n<p><span class="code blue code-font">> data(MockJury)</span></p>\r\n<p><span class="code blue code-font">> par(mfrow=c(1,2))</span></p>\r\n<p><span class="code blue code-font">> boxplot(Years~Attr,data=MockJury)</span></p>\r\n<p><span class="code blue code-font">> beanplot(Years~Attr,data=MockJury,log="",col="bisque",method="jitter")</span></p>\r\n\r\n<p><span class="code blue code-font">> favstats(Years~Attr,data=MockJury)</span></p>\r\n<table class="code code-font">\r\n <tr><td align="right"> </td><td align="right">.group</td><td align="right"> min</td><td align="right"> Q1</td><td align="right"> median</td><td align="right">Q3</td><td align="right">max</td><td align="right">mean</td><td align="right">sd</td><td align="right">n</td><td align="right"> missing</td></tr>\r\n<tr><td>1</td><td align="right">Beautiful</td><td align="right">1</td><td align="right">2</td><td align="right">3</td><td align="right">6.5</td><td align="right">15</td><td align="right">4.333333</td><td align="right">3.405362</td><td align="right">39</td><td align="right">0</td></tr>\r\n<tr><td>2</td><td align="right">Average</td><td align="right">1</td><td align="right">2</td><td align="right">3</td><td align="right">5.0</td><td align="right">12</td><td align="right">3.973684</td><td align="right">2.823519</td><td align="right">38</td><td align="right">0</td></tr>\r\n<tr><td>3</td><td align="right">Unattractive</td><td align="right">1</td><td align="right">2</td><td align="right">5</td><td align="right">10.0</td><td align="right">15</td><td align="right">5.810811</td><td align="right">4.364235</td><td align="right">37</td><td align="right">0</td></tr>\r\n  </table>\r\n<br>\r\n<p>There are slight differences in the sample sizes in the three groups with 37 <em>Unattractive</em>, 38 <em>Average</em> and 39 <em>Beautiful</em> group responses, providing a data set has a total sample size of N=114. The <em>Beautiful</em> and <em>Average</em> groups do not appear to be very different with means of 4.33 and 3.97 years. In Chapter 1, we found moderate evidence regarding the difference in <em>Average</em> and <em>Unattractive</em>. It is less clear whether we might find evidence of a difference between <em>Beautiful</em> and <em>Unattractive</em> groups since we are comparing means of 5.81 and 4.33 years. All the distributions appear to be right skewed with relatively similar shapes. The variability in <em>Average</em> and <em>Unattractive</em> groups seems like it could be slightly different leading to an overall concern of whether the variability is the same in all the groups.</p>\r\n<br>\r\n<figure>\r\n<img src="../meta/img/Figure2.1.jpg" alt="Figure2.1">\r\n<figcaption><em>Figure 2-1: Boxplot and beanplot of the sentences (years) for the three treatment groups.</em></figcaption>\r\n</figure>', '  <sup><a id="21top" href="#21ft">21</a></sup>In Chapter 3, we will discuss methods for when there are two categorical explanatory variables that is called the Two-Way ANOVA.', 'Chapter 2', '2.001', '2.0 Situation', 'Textbook', 'Textbook', 'One-way analysis of variance', NULL, NULL, NULL, NULL, NULL, '2015-08-28 00:56:08', NULL, NULL, NULL, NULL),
(55, 'Linear model for One-Way ANOVA (cell-means and reference-coding)', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>We introduced the statistical model &#947;<sub>ij</sub> = &#956;<sub>j</sub> + &#949;<sub>ij</sub> in Chapter 1 for the situation with <em>j</em> = 1 or 2 to denote a situation where there were two groups and, for the alternative model, the means differed. Now we have three groups and the previous model can be extended to this new situation by allowing <em>j</em> to be 1, 2, or 3. Now that we have more than two groups, we need to admit that what we were doing in Chapter 1 was actually fitting what is called a <em><strong>linear model</em></strong>. The linear model assumes that the responses follow a normal distribution with the linear model defining the mean, all observations have the same variance, and the parameters for the mean in the model enter linearly. This last condition is hard to explain at this level of material - it is sufficient to know that there models where the parameters enter the model nonlinearly and that they are beyond the scope of this course. The result of this constraint is that we will be able to use the same general modeling framework for the rest of the course. </p>\r\n\r\n<p>As in Chapter 1, we have a null hypothesis that defines a situation (and model) where all the groups have the same mean. Specifically, the <em><strong>null hypothesis</em></strong> in the general situation with <em>J</em> groups (<em>J</em>&#8805;2) is to have all the <u>true</u> group means equal,</p>\r\n	\r\n<p align="center">H<sub>0</sub>: &#956;<sub>1</sub> =... = &#956;<sub>J</sub>.</p>\r\n\r\n<p>This defines a model where all the groups have the same mean that we can define in terms of a single mean, &#956;, for the <em>i<sup>th</sup></em> observation from the <em>j</em><sup>th</sup> group as &#947;<sub>ij</sub> = &#956; + &#949;<sub>ij</sub>. This is not the model that most researchers want to characterize their study as it implies no difference in the groups. There is more caution required to specify the <em><strong>alternative hypothesis</em></strong> with more than two groups. The alternative hypothesis needs to be the logical negation of this null hypothesis of all groups having equal means; to make the null hypothesis false, we only need one group to differ but more than one group could differ from the others. Essentially, there are many ways to "violate" the null hypothesis so we choose some delicate wording for the alternative hypothesis when there are more than 2 groups. Specifically, we state the alternative as</p>\r\n\r\n<p align="center">H<sub>A</sub>: Not all &#956;<sub>j</sub> are equal</p>\r\n\r\n<p>or, in words, <em>at least one of the true means differs among the J groups</em>. You will be attracted to trying to say that all means are different in the alternative but we do not put this strict a requirement in place to reject the null hypothesis. The alternative model allows all the true group means to differ but does require that they differ with</p>\r\n\r\n<p align="center">&#947;<sub>ij</sub> = <span class="red">&#956;<sub>j</sub></span> + &#949;<sub>ij</sub>.</p>\r\n\r\n<p>This linear model states that the response for the i<sup>th</sup> observation in the <em>j<sup>th</sup></em> group, <strong>&#947;</strong><sub>ij</sub>, is modeled with a group <em>j</em> (<em>j</em>=1,...,<em>J</em>) population mean, &#956;<sub>j</sub>, and a random error for each subject in each group, &#949;<sub>ij</sub>, that we assume follows a normal distribution and that all the random errors have the same variance, &#963;<sup>2</sup>. We can write the assumption about the random errors, often called the <em><strong>normality assumption</em></strong>, as &#949;<sub>ij</sub>~N(0,&#963;<sup>2</sup>). There is a second way to write out this model that will allow extensions to more complex models discussed below, so we need a name for this version of the model. The model writtern in terms of the <span class="red">&#956;<sub>j</sub></span>''s is called the <em><span class="red">cell means model</span></em> and is the easier version of this model to understand.</p>\r\n\r\n<p>One of the reasons we learned about beanplots is that it helps us visually consider all the aspects of this model. In the right panel of Figure 2-1, we can see the wider, bold horizontal lines that provide the estimated group means. The bigger the differences, the more likely we are to find evidence against the null hypothesis. You can also see the null model on the plot that assumes all the groups have the same as displayed in the dashed horizontal line at 4.7 years (the R code below shows the overall mean of <em>Years</em> is 4.7). While the hypotheses focus on the means, the model also contains assumptions about the distribution of the responses - specifically that the distributions are normal and all have the groups have the same variability. As discussed previously, it appears that the distributions are right skewed and the variability might not be the same for all the groups. The boxplot provides the information about the skew and variability but since it doesn''t display the means it is not directly related to the linear model and hypotheses we are considering.</p>\r\n<p><span class="code blue code-font">> mean(MockJury$Years)</span></p>\r\n<p><span class="code code-font">[1] 4.692982</span></p>\r\n<p>There is a second way to write out the One-Way ANOVA model that will allow extensions to more complex models in Chapter 3. The other parameterization (way of writing out or defining) of the model is called the <em><span class="purple">reference-coded model</span></em> since it writes out the model in terms of a baseline group and deviations from that baseline or reference level. The reference-coded model for the <em>i<sup>th</sup></em> subject in the <em>j<sup>th</sup></em> group is y<sub>ij</sub> = <span class="purple">&#945;</span> + &tau;<sub>j</sub> + &#949;<sub>ij</sub> where <span class="purple">&#945;</span> (alpha) is the true mean for the baseline group (first alphabetically) and the <span class="purple">&#964;<sub>j</sub></span> (tau j) are the deviations from the baseline group for group <em>j</em>. The deviation for the baseline group, <span class="purple">&#964;<sub>1</sub></span>, is always set to 0 so there are really just deviations for groups 2 through <em>J</em>. The equivalence between the two models can be seen by considering the mean for the first, second, and <em>J<sup>th</sup></em> groups in both models:</p>\r\n<table align="center">\r\n<tr><td></td><td>Cell means:</td><td>Reference-coded</td></tr>\r\n<tr><td>Group 1:</td><td><span class="red">&#956;<sub>1</sub></span></td><td><span class="purple">&#945;</span></td></tr>\r\n<tr><td>Group 2:</td><td><span class="red">&#956;<sub>2</sub></span></td><td><span class="purple">&#945; + &#964;<sub>2</sub></span></td></tr>\r\n<tr><td>...</td><td>...</td><td>...</td></tr>\r\n<tr><td>Group J:</td><td><span class="red">&#956;<sub>J</sub></td><td><span class="purple">&#945; + &#964;<sub>J</sub></span></td></tr>\r\n</table>\r\n<p>The hypotheses for the reference-coded model are similar to those in the cell-means coding except that they are defined in terms of the deviations, <span class="purple">&#964;<sub>j</sub></span>. The null hypothesis is that there is no deviation from the baseline for any group - that all the <span class="purple">&#964;<sub>j</sub></span>''s =0,</p>\r\n<p align="center"><strong>H<sub>0</sub>: &#964;<sub>2</sub> =... = &#964;<sub>J</sub> = 0.</strong></p>\r\n<p>The alternative hypothesis is that at least one of the deviations is not 0,</p>\r\n<p align="center"><strong>H<sub>A</sub>: Not all &#964;<sub>j</sub> equal 0.</strong></p>\r\n<p>You are welcome to use either version unless we instruct you to use a particular version in this chapter but we have to use the reference-coding in subsequent chapters. The next task is to learn how to use R''s linear model <span class="code-font">(lm)</span> function to get estimates of the parameters in each model, but first a review of these new ideas:</p>\r\n\r\n<p><span class="red">Cell-means version:</span></p>\r\n<p>&#8226;	H<sub>0</sub>: <span class="red">&#956;<sub>1</sub> =... = &#956;<sub>J</sub></span>&#8195;&#8195;&#8195;			H<sub>A</sub>: <span class="red">Not all &#956;<sub>j</sub> equal</span></p>\r\n<p>&#8226;	Null hypothesis in words: No difference in the true means between the groups.</p>\r\n<p>&#8226;	Null model: y<sub>ij</sub> = &#956; + &#949;<sub>ij</sub></p>\r\n\r\n<p>&#8226;	Alternative hypothesis in words: At least one of the true means differs between the groups.</p>\r\n<p>&#8226;	Alternative model: y<sub>ij</sub> = <span class="red">&#956;<sub>j</sub></span> + &#949;<sub>ij</sub></p>\r\n\r\n</p><span class="purple">Reference-coded version:</span></p>\r\n<p>&#8226;	H<sub>0</sub>: <span class="purple">&#964;<sub>2</sub> =... = &#964;<sub>J</sub> = 0</span>&#8195;&#8195;&#8195;	H<sub>A</sub>: <span class="purple">Not all &#964;<sub>j</sub> equal 0</span></p>\r\n<p>&#8226;	Null hypothesis in words: No deviation of the true mean for any groups from the baseline group.</p>\r\n<p>&#8226;	Null model: y<sub>ij</sub> = <strong>&#945;</strong> + &#949;<sub>ij</sub></p>\r\n\r\n<p>&#8226;	Alternative hypothesis in words: At least one of the true deviations is different from 0 or that at least one group has a different true mean than the baseline group.</p>\r\n<p>&#8226;	Alternative model: y<sub>ij</sub> = <span class="purple">&#945; + &#964;<sub>j</sub></span> + &#949;<sub>ij</sub></p>\r\n\r\n<p>In order to estimate the models discussed above, the <span class="code-font">lm</span> function will be used. If you look closely in the code for the rest of the semester, any model for a quantitative response will use this function, suggesting a common threads in the most commonly used statistical models. The <span class="code-font">lm</span> function continues to use the same format as previous functions, <span class="code-font">lm(Y~X,data=datasetname)</span>. It ends up that this code will give you the reference-coded version of the model by default. We want to start with the cell-means version of the model, so we have to add a <span class="code-font">"-1"</span> to the formula interface to tell R that we want to the cell-means coding. Generally, this looks like <span class="code-font">lm(Y~X-1,data=datasetname)</span> and you will find a row of output for each group. It will contain columns for an estimate (<span class="code-font">Estimate</span>), standard error (<span class="code-font">Std. Error</span>), t-value (<span class="code-font">t value</span>), and p-value (<span class="code-font">Pr(>|t|)</span>). We''ll learn to use all of the output in the following material, but for now we will just focus on the estimates of the parameters that the function provides that we put in bold.</p>\r\n\r\n<p><span class="code blue code-font">> lm1 <- lm(Years~Attr-1,data=MockJuryR)</span></p>\r\n<p><span class="code code-font">> summary(lm1)</span></p>\r\n<p><span class="code code-font">Coefficients:</span></p>\r\n<table class="code code-font">\r\n<tr>\r\n<td></td><td>Estimate</td><td>Std.Error</td><td>t value</td><td>Pr(>|t|)</td><td></td>\r\n</tr>   \r\n<tr>\r\n<td>AttrBeautiful</td><td>4.3333</td><td>0.5730</td><td>7.563</td><td>1.23e-11</td><td>***</td>\r\n</tr> \r\n<tr>\r\n<td>AttrAverage</td><td>3.9737</td><td>0.5805</td><td>6.845</td><td>4.41e-10</td><td>***</td>\r\n</tr> \r\n<tr>\r\n<td>AttrUnattractive</td> <td>5.8108</td> <td>0.5883</td> <td>9.878</td> <td>< 2e-16</td> <td>***</td>\r\n</tr> \r\n</table>\r\n\r\n<p>In general, we denote estimated parameters with a hat over the parameter of interest to show that it is an estimate. For the true mean of group <em>j</em>, <em>&#956;<sub>j</sub></em>, we estimate it with <em>&#956;&#770;<sub>j</sub></em>, which is just the sample mean for group <em>j</em>, <em><span style="text-decoration: overline">x</span><sub>j</sub></em>. The model suggests an estimate for each observation that we denote as <em>y&#770;<sub>ij</sub></em> that we will also call a <em><strong>fitted value</em></strong> based on the model being considered. The three estimates are bolded in the previous output, with a different estimate produced for all observations in the same group. R tries to help you to sort out which row of output corresponds to which group by appending the group name with the variable name. Here, the variable name was <span class="code-font">Attr</span> and the first group alphabetically was Beautiful, so R provides a row labeled <span class="code-font">AttrBeautiful</span> with an estimate of 4.3333. The sample means from the three groups can be seen to directly match those results.</p>\r\n<p><span class="code blue code-font">> mean(Years~Attr,data=MockJuryR)</span></p>\r\n<table class="code code-font">\r\n<tr><td>Beautiful</td><td>Average</td><td>Unattractive</td></tr> \r\n<tr><td>4.333333</td><td>3.973684</td><td>5.810811</td></tr>\r\n</table>\r\n<p>The reference-coded version of the same model is more complicated but ends up giving the same results once we understand what it is doing. Here is the model summary:</p>\r\n<p><span class="code blue code-font">> lm2 <- lm(Years~Attr,data=MockJuryR)</span></p>\r\n<p><span class="code blue code-font">> summary(lm2)</span></p>\r\n<p><span class="code code-font">Coefficients:</span></p>\r\n<table class="code code-font">\r\n<tr><td></td><td>Estimate</td><td>Std. Error</td><td>t value</td><td>Pr(>|t|)</td><td></td></tr>    \r\n<tr><td>(Intercept)</td><td>4.3333</td><td>0.5730</td><td>7.563</td><td>1.23e-11</td><td>***</td></tr>\r\n<tr><td>AttrAverage</td><td>-0.3596 </td><td>0.8157</td><td>-0.441</td><td>0.6601</td><td></td></tr>   \r\n<tr><td>AttrUnattractive</td><td>1.4775</td><td>0.8212</td><td>1.799</td><td>0.0747</td><td>.</td></tr> \r\n</table> \r\n<br>\r\n<p><span class="code code-font">Residual standard error: 3.578 on 111 degrees of freedom</span></p>\r\n<p><span class="code code-font"><p><span class="code code-font">Multiple R-squared:  0.04754,	Adjusted R-squared:  0.03038 </span></p>\r\n<p><span class="code code-font">F-statistic:  2.77 on 2 and 111 DF,  p-value: 0.067</span></p>\r\n<p>Remember that this is the standard version of the linear model so it will be something that gets used repeatedly this semester. The estimated model coefficients are &#945;&#770; = 4.333 years, &#964;&#770;<sub>2</sub> =-0.3596 years, and &#964;&#770;<sub>3</sub> =1.4775 years where group 1 is <em>Beautiful</em>, 2 is <em>Average</em>, and 3 is <em>Unattractive</em>. The way you can figure out the baseline group (group 1 is <em>Beautiful</em> here) is to see which category label is not present in the output. The baseline level is typically the first group label alphabetically, but you should always check this. Based on these definitions, there are interpretations available for each coefficient. For &#945;&#770; = 4.333 years, this is an estimate of the mean sentencing time for the <em>Beautiful</em> group. &#964;&#770;<sub>2</sub> =-0.3596 years is the deviation of the <em>Average</em> group''s mean from the <em>Beautiful</em> groups mean (specifically, it is 0.36 years lower). Finally, &#964;&#770;<sub>3</sub> =1.4775 years tells us that the <em>Unattractive</em> group mean sentencing time is 1.48 years higher than the <em>Beautiful</em> group mean sentencing time. These interpretations lead directly to reconstructing the estimated means for each group by combining the baseline and pertinent deviations as shown in Table 2-1.</p>\r\n\r\n<table class="border">\r\n<caption>Table 2-1: Constructing group mean estimates from the reference-coded linear model estimates.<caption>\r\n<tr><td>Group</td><td>Formula</td><td>Estimates</td></tr>	\r\n<tr><td>Beautiful</td><td>&#945;&#770;</td><td><strong>4.3333 years</strong></td></tr>\r\n<tr><td>Average</td><td>&#945;&#770; + &#964;&#770;<sub>2</sub></td><td>4.3333-0.3596=<strong>3.974</strong> years</td></tr>\r\n<tr><td>Unattractive</td><td>&#945;&#770; + &#964;&#770;<sub>3</sub></td><td>4.3333+1.4775=<strong>5.811</strong> years</td></tr>\r\n</table>\r\n<br>\r\n<p>We can also visualize the results of our linear models using what are called <em><strong>term</em></strong> or <em><strong>effect plots</em></strong> (from the <span class="code-font">effects</span> package; Fox, 2003) as displayed in Figure 2-2 (we don''t want to use "effect" unless we have random assignment in the study design so we will mainly call these <em><strong>term plots</em></strong>). These plots take an estimated model and show you its estimates along with 95% confidence intervals generated by the linear model, which will be especially useful for some of the more complicated models encountered later in the semester. To make this plot, you need to install and load the <span class="code-font">effects</span> package and then use <span class="code-font">plot(allEffects(...))</span> functions together on the <span class="code-font">lm</span> object called <span class="code-font">lm2</span> generated above. You can find the correspondence between the displayed means and the estimates that were constructed in Table 2-1.</p>\r\n<p><span class="code blue code-font">> require(effects)</span></p>\r\n<p><span class="code blue code-font">> plot(allEffects(lm2))</span></p>\r\n<br>\r\n <figure>\r\n<img src="../meta/img/Figure2.2.jpg" alt="Figure2.2">\r\n<figcaption><em>Figure 2-2: Plot of the estimated group mean sentences from the reference-coded model for the MockJury data.</em></figcaption>\r\n</figure>\r\n<br>\r\n<p>In order to assess evidence for having different means for the groups, we will compare either of the previous models (cell-means or reference-coded) to a null model based on the null hypothesis (H<sub>0</sub>: &#956;<sub>1</sub> =... = &#956;<sub>J</sub>) which implies a model of <em><span class="red">y<sub>ij</sub> = &#956; + &#949;<sub>ij</sub></span></em> in the cell-means version where <em><span class="red">&#956;</span></em> is a common mean for all the observations. We will call this the <em><span class="red">mean-only</span></em> model since it is boring and only has a single mean in it. In the reference-coding version of the model, we have a null hypothesis that H<sub>0</sub>: &#964;<sub>2</sub> =... = &#964;<sub>J</sub> = 0, so the "mean-only" model is <em><span class="red">y<sub>ij</sub> = &#945; + &#949;<sub>ij</sub></span></em> with <em><span class="red">&#945;</span></em> having the same definition as <em><span class="red">&#956;</span></em> for the cell means model - it forces a common estimate for every group. The <em>mean-only</em> model is also an example of a reduced model where we set some coefficients in the model to 0 and get a simpler model. Simple can be good as it is easy to interpret, but having a model for <em>J</em> groups that suggests no difference in the groups is not a very exciting result in most, but not all, situations. In order for R to provide results for the mean-only model, we remove the grouping variable, <span class="code-font">Attr</span>, from the model formula and just include a "1". The (<span class="code-font">Intercept</span>) row of the output provides the estimate for either model when we assume that the mean is the same for all groups:</p>\r\n<p><span class="code blue code-font">> lm3 <- lm(Years~1,data=MockJuryR)</span></p>\r\n<p><span class="code blue code-font">> summary(lm3)</span></p>\r\n<p><span class="code code-font">Coefficients:</span></p>\r\n<table class="code code-font">\r\n<tr><td></td><td>Estimate</td><td>Std. Error</td><td>t value</td><td>Pr(>|t|)</td></tr>  \r\n<tr><td>(Intercept)</td><td>4.6930</td><td>0.3404</td><td>13.79</td><td><2e-16</td><td>***</td></tr>\r\n</table>\r\n<p><span class="code code-font">Residual standard error: 3.634 on 113 degrees of freedom</span></p>\r\n<p>This model provides an estimate of the common mean for all observations of 4.693 = &#956;&#770;=&#945;&#770; years. This value also is the dashed, horizontal line in the beanplot in Figure 2-1. </p>', NULL, 'Chapter 2', '2.002', '2.1', 'Academic Journal', 'Academic Journal', 'Design_matrix#One-way_ANOVA_.28Cell_Means_Model.29', NULL, NULL, NULL, NULL, NULL, '2015-09-15 16:58:08', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(56, 'One-Way ANOVA Sums of Squares, Mean Squares, and F-test', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>The previous discussion showed two ways of estimating the model but still hasn''t addressed how to assess evidence related to whether the observed differences in the means among the groups is "real". In this section, we develop what is called the <em><strong>ANOVA F-test</em></strong> that provides a method of aggregating the differences among the means of 2 or more groups and testing our null hypothesis of no difference in the means vs the alternative. In order to develop the test, some additional notation needs to be defined. The sample size in each group is denoted <em>n<sub>j</sub></em> and the total sample size is <strong>N=&#931;n<sub>j</sub> = n<sub>1</sub>+n<sub>2</sub>+...+n<sub>J</sub></strong> where &#931; (capital sigma) means "add up over whatever follows". An estimated <em><strong>residual</em></strong> (e<sub>ij</sub>) is the difference between an observation, &#947;<sub>ij</sub>, and the model estimate, &#947;&#770;<sub>ij</sub>=&#956;&#770;<sub>j</sub>, for that observation, &#947;<sub>ij</sub> - &#947;&#770;<sub>ij</sub>=e<sub>ij</sub>. It is basically what is left over that the mean part of the model (&#956;&#770;<sub>j</sub>) does not explain and is our window into how "good" the model might be.</p>\r\n \r\n<figure>\r\n<img src="../meta/img/Figure2.3.jpg" alt="Figure2.3">\r\n<figcaption><em>Figure 2-3: Demonstration of different amount of difference in means relative to variability.</em></figcaption>\r\n</figure> \r\n\r\n\r\n<p>Consider the four different fake results for a situation with four groups in Figure 2-3. In Situation 1, it looks like there is little evidence for a difference in the means and in Situation 2, it looks fairly clear that there is a difference in the group means. Why? It is because the variation in the means looks "clear" relative to the variation around the means. Consider alternate versions of each result in Situations 3 and 4 and how much evidence there appears to be for same sizes of differences in the means. In the plots, there are two sources of variability in the responses - how much the group means vary across the groups and how much variability there is around the means in each group. So we need a test statistic to help us make some sort of comparison of the groups and to account for the amount of variability present around the means. The statistic is called the <em><strong>ANOVA F-statistic</em></strong>. It is developed using <em><strong>sums of squares</em></strong> which are measures of total variation like used in the numerator of the standard deviation <img src="../meta/img/Equation2.1.jpeg"  alt="Equation2.1" style="vertical-align:middle"> that took all the observations, subtracted the mean, squared the differences, and then added up the results over all the observations to generate a measure of total variability. With multiple groups, we will focus on decomposing that total variability (<em><strong>Total Sums of Squares</em></strong>) into variability among the means (we''ll call this <em><strong>Explanatory Variable A''s Sums of Squares</em></strong>) and variability in the residuals or errors (<em><strong>Error Sums of Squares</em></strong>). We define each of these quantities in the One-Way ANOVA situation as follows:</p>\r\n	<ul>\r\n	<li>&#9898;&#8195;<em><strong>SS<sub>Total</sub></em></strong> = Total Sums of Squares <img src="../meta/img/Equation2.2.jpeg"  alt="Equation2.2" style="vertical-align:middle">\r\n	<ul>\r\n	<li>&#9632;&#8195;By summing over all nj observations in each group <img src="../meta/img/Equation2.3.jpeg"  alt="Equation2.3" style="vertical-align:middle"> and then adding those results up across the groups <img src="../meta/img/Equation2.4.jpeg"  alt="Equation2.4" style="vertical-align:middle">, we accumulate the variation across all N observations.</li>\r\n	<li>&#9632;&#8195;Total variation is assessed by squaring the deviations of the responses around the overall or <em><strong>grand mean</em></strong> (&#947;&#831;, the estimated mean for all the observations and available from the mean-only model).</li>\r\n	<li>&#9632;&#8195;Note: this is the residual variation if the null model is used, so there is no further decomposition possible for that model.</li>\r\n	<li>&#9632;&#8195;This is also equivalent to the numerator of the sample variance which is what you get when you ignore the information on the potential differences in the groups.</li>\r\n</ul>\r\n</li>\r\n	<li>&#9898;&#8195;<em><strong>SS<sub>A</sub></em></strong> = Explanatory Variable A''s Sums of Squares <img src="../meta/img/Equation2.5.jpeg"  alt="Equation2.5" style="vertical-align:middle">\r\n	<ul>\r\n	<li>&#9632;&#8195;Variation in the group means around the grand mean based on explanatory variable A.</li>\r\n	<li>&#9632;&#8195;Also called sums of squares for the treatment, regression, or model.</li>\r\n</ul>\r\n</li>\r\n	<li>&#9898;&#8195;<em><strong>SS<sub>E</sub></em></strong> = Error (Residual) Sums of Squares <img src="../meta/img/Equation2.6.jpeg"  alt="Equation2.6" style="vertical-align:middle">\r\n	<ul>\r\n	<li>&#9632;&#8195;Variation in the responses around the group means.</li>\r\n	<li>&#9632;&#8195;Also called the sums of squares for the residuals.</li>\r\n</ul>\r\n</li>\r\n</ul>\r\n<p>The possibly surprising result given the mass of notation just presented is that the total sums of squares is ALWAYS equal to the sum of explanatory variable A''s sum of squares and the error sums of squares, <strong>SS<sub>Total</sub> = SS<sub>A</sub> + SS<sub>E</sub></strong>. This equality means that if the <strong>SS<sub>A</sub></strong> goes up, then the <strong>SS<sub>E</sub></strong> must go down if <strong>SS<sub>Total</sub></strong> remains the same. This result is called the <em><strong>sums of squares decomposition formula</em></strong>. We use these results to build our test statistic and organize this information in what is called an <em><strong>ANOVA table</em></strong>. The ANOVA table is generated using the <span class="code-font">anova</span> function applied to the reference-coded model:</p>\r\n<p><span class="code blue code-font">> lm2 <- lm(Years~Attr,data=MockJuryR)</span></p>\r\n<p><span class="code blue code-font">> anova(lm2)</span></p>\r\n<p><span class="code code-font">Analysis of Variance Table</span></p>\r\n<p><span class="code code-font">Response: Years</span></p>\r\n<table class="code code-font">\r\n<tr><td></td><td>Df</td><td><strong>Sum Sq</strong></td><td>Mean Sq</td><td>F value</td><td>Pr(>F)</td><td></td></tr>\r\n<tr><td>Attr</td><td>2</td><td><strong>70.94</strong></td><td>35.469</td><td>2.77</td><td>0.067</td><td>.</td></tr> \r\n<tr><td>Residuals</td><td>111</td><td><strong>1421.32</strong></td><td>12.805 </td></tr>\r\n</table>                \r\n                                    \r\n\r\n<p>Note that the ANOVA table has a row labelled <span class="code-font">Attr</span>, which contains information for the grouping variable (we''ll generally refer to this as explanatory variable A but here it is the picture group that was randomly assigned), and a row labelled <span class="code-font">Residuals</span>, which is synonymous with "Error". The SS are available in the <span class="code-font">Sum Sq</span> column. It doesn''t show a row for "Total" but the SS<sub>Total</sub> =SS<sub>A</sub>+SS<sub>E</sub> = 1492.26.</p>\r\n<p><span class="code blue code-font">> 70.94+1421.32</span></p>\r\n<p><span class="code code-font">[1] 1492.26</span></p>\r\n<p>It may be easiest to understand the sums of squares decomposition by connecting it to our permutation ideas. In a permutation situation, the total variation (SS<sub>Total</sub>) cannot change - it is the same responses varying around the grand mean. However, the amount of variation attributed to variation among the means and in the residuals can change if we change which observations go with which group. In Figure 2-4, the means and 95% confidence intervals are displayed for the three treatment levels. In panel (a), the results for the original data set (a) are presented including sums of squares. Three permuted versions of the data set are summarized in panels (b), (c), and (d). The SS<sub>A</sub> is 70.9 in the real data set and between 6.6 and 11 in the permuted data sets. If you had to pick among the plots for the one with the most evidence of a difference in the means, you hopefully would pick panel (a). This visual "unusualness" suggests that this observed result is unusual relative to the possibilities under permutations, which are, again, the possibilities tied to having the null hypothesis being true. But note that the differences are not that great between these permuted data sets and the real one. </p>\r\n<p>One way to think about <strong>SS<sub>A</sub></strong> is that it is a function that converts the variation in the group means into a single value. This makes it a reasonable test statistic in a permutation testing context. By comparing the observed SS<sub>A</sub>=70.9 to the permutation results of 6.7, 6.6, and 11 we see that the observed result is much more extreme than the three alternate versions. In contrast to our previous test statistics where positive and negative differences were possible, SS<sub>A</sub> is always positive with a value of 0 corresponding to no variation in the means. The larger the SS<sub>A</sub>, the more variation there was in the means. The permutation p-value for the alternative hypothesis of <strong>some</strong> (not of greater or less than!) difference in the true means of the groups will involve counting the number of permuted SS<sub>A</sub>* results that are larger than what we observed.</p>\r\n\r\n<figure><p>\r\n<img src="../meta/img/Figure2.4.jpg" alt="Figure2.4">\r\n<figcaption><em>Figure 2-4: Plot of means and 95% confidence intervals for the three groups for the real data (a) and three different permtutations of the treatment labels to the same responses in (b), (c), and (d).</em></figcaption></p>\r\n</figure>\r\n\r\n\r\n<p>To do a permutation test, we need to be able to calculate and extract the SS<sub>A</sub> value. In the ANOVA table, it is in the first row and is the second number and we can use the [,] referencing to extract that number from the ANOVA table that anova produces <span class="code-font">(anova(lm(Years~Attr,data=MockJury))[1,2])</span>. We''ll store the observed value of SSA is <span class="code-font">Tobs:</span></p>\r\n<p><span class="code blue code-font">> Tobs <- anova(lm(Years~Attr,data=MockJury))[1,2]; Tobs</span></p>\r\n<p><span class="code code-font">[1] 70.93836</span></p>\r\n\r\n<p>The following code performs the permutations using the <span class="code-font">shuffle</span> function and then makes a plot of the resulting permutation distribution:</p>\r\n<p><span class="code blue code-font">> B<-1000</span></p>\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-anova(lm(Years~shuffle(Attr),data=MockJury))[1,2]</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=3)</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=3)</span></p>\r\n\r\n <figure>\r\n<img src="../meta/img/Figure2.5.jpg" alt="Figure2.5">\r\n<figcaption><em>Figure 2-5: Permutation distributions of SS<sub>A</sub> with the observed value of SS<sub>A</sub> (bold, vertical line).</em></figcaption>\r\n</figure>\r\n\r\n\r\n<p>The right-skewed distribution (Figure 2-5) contains the distribution of SS<sub>A</sub>*''s under permutations (where all the groups are assumed to be equivalent under the null hypothesis). While the observed result is larger than many SS<sub>A</sub>*''s, there are also many results that are much larger than observed that showed up when doing permutations. The proportion of permuted results that exceed the observed value is found using <span class="code-font">pdata</span> as before, except only for the area to the right of the observed result. We know that Tobs will always be positive so no absolute values are required now.</p>\r\n<p><span class="code blue code-font">> pdata(Tobs,Tstar,lower.tail=F)</span></p>\r\n<p><span class="code code-font">[1] 0.071</span></p>\r\n\r\n<p>This provides a permutation-based p-value of 0.071 and suggests marginal evidence against the null hypothesis of no difference in the true means. We would interpret this as saying that there is a 7.1% chance of getting a SS<sub>A</sub> as large or larger than we observed, given that the null hypothesis is true.</p>\r\n	<p>It ends up that some nice parametric statistical results are available (if our assumptions are met) for the ratio of estimated variances, which are called <strong><em>Mean Squares</strong></em>. To turn sums of squares into mean square (variance) estimates, we divide the sums of squares by the amount of free information available. For example, remember the typical variance estimator introductory statistics, <img src="../meta/img/Equation2.7.jpeg"  alt="Equation2.7" style="vertical-align:middle">, where we "lose" one piece of information to estimate the mean and there are N deviations around the single mean so we divide by N-1. Now consider <img src="../meta/img/Equation2.8.jpeg" alt="Equation2.8" style="vertical-align:middle">  which still has N deviations but it varies around the J means, so the <strong><em>Mean Square Error</strong></em> = MS<sub>E</sub> = SS<sub>E</sub>/(N-J). Basically, we lose J pieces of information in this calculation because we have to estimate J means. The sums of squares for explanatory variable A is harder to see in the formula <img src="../meta/img/Equation2.9.jpeg"  alt="Equation2.9" style="vertical-align:middle">, but the same reasoning can be used to understand the denominator for forming the <strong><em>Mean Square for variable A</strong></em> or MS<sub>A</sub>: there are <em>J</em> means that vary around the grand mean so MS<sub>A</sub> = SS<sub>A</sub>/(<em>J</em>-1). In summary, the two mean squares are simply:</p>\r\n	<ul>\r\n	<li>&#9632;&#8195;MS<sub>A</sub> = SS<sub>A</sub>/(<em>J</em>-1), which estimates the variance of the group means around the grand mean.</li>\r\n	<li>&#9632;&#8195;MS<sub>Error</sub> = SS<sub>Error</sub>/(<em>N-J</em>), which estimates the variation of the errors around the group means.</li>\r\n	</ul>\r\n<p>These results are put together using a ratio to define the <strong><em>ANOVA F-statistic</strong></em> (also called the <strong><em>F-ratio</strong></em>) as</p> \r\n<p align="center"><em>F</em>=MS<sub>A</sub>/MS<sub>Error</sub>.</p>\r\n<p>This statistic is close to 1 if the variability in the means is "similar" to the variability in the residuals and would lead to no evidence being found of a difference in the means. If the MS<sub>A</sub> is much larger than the MS<sub>E</sub>, the <em>F</em>-statistic will provide evidence against the null hypothesis. The "size" of the <em>F</em>-statistic is formalized by finding the p-value. The <em>F</em>-statistic, if assumptions discussed below are met and we assume the null hypothesis is true, follows an <em>F</em>-distribution. The <strong><em>F-distribution</strong></em> is a right-skewed distribution whose shape is defined by what are called the <strong><em>numerator degrees of freedom</strong></em> (<em>J</em>-1) and the <strong><em>denominator degrees of freedom</strong></em> <em>(N-J)</em>. These names correspond to the values that we used to calculate the mean squares and where in the <em>F</em>-ratio each mean square was used; <em>F</em>-distributions are denoted by their degrees of freedom using the convention of <em>F(numerator df, denominator df)</em>. Some examples of different <em>F</em>-distributions are displayed for you in Figure 2-6.</p>\r\n \r\n<figure>\r\n<img src="../meta/img/Figure2.6.jpg" alt="Figure2.6">\r\n<figcaption><em>Figure 2-6: Density curves of four different F-distributions.</em></figcaption>\r\n</figure>\r\n\r\n<p>The characteristics of the F-distribution can be summarized as:</p>\r\n<ul>\r\n	<li>&#9898;&#8195;Right skewed,</li>\r\n	<li>&#9898;&#8195;Nonzero probabilities for values greater than 0,</li>\r\n	<li>&#9898;&#8195;Shape changes depending on the <strong>numerator</strong> and <strong>denominator DF</strong>, and</li>\r\n	<li>&#9898;&#8195;<strong>Always use the right-tailed area for p-values.</strong></li>\r\n</ul>\r\n<p>Now we are ready to see an ANOVA table when we know about all its components. Note the general format of the ANOVA table is<sup><a id="22top" href="#22ft">22</a></sup>:</p>\r\n<table class="border">\r\n<caption><em>Table 2-2: General One-Way ANOVA table.</em></caption>\r\n<tr><td>Source</td><td>DF</td><td>Sums of Squares</td><td>Mean Squares</td><td>F-ratio</td><td>P-value</td></tr>\r\n<tr><td>Variable A</td><td><em>J</em>-1</td><td>SS<sub>A</sub></td><td>MS<sub>A</sub> = SS<sub>A</sub>/(<em>J</em>-1)</td><td>F=MS<sub>A</sub>/MS<sub>E</sub></td><td>Right tail of F(<em>J</em>-1,N-<em>J</em>)</td></tr>	\r\n<tr><td>Residuals</td><td>N-<em>J</em></td><td>SS<sub>E</sub></td><td>MS<sub>E</sub> =SS<sub>E</sub>/(N-J)</td> <td></td><td></td></tr>						\r\n<tr><td>Total</td><td><em>N</em>-1</td><td>SS<sub>Total</sub></td><td></td><td></td><td></td></tr>\r\n</table>											\r\n<p>The table is oriented to help you reconstruct the <em>F</em>-ratio from each of its components. The output from R is similar although it does not provide the last row. The R version of the table for the type of picture effect (<span class="code-font">Attr</span>) with <em>J</em>=3 levels and <em>N</em>=114 observations, repeated from above, is:</p>\r\n<p><span class="code blue code-font">> anova(lm2)</span></p>\r\n<p><span class="code code-font">Analysis of Variance Table</span></p>\r\n<p><span class="code code-font">Response: Years</span></p>\r\n<table class="code code-font">\r\n<tr><td></td><td>Df</td><td>Sum Sq</td><td>Mean Sq</td><td>F value</td><td>Pr(>F)</td><td></td></tr>                 \r\n<tr><td>Attr</td><td>2</td><td>70.94</td><td>35.469</td><td>2.77</td><td>0.067</td><td>.</td></tr>              \r\n<tr><td>Residuals</td><td>111</td><td>1421.32</td><td>12.805</td></tr>\r\n</table>\r\n\r\n<p>The p-value from the <em>F</em>-distribution is 0.067. We can verify this result using the observed F-statistic of 2.77 (which came from the ratio of the means squares: 35.47/12.8) which follows an F(2,111) if the null hypothesis is true and other assumptions are met. Using the <span class="code-font">pf</span> function provides us with areas in the specified F-distribution with the <span class="code-font">df1</span> provided to the function as the numerator <span class="code-font">DF</span> and <span class="code-font">df2</span> as the denominator and <span class="code-font">lower.tail=F</span> reflecting our desire for a right tailed area.</p>\r\n<p><span class="code blue code-font">> pf(2.77,df1=2,df2=111,lower.tail=F)</span></p>\r\n<p><span class="code code-font">[1] 0.06699803</span></p>\r\n\r\n	<p>The result from the F-distribution using this parametric procedure is similar to the p-value obtained using permutations with the test statistic of the SS<sub>A</sub>, which was 0.071. The <em>F</em>-statistic obviously is another potential test statistic to use as a test statistic in a permutation approach. We should check that we get similar results from it with permutations as we did from using SS<sub>A</sub> as a test statistic. The following code generates the permutation distribution for the <em>F</em>-statistic (Figure 2-7) and assesses how unusual the observed <em>F</em>-statistic of 2.77 was in this permutation distribution. The only change in the code involves moving from extracting SS<sub>A</sub> to extracting the <em>F</em>-ratio which is in the 4<sup>th</sup> column of the <span class="code-font">anova</span> output:</p>\r\n<p><span class="code blue code-font">> anova(lm(Years~Attr,data=MockJury))[1,4]</span></p>\r\n<p><span class="code code-font">[1] 2.770024</span></p>\r\n<p><span class="code blue code-font">> Tobs <- anova(lm(Years~Attr,data=MockJury))[1,4]; Tobs</span></p>\r\n<p><span class="code code-font">[1] 2.770024</span></p>\r\n<p><span class="code blue code-font">> B<-1000</span></p>\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-anova(lm(Years~shuffle(Attr),data=MockJury))[1,4]</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p><span class="code blue code-font">> hist(Tstar,labels=T)</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=3)</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=3)</span></p>\r\n<p><span class="code blue code-font">> pdata(Tobs,Tstar,lower.tail=F)</span></p>\r\n<p><span class="code code-font">[1] 0.064</span></p>\r\n\r\n<figure>\r\n<img src="../meta/img/Figure2.7.jpg" alt="Figure2.7">\r\n<figcaption><em>Figure 2-7: Permutation distribution of the F-statistic with bold, vertical line for observed value of test statistic of 2.77.</em></figcaption>\r\n</figure> \r\n\r\n\r\n<p>The permutation-based p-value is 0.064 which, again, matches the other results closely. The first conclusion is that using a test statistic of the F-statistic or the SS<sub>A</sub> provide similar permutation results. However, we tend to favor using the F-statistic because it is more commonly used in reporting ANOVA results, not because it is any better in a permutation context.</p>\r\n	<p>It is also interesting to compare the permutation distribution for the <em>F-statistic</em> and the parametric <em>F</em>(2,111) distribution (Figure 2-8). They do not match perfectly but are quite similar. Some the differences around 0 are due to the behavior of the method used to create the density curve and are not really a problem for the methods. This explains why both methods give similar results. In some situations, the correspondence will not be quite to close.</p>\r\n\r\n<figure>\r\n<img src="../meta/img/Figure2.8.jpg" alt="Figure2.8">\r\n<figcaption><em>Figure 2-8: Comparison of F(2,111) (dashed line) and permutation distribution (solid line).</em></figcaption>\r\n</figure>\r\n\r\n\r\n<p>So how can we rectify this result (p-value&#8776;0.06) and the Chapter 1 result that detected a difference between <em>Average</em> and <em>Unattractive</em> with a p-value&#8776;0.03? I selected the two groups to compare in Chapter 1 because they were furthest apart. "Cherry-picking" the comparison that is likely to be most different creates a false sense of the real situation and inflates the Type I error rate because of the selection. If the entire suite of comparisons are considered, this result may lose some of its luster. In other words, if we consider the suite of all pair-wise differences (and the tests) implicit in comparing all of them, we need stronger evidence in the most different pair than a p-value of 0.033 to suggest overall differences. The <em>Beautiful</em> and <em>Average</em> groups are not that different from each other so they do not contribute much to the overall <em>F-test</em>. In Section 2.5, we will revisit this topic and consider a method that is statistically valid for performing all possible pair-wise comparisons.</p>', '<p><sup><a id="22ft" href="#22top">22</a></sup>Make sure you can work from left to right and up and down to fill in the ANOVA table given just the necessary information to determine the other components - there is always a question like this on the exam...</p>', 'Chapter 2', '2.003', '2.2', 'Textbook', 'Textbook', 'Design_matrix#One-way_ANOVA_.28Cell_Means_Model.29', NULL, NULL, NULL, NULL, NULL, '2015-09-15 17:26:55', NULL, NULL, NULL, NULL),
(57, 'ANOVA model diagnostics including QQ-plots', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>The requirements for a One-Way ANOVA <em>F</em>-test are similar to those discussed in Chapter 1, except that there are now <em>J</em> groups instead of only 2. Specifically, the linear model assumes:</p>\r\n<ul><strong>\r\n<li>1) Independent observations</li> \r\n<li>2) Equal variances</li>\r\n<li>3) Normal distributions</li></strong>\r\n</ul>\r\n<p>For assessing equal variances across the groups, we must use plots to assess this. We can use boxplots and beanplots to compare the spreads of the groups, which are provided in Figure 2-1. The range and IQRs should be similar across the groups, although you should always note how clear or big the violation of the assumption might be, remembering that there will always be some differences in the variation among groups. In this section, we learn how to work with the diagnostic plots that are provided from the <span class="code-font">lm</span> function that can help us more clearly assess potential violations of the previous assumptions.</p> \r\n<p>We can obtain a suite of diagnostic plots by using the <span class="code-font">plot</span> function on the ANOVA model object that we fit. To get all of the plots together in four panels we need to add the <span class="code-font">par(mfrow=c(2,2))</span> command to tell R to make a graph with 4 panels <sup><a id="23top" href="#23ft">23</a></sup>.</p>\r\n<p><span class="code blue code-font">> par(mfrow=c(2,2))</span></p>\r\n<p><span class="code blue code-font">> plot(lm2)</span></p>\r\n\r\n<p>There are two plots in Figure 2-9 with useful information for the equal variance assumption. The "Residuals vs Fitted" in the top left panel displays the residuals (e<sub>ij</sub>= &#947;<sub>ij</sub> - &#947;&#770;<sub>ij</sub>) on the y-axis and the fitted values (&#947;&#770;<sub>ij</sub>) on the x-axis. This allows you to see if the variability of the observations differs across the groups because all observations in the same group get the same fitted value. In this plot, the points seem to have fairly similar spreads at the fitted values for the three groups of 4, 4.3, and 6. The "Scale-Location" plot in the lower left panel has the same x-axis but the y-axis contains the square-root of the absolute value of the standardized residuals. The absolute value transforms all the residuals into a magnitude scale (removing direction) and the square-root helps you see differences in variability more accurately. The usage is similar in the two plots - you want to assess whether it appears that the groups have somewhat similar or noticeably different amounts of variability. If you see a clear funnel shape in the Residuals vs Fitted or an increase or decrease in the edge of points in the Scale-Location plot, that may indicate a violation of the constant variance assumption. Remember that some variation across the groups is expected and is ok, but large differences in spreads are problematic for all the procedures we will learn this semester.</p>\r\n \r\n\r\n<figure>\r\n<img src="../meta/img/Figure2.9.jpg" alt="Figure2.9">\r\n<figcaption><em>Figure 2-9: Default diagnostic plots for the linear model.</em></figcaption>\r\n</figure>\r\n	<p>The linear model assumes that all the random errors () follow a normal distribution. To gain insight into the validity of this assumption, we can explore the original observations, mentally subtracting off the differences in the means and focusing on the shapes of the distributions of observations in each group in the boxplot and beanplot. These plots can help us assess whether there is there a skew or outliers present in each group. If so, by definition, the normality assumption is violated. But sometimes the differen groups might contain different "non-normal" features and this can make an overall assessment complicated. Our real interest in these diagnostics is to understand how reasonable our assumption is overall for our model. The residuals from the entire model provide us with estimates of the random errors and if the normality assumption is met, then the residuals all-together should approximately follow a normal distribition. The <strong><em>Normal Q-Q Plot</strong></em> in upper right panel of Figure 2-9 is a direct visual assessment of how well our residuals match what we would expect from a normal distribution. Outliers, skew, heavy and light-tailed aspects of distributions (all violations of normality) will show up in this plot once you learn to read it - which is our next task. To make it easier to read QQ-plots, it is nice to start with just considering histograms and/or density plots of the residuals. We can obtain the residuals from the linear model using the residuals function on the linear model object.</p>\r\n<p><span class="code blue code-font">> eij=residuals(lm2)</span></p>\r\n<p><span class="code blue code-font">> hist(eij,main="Histogram of residuals")</span></p>\r\n<p><span class="code blue code-font">> plot(density(eij),main="Density plot of residuals",ylab="Density",xlab="Residuals")</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure2.10.jpg" alt="Figure2.10">\r\n<figcaption><em>Figure 2-10: Histogram and density curve of the linear model raw residuals.</em></figcaption>\r\n</figure> \r\n\r\n\r\n<p>Figure 2-10 shows that there is a right skew present in the residuals, which is consistent with the initial assessment of some right skew in the plots of observations in each group. </p>\r\n	<p>A Quantile-Quantile plot (<strong><em>QQ-plot</strong></em>) shows the "match" of an observed distribution with a theoretical distribution, almost always the normal distribution. They are also known as Quantile Comparison, Normal Probability, or Normal Q-Q plots, with the last two names being specific to comparing results to a normal distribution. In this version<sup><a id="24top" href="#24ft">24</a></sup> , the QQ-plots display the value of observed percentiles in the residual distribution on the y-axis versus the percentiles of a theoretical normal distribution on the x-axis. If the observed <strong>distribution of the residuals matches the shape of the normal distribution, then the plotted points should follow a 1-1 relationship</strong>. If the points follow the displayed straight line that suggests that the residuals have a similar shape to a normal distribution. Some variation is expected around the line and some patterns of deviation are worse than others for our models, so you need to go beyond saying "it does not match a normal distribution" and be specific about the type of deviation you are detecting. And to do that, we need to practice interpreting some QQ-plots.</p>\r\n	<p>I extracted the previous QQ-plot of the linear model residuals and enhanced it a little to make Figure 2-11. We know from looking at the histogram that this is a slightly right skewed distribution. The QQ-plot places the observed <strong><em>standardized</strong></em><sup><a id="25top" href="#25ft">25</a></sup> <strong><em>residuals</strong></em> on the y-axis and the theoretical normal values on the x-axis. The most noticeable deviation from the 1-1 line is in the lower left corner of the plot. These are for the negative residuals (left tail) and there are many residuals at around the same value a little smaller than -1. If the distribution had followed the normal here, the points would be on the 1-1 line and would actually be even smaller. So we are not getting as much spread in the lower observations as we would expect in a normal distribution. If you go back to the histogram you can see that the lower observations are all stacked up and do not spread out like the left tail of a normal distribution should. In the right tail (positive) residuals, there is also a systematic lifting from the 1-1 line to larger values in the residuals than the normal would generate. For example, the point labeled as "82" (the 82<sup>nd</sup> observation in the data set) has a value of 3 in residuals but should actually be smaller (maybe 2.5) if the distribution was normal. Put together, this pattern in the QQ-plot suggests that the left tail is too compacted (too short) and the right tail is too spread out - this is the right skew we identified from the histogram and density curve!</p>\r\n \r\n\r\n<figure>\r\n<img src="../meta/img/Figure2.11.jpg" alt="Figure2.11">\r\n<figcaption><em>Figure 2-11: QQ-plot of residuals from linear model.</em></figcaption>\r\n</figure> \r\n<p>Generally, when both tails deviate on the same side of the line (forming a sort of quadratic curve, especially in more extreme cases), that is evidence of a skew. To see some different potential shapes QQ-plots, six different data sets are Figures 2-12 and 2-13. In each row, a QQ-plot and density curve are displayed. If the points are both above the 1-1 line in the lowr and upper tails as in Figure 2-12(a), then the pattern is a right skew, here even more extreme than in the real data set. If the points are below the 1-1 line in both tails as in Figure 2-12(c), then the pattern should be identified as a left skew. These are both problematic for models that assume normally distributed responses but not necessarily for our permutation approaches if all the groups have similar skewed shapes. The other problematic pattern is to have more spread than a normal curve as in Figure2-12(e) and (f). This shows up with the points being below the line in the left tail (more extreme negative than expected by the normal) and the points being above the line for the right tail (more extreme positive than the normal). We call these distributions <strong><em>heavy-tailed</strong></em> and can manifest as distributions with outliers in both tails or just a bit more spread out than a normal distribution. Heavy-tailed residual distributions can be problematic for our models as the variation is greater than what the normal distribution can account for and our methods might under-estimate the variability in the results. The opposite pattern with the left tail above the line and the right tail below the line suggests less spread (<strong><em>lighter-tailed</strong></em>) than a normal as in Figure 2-12(g) and (h). This pattern is relatively harmless and you can proceed with methods that assume normality safely. </p>\r\n \r\n\r\n<figure>\r\n<img src="../meta/img/Figure2.12.jpg" alt="Figure2.12">\r\n<figcaption><em>Figure 2-12: QQ-plots and density curves of four fake distributions with different shapes.</em></figcaption>\r\n</figure> \r\n<p>Finally, to help you calibrate expectations for data that are actually normally distributed, two data sets simulated from normal distributions are displayed below in Figure 2-13. Note how neither follows the line exactly but that the overall pattern matches fairly well. <strong><em>You have to allow for some variation from the line in real data sets</strong></em> and focus on when there are really noticeable issues in the distribution of the residuals such as those displayed above.</p>\r\n \r\n\r\n<figure>\r\n<img src="../meta/img/Figure2.13.jpg" alt="Figure2.13">\r\n<figcaption><em>Figure 2-13: Two more simulated data sets, generated from normal distributions.</em></figcaption>\r\n</figure> \r\n	<p>The last issues with assessing the assumptions in an ANOVA relates to situations where the models are more or less <strong><em>resistant</strong></em><sup><a id="26top" href="#26ft">26</a></sup>.  to violations of assumptions. For reasons beyond the scope of this class, the parametric ANOVA F-test is more resistant to violations of the assumptions of the normality and equal variance assumptions if the design is balanced. A <strong><em>balanced design</strong></em> occurs when each group is measured the same number of times. The resistance decreases as the data set becomes less balanced, so having close to balance is preferred to a more imbalanced situation if there is a choice available. There is some intuition available here - it makes some sense that you would have better results if all groups are equally (or nearly equally) represented in the data set. We can check the number of observations in each group to see if they are equal or similar using the <span class="code-font">tally</span> function from the <span class="code-font">mosaic</span> package:</p>\r\n<p><span class="code blue code-font">> tally(~Attr,data=MockJuryR)</span></p>\r\n<table class="code code-font">\r\n<tr><td>Beautiful</td><td>Average</td><td>Unattractive</td><td>Total</td></tr>\r\n<tr><td>39</td><td>38</td><td>37</td><td>114</td></tr>\r\n</table>\r\n\r\n<p>So the sample sizes do vary among the groups and the design is technically not balanced, but it is also very close to being balanced. This tells us that the <em>F</em>-test so should have some resistance to violations of assumptions. This nearly balanced design, and the moderate sample size, make the parametric and nonparametric approaches provide similar results in this data set.</p>', '<p><sup><a id="23ft" href="#23top">23</a></sup>We have been using this function quite a bit to make multi-panel graphs but you will always want to use this command for linear model diagnostics or your will have to use the arrows above the plots to go back and see previous plots.</p>\r\n<p><sup><a id="24ft" href="#24top">24</a></sup>Along with multiple names, there is variation of what is plotted on the x and y axes and the scaling of the values plotted, increasing the challenge of interpreting QQ-plots. We will try to be consistent about the x and y axis choices.</p>\r\n  <p><sup><a id="25ft" href="#25top">25</a></sup>Here this means re-scaled so that they should have similar scaling to a standard normal with mean 0 and standard deviation 1. This does not change the shape of the distribution but can make outlier identification by value of the residuals simpler - having a standardized residual more extreme than 5 or -5 would suggest a deviation from normality. But mainly focus on the shape of the pattern in the QQ-plot.</p>\r\n<p><sup><a id="26ft" href="#26top">26</a></sup>A resistant procedure is one that is not severely impacted by a particular violation of an assumption. For example, the median is resistant to the impact of an outlier.</p>\r\n', 'Chapter 2', '2.004', '2.3', 'Textbook', 'Textbook', 'Q-Q plot', NULL, NULL, NULL, NULL, NULL, '2015-09-02 16:36:59', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(58, 'Guinea pig tooth growth One-Way ANOVA example', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>A second example of the One-way ANOVA methods involves a study of growth rates of the teeth of Guinea Pigs (measured in millimeters, mm). <em>N</em>=60 Guinea Pigs were obtained from a local breeder and each received Orange Juice (<em>OJ</em>) or ascorbic acid (the stuff in vitamin C capsules, called <em>VC below</em>) at one of three dosages (0.5, 1, or 2 mg) as a source of added Vitamin C in their diets. Each guinea pig was randomly assigned to receive one of the six different treatment combinations possible (OJ at 0.5 mg, OJ at 1 mg, OJ at 2 mg, VC at 0.5 mg, VC at 1 mg, and VC at 2 mg). The animals were treated similarly otherwise and we can assume lived in separate cages. We need to create a variable that combines the levels of delivery type (OJ, VC) and the dosages (0.5, 1, and 2) to use our One-Way ANOVA on the six levels. The <span class="code-font">interaction</span> function creates a new variable in the <span class="code-font">ToothGrowth</span> data.frame that we called <span class="code-font">Treat</span> that will be used as a six-level grouping variable.</p>\r\n<p><span class="code blue code-font">> data(ToothGrowth) #Available in Base R package</span></p>\r\n<p><span class="code blue code-font">> ToothGrowth$Treat=with(ToothGrowth,interaction(supp,dose)) #Creates a new variable Treat with 6 levels</span></p>\r\n<p>The <span class="code-font">tally</span> function helps us to check for balance; this is a balanced design because the same number of guinea pigs (<em>nj</em>=10 for all <em>j</em>) were measured in each treatment combination.</p>\r\n<p><span class="code blue code-font">> require(mosaic)</span></p>\r\n<p><span class="code blue code-font">> tally(~Treat,data=ToothGrowth)</span></p>\r\n<table class="code code-font">\r\n<tr><td>OJ.0.5</td><td>VC.0.5</td><td>OJ.1</td><td>VC.1</td><td>OJ.2</td><td>VC.2</td></tr>\r\n<tr><td>10</td><td>10</td><td>10</td><td>10</td><td>10</td><td>10 </td></tr>\r\n</table>\r\n<br></br>\r\n<p>The next task is to visualize the results using boxplots and beanplots<sup><a id="27top" href="#27ft">27</a></sup>  (Figure 2-14) and generate some summary statistics for each group using <span class="code-font">favstats</span>.</p> \r\n<p><span class="code blue code-font">> par(mfrow=c(1,2))</span></p>\r\n<p><span class="code blue code-font">> boxplot(len~Treat,data=ToothGrowth,ylab="Tooth Growth in mm")</span></p>\r\n<p><span class="code blue code-font">> beanplot(len~Treat,data=ToothGrowth,log="",col="yellow",method="jitter")</span></p>\r\n<p><span class="code blue code-font">> favstats(len~Treat,data=ToothGrowth)</span></p>\r\n<table class="code code-font">\r\n<tr><td></td><td>.group</td><td>min</td><td>Q1</td><td>median</td><td>Q3</td><td>max</td><td>mean </td><td>sd</td><td>n</td><td>missing</td></tr>\r\n<tr><td>1</td><td>OJ.0.5</td><td>8.2</td><td>9.700</td><td>12.25</td><td>16.175</td><td>21.5</td><td>13.23</td><td>4.459709</td><td>10</td><td>0</td></tr>\r\n<tr><td>2</td><td>VC.0.5</td><td>4.2</td><td>5.950</td><td>7.15</td><td>10.900</td><td>11.5</td><td>7.98</td><td>2.746634</td><td>10</td><td>0</td></tr>\r\n<tr><td>3</td><td>OJ.1</td><td>14.5</td><td>20.300</td><td>23.45</td><td>25.650</td><td>27.3</td><td>22.70</td><td>3.910953</td><td>10</td><td>0</td></tr>\r\n<tr><td>4</td><td>VC.1</td><td>13.6</td><td>15.275</td><td>16.50</td><td>17.300</td><td>22.5</td><td>16.77</td><td>2.515309</td><td>10</td><td>0</td></tr>\r\n<tr><td>5</td><td>OJ.2</td><td>22.4</td><td>24.575</td><td>25.95</td><td>27.075</td><td>30.9</td><td>26.06</td><td>2.655058</td><td>10</td><td>0</td></tr>\r\n<tr><td>6</td><td>VC.2</td><td>18.5</td><td>23.375</td><td>25.95</td><td>28.800</td><td>33.9</td><td>26.14</td><td>4.797731</td><td>10</td><td>0</td></tr>\r\n</table>\r\n<br></br>\r\n<p>Figure 2-14 suggests that the mean tooth growth increases with the dosage level and that OJ might lead to higher growth rates than VC except at dosages of 2 mg. The variability around the means looks to be small relative to the differences among the means, so we should expect a small p-value from our <em>F</em>-test. The design is balanced as noted above (<em>nj</em> = 10 for all six groups) so the methods are somewhat resistant to impacts from non-normality and non-constant variance. There is some suggestion of non-constant variance in the plots but this will be explored further below when we can visually remove the difference in the means from this comparison. There might be some skew in the responses in some of the groups but there are only 10 observations per group so skew in the boxplots could be generated by very few observations.</p>\r\n<figure>\r\n<img src="../meta/img/Figure2.14.jpg" alt="Figure2.14">\r\n<figcaption><em>Figure 2-14: Boxplot and beanplot of tooth growth responses for the six treatment level combinations.</em></figcaption>\r\n</figure> \r\n<p>Now we can apply our 6+ steps for performing a hypothesis test with these observations. The initial step is deciding on the claim to be assessed and the test statistic to use. This is a six group situation with a quantitative response, identifying it as a One-Way ANOVA where we want to test a null hypothesis that all the groups have the same population mean. We will use a 5% significance level.</p>\r\n<li><strong>1)&#8195;Hypotheses: H<sub>0</sub>: &#956;<sub>OJ0.5</sub> = &#956;<sub>VC0.5</sub> = &#956;<sub>OJ1</sub> = &#956;<sub>VC1</sub> = &#956;<sub>OJ2</sub> = &#956;<sub>VC2</sub> vs H<sub>A</sub>: Not all &#956;<sub>j</sub> equal </strong>\r\n	<ul>\r\n	<li>&#8226;&#8195;The null hypothesis could also be written in reference-coding as H<sub>0</sub>: &#964;<sub>VC0.5</sub> = &#964;<sub>OJ1</sub> = &#964;<sub>VC1</sub> = &#964;<sub>OJ2</sub> = &#964;<sub>VC2</sub> = 0 since OJ.0.5 is chosen as the baseline group (discussed below).\r\n	<li>&#8226;&#8195;The alternative hypothesis can be left a bit less specific: H<sub>A</sub>: Not all &#964;<sub>j</sub> equal 0.\r\n	</ul>\r\n	</li>\r\n	</li>\r\n	</li>\r\n	<li><strong>2)&#8195;Validity conditions:</strong>\r\n	<ul>\r\n	<li>&#8226;&#8195;Independence:\r\n	<ul>\r\n	<li>&#9675;&#8195;This is where the separate cages note above is important. Suppose that there were cages that contained multiple animals and they competed for food or could share illness. The animals in one cage might be systematically different from the others and this "clustering" of observations would present a potential violation of the independence assumption. If the experiment had the animals in separate cages, there is no clear dependency in the design of the study and can assume that there is no problem with this assumption.</li>\r\n	</ul>	\r\n	\r\n	<li>&#8226;&#8195;Constant variance:\r\n	<ul>\r\n	<li>&#9675;&#8195;As noted above, there is some indication of a difference in the variability among the groups in the boxplots but the sample size was small in each group. We need to fit the linear model to get the other diagnostic plots to make an overall assessment.</li>\r\n	</ul>\r\n	</ul>\r\n<p><span class="code blue code-font">> m2=lm(len~Treat,data=ToothGrowth)</span></p>\r\n<p><span class="code blue code-font">> par(mfrow=c(2,2))</span></p>\r\n<p><span class="code blue code-font">> plot(m2)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure2.15.jpg" alt="Figure2.15">\r\n<figcaption><em>Figure 2-15: Diagnostic plots for the toothgrowth model.</em></figcaption>\r\n</figure> \r\n\r\n<ul><ul>\r\n	<li>&#9675;&#8195;The Residuals vs Fitted panel in Figure 2-15 shows some difference in the spreads but the spread is not that different between the groups.</li>\r\n	<li>&#9675;&#8195;The Scale-Location plot also shows just a little less variability in the group with the smallest fitted value but the spread of the groups looks fairly similar in this alternative scaling.</li> \r\n	<li>&#9675;&#8195;Put together, the evidence for non-constant is not that strong and we can assume that there is at least not a major problem with this assumption.\r\n	\r\n	</li></ul></ul>\r\n	<ul><li>&#8226;&#8195;Normality of residuals:\r\n	\r\n	<ul><li>&#9675;&#8195;The Normal Q-Q plot shows a small deviation in the lower tail but nothing that we wouldn''t expect from a normal distribution. There is no evidence of a problem with this assumption in the upper right panel of Figure 2-15.	</li></ul>\r\n	</li>\r\n	</li></li></li>\r\n	</ul>\r\n	\r\n	<li><strong>3)&#8195;Calculate the test statistic:</strong>\r\n	<ul>\r\n	<li>&#8226;&#8195;The ANOVA table for our model follows, providing an F-statistic of 41.557:</li>\r\n	</ul>\r\n	</li>\r\n<p><span class="code blue code-font">> anova(m2)</span></p>\r\n<p><span class="code code-font">Analysis of Variance Table</span></p>\r\n<table class="code code-font">\r\n<tr><td>Response: len</td></tr>\r\n<tr><td></td><td>Df</td><td>Sum Sq</td><td>Mean Sq</td><td>F value</td><td>Pr(>F)</td></tr>  \r\n<tr><td>Treat</td><td>5</td><td>2740.10</td><td>548.02</td><td>41.557</td><td>< 2.2e-16</td><td>***</td></tr>\r\n<tr><td>Residuals</td><td>54</td><td>712.11</td><td>13.19</td></tr>\r\n</table>\r\n	<li><strong>4)&#8195;Find the p-value:</strong>\r\n	<ul>\r\n	<li>&#8226;&#8195;There are two options here, especially since it seems that our assumptions about variance and normality are not violated (note that we do not say "met" - we just have no strong evidence against them). The parametric and nonparametric approaches should provide similar results here.</li>\r\n	<li>&#8226;&#8195;The parametric approach is easiest - the p-value comes from the previous ANOVA table as <2.2e-16. This is in scientific notation and means it is at the numerical precision of the computer and it reports that this is a very small number. You report that the p-value<0.00001 but should not report that it is 0. This p-value came from an F(5,54) distribution (the distribution of the test statistic if the null hypothesis is true).</li>\r\n	<li>&#8226;&#8195;The nonparametric approach is not too hard so we can compare the two approaches here.</li></li></ul>\r\n<p><span class="code blue code-font">> Tobs <- anova(lm(len~Treat,data=ToothGrowth))[1,4]; Tobs</span></p>\r\n<p><span class="code code-font">[1] 41.55718</span></p>\r\n<p><span class="code blue code-font">> par(mfrow=c(1,2))</span></p>\r\n<p><span class="code blue code-font">> B<- 1000</span></p>\r\n<p><span class="code blue code-font">> Tstar<-matrix(NA,nrow=B)</span></p>\r\n<p><span class="code blue code-font">> for (b in (1:B)){</span></p>\r\n<p><span class="code blue code-font">+   Tstar[b]<-anova(lm(len~shuffle(Treat),data=ToothGrowth))[1,4]</span></p>\r\n<p><span class="code blue code-font">+   }</span></p>\r\n<p><span class="code blue code-font">> hist(Tstar,xlim=c(0,Tobs+3))</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=3)</span></p>\r\n<p><span class="code blue code-font">> plot(density(Tstar),,xlim=c(0,Tobs+3),main="Density curve of Tstar")</span></p>\r\n<p><span class="code blue code-font">> abline(v=Tobs,col="red",lwd=3)</span></p>\r\n<p><span class="code blue code-font">> pdata(Tobs,Tstar,lower.tail=F)</span></p>\r\n<p><span class="code code-font">[1] 0</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure2.16.jpg" alt="Figure2.16">\r\n<figcaption><em>Figure 2-16: Histogram and density curve of permutation distribution for F-statistic for tooth growth data. Observed test statistic in bold, vertical line at 41.56.</em></figcaption>\r\n</figure> \r\n<br></br>\r\n	<ul><ul><li>&#8226;&#8195;The permutation p-value was reported as 0. This should be reported as p-value<0.0001 since we did 1000 permutations and found that none of the permuted F-statistics, F*, were larger than the observed F-statistic of 41.56. The permuted results do not exceed 6 as seen in Figure 2-16, so the observed result is really unusual relative to the null hypothesis. As suggested previously, the parametric and nonparametric approaches should be similar here and they were. </li></ul></ul>\r\n	\r\n	\r\n	<li><strong>5)&#8195;Make a decision:</strong>\r\n	<ul>\r\n	<li>&#8226;&#8195;Reject H<sub>0</sub> since the p-value is less than 5%.</li>\r\n	</ul>\r\n	</li>\r\n	<li><strong>6)&#8195;Write a conclusion:</strong>\r\n	<ul>\r\n	<li>&#8226;&#8195;There is evidence at the 5% significance level that the different treatments (combinations of OJ/VC and dosage levels) cause some difference in the true mean tooth growth for these Guinea Pigs.\r\n<ul>	\r\n	<li>&#9675;&#8195;We can make the causal statement because the treatments were randomly assigned but these inferences only apply to these Guinea Pigs since they were not randomly selected from a larger population.</li>\r\n	<li>&#9675;&#8195;Remember that we are making inferences to the population means and not the sample means and want to make that clear in any conclusion.</li>\r\n	<li>&#9675;&#8195;The alternative is that there is some difference in the true means - be sure to make the wording clear that you aren''t saying that all differ. In fact, if you look back at Figure 2-14, the means for the 2 mg dosages look almost the same. The F-test is about finding evidence of some difference somewhere among the true means. The next section will provide some additional tools to get more specific about the source of those detected differences.</li>\r\n	</li></li></ul>\r\n	</ul>\r\n	\r\n	\r\n<p>Before we leave this example, we should revisit our model estimates and interpretations. The default model parameterization is into the reference-coding. Running the model <span class="code-font">summary</span> function on <span class="code-font">m2</span> provides the estimated coefficients:</p>\r\n<p><span class="code blue code-font">> summary(m2)</span></p>\r\n<p><span class="code code-font">Coefficients:</span></p>\r\n<table class="code code-font">\r\n<tr><td></td><td>Estimate Std.</td><td>Error</td><td>t value</td><td>Pr(>|t|)</td><td></td></tr>    \r\n<tr><td>(Intercept)</td><td>13.230</td><td>1.148</td><td>11.521</td><td>3.60e-16</td><td>***</td></tr>\r\n<tr><td>TreatVC.0.5</td><td>-5.250</td><td>1.624</td><td>-3.233</td><td>0.00209</td><td>** </td></tr>\r\n<tr><td>TreatOJ.1</td><td>9.470</td><td>1.624</td><td>5.831</td><td>3.18e-07</td><td>***</td></tr>\r\n<tr><td>TreatVC.1</td><td>3.540</td><td>1.624</td><td>2.180</td><td>0.03365</td><td>*  </td></tr>\r\n<tr><td>TreatOJ.2</td><td>12.830</td><td>1.624</td><td>7.900</td><td>1.43e-10</td><td>***</td></tr>\r\n<tr><td>TreatVC.2</td><td>12.910</td><td>1.624</td><td>7.949</td><td>1.19e-10</td><td>***</td></tr>\r\n</table>\r\n<span class="code code-font">Residual standard error: 3.631 on 54 degrees of freedom</span></p>\r\n<span class="code code-font">Multiple R-squared:  0.7937,	Adjusted R-squared:  0.7746</span></p>\r\n<span class="code code-font">F-statistic: 41.56 on 5 and 54 DF,  p-value: < 2.2e-16</span></p>\r\n<p>For some practice with the reference coding used in these models, we will find the estimates for observations for a couple of the groups. To work with the parameters, you need to start with diagnosing the baseline category by considering which level is not displayed in the output. The levels function can list the groups and their coding in the data set. The first <span class="code-font">level</span> is usually the baseline category but you should check this in the model summary as well.</p>\r\n<p><span class="code blue code-font">> levels(ToothGrowth$Treat)</span></p>\r\n<table class="code code-font">\r\n<tr><td>[1]</td><td>"OJ.0.5"</td><td>"VC.0.5"</td><td>"OJ.1"</td><td>"VC.1"</td><td>"OJ.2"</td><td>"VC.2"</td></tr>\r\n</table>\r\n<p>There is a <span class="code-font">VC.0.5</span> in the second row of the model summary, but there is no row for <span class="code-font">0J.0.5</span> and so this must be the baseline category. That means that the fitted value or model estimate for the OJ at 0.5 mg group is the same as the <span class="code-font">(Intercept)</span> row or &#945;&#770;, estimating a mean tooth growth of 13.23 mm when the pigs get OJ at a 0.5 mg dosage level. You should always start with working on the baseline level in a reference-coded model. To get estimates for any other group, then you can use the (Intercept) estimate and add the deviation for the group of interest. For <span class="code-font">VC.0.5</span>, the estimated mean tooth growth is &#945;&#770; + &#964;&#770;<sub>2</sub> = &#945;&#770; + &#964;&#770;<sub>VC.0.5</sub> =13.23+ (-5.25) = 7.98 mm. It is also potentially interesting to directly interpret the estimated difference (or deviation) between <span class="code-font">OJ0.5</span> (the baseline) and <span class="code-font">VC0.5</span> (group 2) that is &#964;&#770;<sub>VC.0.5</sub> = -5.25: we estimate that the mean tooth growth in VC.0.5 is 5.25 mm shorter than it is in OJ.0.5. This and many other direct comparisons of groups are likely of interest to researchers involved in studying the impacts of these supplements on tooth growth and the next section will show us how to do that (correctly!).</p>', '<p><sup><a id="27ft" href="#27top">27</a></sup>Note that to see all the group labels in the plot when I copied it into R, I had to widen the plot window. You can resize the plot window using the small "=" signs in the grey bars that separate the different panels in R-studio.</p>', 'Chapter 2', '2.005', '2.4', 'Textbook', 'Textbook', 'F-test#One-way ANOVA example', NULL, NULL, NULL, NULL, NULL, '2015-09-16 14:30:52', NULL, NULL, NULL, NULL),
(59, 'Multiple (pair-wise) comparisons using Tukey''s HSD and the compact letter display', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>With evidence that the true means are likely not all equal, many researchers want to know which groups show evidence of differing from one another. This provides information on the source of the overall difference that was detected and detailed information on which groups differed from one another. Because this is a shot-gun/ unfocused sort of approach, some people think it is an over-used procedure. Others feel that it is an important method of addressing detailed questions about group comparisons in a valid way. For example, we might want to know if OJ is different from VC at the 0.5 mg dosage level and these methods will allow us to get an answer to this sort of question. It also will test for differences between the OJ-0.5 and VC-2 groups and every other pair you can construct. This method actually takes us back to the methods in Chapter 1 where we compared the means of two groups except that we need to deal with potentially many pair-wise comparisons, making an adjustment to account for that inflation in Type I errors that occurs due to many tests being performed at the same time. There are many different statistical methods to make all the pair-wise comparisons, but we will employ the most commonly used one, called <strong><em>Tukey''s Honest Significant Difference</strong></em> (Tukey''s HSD) method<sup><a id="28top" href="#28ft">28</a></sup> . The name suggests that not using it could lead to a dishonest answer and that it will give you an honest result. It is more that if you don''t do some sort of correction for all the tests you are performing, you might find some <strong><em>spurious</strong></em><sup><a id="29top" href="#29ft">29</a></sup> results. There are other methods that could be used to do a similar correction.</p>\r\n<p>Generally, the general challenge in this situation is that if you perform many tests at the same time, you inflate the Type I error rate. We can define the <strong><em>family-wise error rate</strong></em> as the probability that at least one error is made on a set of tests or P(At least 1 error is made). The family-wise error is meant to capture the overall situation in terms of measuring the likelihood of making a mistake if we consider many tests, each with some chance of making their own mistake, and focus on how often we make at least one error when we do many tests. A quick probability calculation shows the magnitude of the problem. If we start with a 5% significance level test, then P(Type I error on one test) =0.05 and the P(no errors made on one test) =0.95, by definition. This is our standard hypothesis testing situation. Now, suppose we have m independent tests, then P(make at least 1 Type I error given all null hypotheses are true) = 1 - P(no errors made) = 1 - .95<sup>m</sup>. Figure 2-17 shows how the probability of having at least one false detection grows rapidly with the number of tests. The plot stops at 100 tests since it is effectively a 100% chance of at least on false detection. It might seem like doing 100 tests is a lot, but in Genetics research it is possible to consider situations where millions of tests are considered so these are real issues to be concerned about in many situations.</p> \r\n<figure>\r\n<img src="../meta/img/Figure2.17.jpg" alt="Figure2.17">\r\n<figcaption><em>Figure 2-17: Plot of family-wise error rate as the number of tests performed increases. Dashed line indicates 0.05.</em></figcaption>\r\n</figure> \r\n\r\n<p>In pair-wise comparisons between all the pairs of means in a One-Way ANOVA, the number of tests is based on the number of pairs. We can calculate the number of tests using <em>J</em> choose 2, (<sup><em>J</em></sup><sub>2</sub>), to get the number of pairs of size 2 that we can make out of <em>J</em> individual treatment levels. We won''t explore the combinatorics formula for this, as the <span class="code-font">choose</span> function can give us the answers:</p>\r\n<p><span class="code blue code-font">> choose(3,2)</span></p>\r\n<p><span class="code code-font">[1] 3</span></p>\r\n<p><span class="code blue code-font">> choose(4,2)</span></p>\r\n<p><span class="code code-font">[1] 6</span></p>\r\n<p><span class="code blue code-font">> choose(5,2)</span></p>\r\n<p><span class="code code-font">[1] 10</span></p>\r\n<p><span class="code blue code-font">> choose(6,2)</span></p>\r\n<p><span class="code code-font">[1] 15</span></p>\r\n\r\n<p>So if you have 6 groups, like in the Guinea Pig study, we will have to consider 15 tests to compare all the pairs of groups. 15 tests seems like enough that we should be worried about inflated family-wise error rates. Fortunately, the Tukey''s HSD method controls the family-wise error rate at your specified level (say 0.05) across any number of pair-wise comparisons. This means that the overall rate of at least one Type I error is controlled at the specified significance level, often 5%. To do this, each test must use a slightly more conversative cut-off than if just one test is performed and the procedure helps us figure out how much more conservative we need to be.</p>\r\n<p>Tukey''s HSD starts with focusing on the difference between the groups with the largest and smallest means (&#947;&#773;<sub>max</sub> -&#947;&#773;<sub>min</sub>). If (&#947;&#773;<sub>max</sub> - &#947;&#773;<sub>min</sub>) &#8804; Margin of Error for the difference in the means, then all other pairwise differences, say |&#947;&#773;<sub>j</sub> - &#947;&#773;<sub>j''</sub>|, will be less than or equal to that margin of error. This also means that any confidence intervals for any difference in the means will contain 0. Tukey''s HSD selects a critical value so that (&#947;&#773;<sub>max</sub> - &#947;&#773;<sub>min</sub>) will be less than the margin of error in 95% of data sets drawn from populations with a common mean. This implies that in 95% of datasets in which all the population means are the same, all confidence intervals for differences in pairs of means will contain 0. Tukey''s HSD provides confidence intervals for the difference in true means between groups <em>j</em> and <em>j''</em>, &#956;<sub>j</sub> - &#956;<sub>j''</sub>, for all pairs where <em>j</em> &#8800; <em>j''</em>, using</p>\r\n	<figure>\r\n<img src="../meta/img/Equation2.10.jpeg" alt="Equation2.10">\r\n</figure> \r\n<p>where <img src="../meta/img/Equation2.11.jpeg"  alt="Equation2.11" style="vertical-align:middle"> is the margin of error for the intervals. The distribution used to find the multiplier, q, for the confidence intervals is available in the <span class="code-font">qtukey</span> function and generally provides a slightly larger multiplier than the regular t* from our two-sample t-based confidence interval, discussed in Chapter 1. We will use the <span class="code-font">confint</span>, <span class="code-font">cld</span>, and <span class="code-font">plot</span> functions applied to output from the <span class="code-font">glht</span> function (<span class="code-font">multcomp</span> package; Hothorn, Bretz and Westfall, 2008) to easily get the required comparisons from our ANOVA model. Unfortunately, its code format is a little complicated - but there are just two places to modify the code, by including the modele name and after <span class="code-font">mcp</span> (stands for multiple comparisons) in the <span class="code-font">linfct</span> option, you need to include the explanatory variable name as <span class="code-font">VARIABLENAME="Tukey"</span>. The last part is to get the Tukey HSD multiple comparisons. Once we obtain the intervals, we can use them to test H<sub>0</sub>: &#947;<sub>j</sub> = &#947;<sub>j''</sub> vs H<sub>A</sub>: &#947;<sub>j</sub> &#8800; &#947;<sub>j''</sub> by assessing whether 0 is in the confidence for each pair. If 0 is in the interval, then there is no evidence of a difference for that pair. If 0 is not in the interval, then we reject H<sub>0</sub> and have evidence at the specified family-wise significance level of a difference for that pair. The following code provides the numerical and graphical<sup><a id="30top" href="#30ft">30</a></sup>  results of applying Tukey''s HSD to the linear model for the Guinea Pig data:</p>\r\n<p><span class="code blue code-font">> require(multcomp)</span></p>\r\n<p><span class="code blue code-font">> Tm2 <- glht(m2, linfct = mcp(Treat = "Tukey"))</span></p>\r\n<p><span class="code blue code-font">> confint(Tm2)</span></p>\r\n<p><span class="code code-font">&#8195;&#8195;Simultaneous Confidence Intervals</span></p>\r\n<p><span class="code code-font">Multiple Comparisons of Means: Tukey Contrasts</span></p>\r\n<p><span class="code code-font">Fit: lm(formula = len ~ Treat, data = ToothGrowth)</span></p>\r\n<p><span class="code code-font">Quantile = 2.9549</span></p>\r\n<p><span class="code code-font">95% family-wise confidence level</span></p>\r\n<table class="code code-font">\r\n<tr><td>Linear Hypotheses:</td></tr>\r\n<tr><td></td><td>Estimate</td><td>lwr</td><td>upr     \r\n<tr><td>VC.0.5 - OJ.0.5 == 0</td><td>-5.2500</td><td>-10.0487</td><td>-0.4513</td></tr>\r\n<tr><td>OJ.1 - OJ.0.5 == 0</td><td>9.4700</td><td>4.6713</td><td>14.2687</td></tr>\r\n<tr><td>VC.1 - OJ.0.5 == 0</td><td>3.5400</td><td>-1.2587</td><td>8.3387</td></tr>\r\n<tr><td>OJ.2 - OJ.0.5 == 0</td><td>12.8300</td><td>8.0313</td><td>17.6287</td></tr>\r\n<tr><td>VC.2 - OJ.0.5 == 0</td><td>12.9100</td><td>8.1113</td><td>17.7087</td></tr>\r\n<tr><td>OJ.1 - VC.0.5 == 0</td><td>14.7200</td><td>9.9213</td><td>19.5187</td></tr>\r\n<tr><td>VC.1 - VC.0.5 == 0</td><td>8.7900</td><td>3.9913</td><td>13.5887</td></tr>\r\n<tr><td>OJ.2 - VC.0.5 == 0</td><td>18.0800</td><td>13.2813</td><td>22.8787</td></tr>\r\n<tr><td>VC.2 - VC.0.5 == 0</td><td>18.1600</td><td>13.3613</td><td>22.9587</td></tr>\r\n<tr><td>VC.1 - OJ.1 == 0</td><td>-5.9300</td><td>-10.7287</td><td>-1.1313</td></tr>\r\n<tr><td>OJ.2 - OJ.1 == 0</td><td>3.3600</td><td>-1.4387</td><td>8.1587</td></tr>\r\n<tr><td>VC.2 - OJ.1 == 0</td><td>3.4400</td><td>-1.3587</td><td>8.2387</td></tr>\r\n<tr><td>OJ.2 - VC.1 == 0</td><td>9.2900</td><td>4.4913</td><td>14.0887</td></tr>\r\n<tr><td>VC.2 - VC.1 == 0</td><td>9.3700</td><td>4.5713</td><td>14.1687</td></tr>\r\n<tr><td>VC.2 - OJ.2 == 0</td><td>0.0800</td><td>-4.7187</td><td>4.8787</td></tr>\r\n</table>\r\n\r\n<p><span class="code blue code-font">> old.par <- par(mai=c(1.5,2,1,1)) #Makes room on the plot for the group names</span></p>\r\n<p><span class="code blue code-font">> plot(Tm2)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure2.18.jpg" alt="Figure2.18">\r\n<figcaption><em>Figure 2-18: Graphical display of pair-wise comparisons from Tukey''s HSD for the Guinea Pig data. Any confidence intervals that do not contain 0 provide evidence of a difference in the groups.</em></figcaption>\r\n</figure> \r\n<p>Figure 2-18 contains confidence intervals for the difference in the means for all 15 pairs of groups. For example, the first confidence interval in the first row is comparing VC.0.5 and OJ.0.5 (VC.0.5 <strong>minus</strong> OJ.0.5). In the numerical output, you can find that this 95% family-wise confidence interval goes from -10.05 to -0.45 mm (<span class="code-font">lwr</span> and <span class="code-font">upr</span> in the numerical output provide the CI endpoints). This interval does not contain 0 since its upper end point is -0.45 mm and so we can now say that there is evidence that OJ and VC have different true mean growth rates at the 0.5 mg dosage level. We can go further and say that we are 95% confident that the difference in the true mean tooth growth between VC0.5 and OJ0.5 (VC0.5-OJ0.5) is between -10.05 and -0.45 mm. But there are fourteen more similar intervals...</p> \r\n<p>If you put all these pair-wise tests together, you can generate an overall interpretation of Tukey''s HSD results that discusses sets of groups that are not detectably different from one another and those groups distinguished from other sets of groups. To do this, start with listing out the groups that do are not detectably different (CIs contain 0), which, here, only occurs for four of the pairs. The CIs that contain 0 are for the pairs VC.1 and OJ.0.5, OJ.2 and OJ.1, VC.2 and OJ.1, and, finally, VC.2 and OJ.2. So VC.2, OJ.1, and OJ.2 are all not detectably different from each other and VC.1 and OJ.0.5 are also not detectably different. If you look carefully, VC.0.5 is detected as different from every other group. So there are basically three sets of groups that can be grouped together as "similar": VC.2, OJ.1, and OJ.2; VC.1 and OJ.0.5; and VC.0.5. Sometimes groups overlap with some levels not being detectably different from other levels that belong to different groups and the story is not as clear as it is in this case. An example of this sort of overlap is seen in the next section.</p>\r\n<p>There is a method that many researchers use to more efficiently generate and report these sorts of results that is called a <strong><em>compact letter display</strong></em> (CLD). The <span class="code-font">cld</span> function can be applied to the results from <span class="code-font">glht</span> to provide a "simple" summary of the sets of groups that we generated above. In this discussion, we are using a set as a union of different groups that can contain one or more members and the member of these groups are the six different treatment levels.</p>\r\n<p><span class="code blue code-font">> cld(Tm2)</span></p>\r\n<table class="code code-font">\r\n<tr><td>OJ.0.5</td><td>VC.0.5</td><td>OJ.1</td><td>VC.1</td><td>OJ.2</td><td>VC.2</td></tr> \r\n   <tr><td>"b"</td><td>"a"</td><td>"c"</td><td>"b"</td><td>"c"</td><td>"c"</td></tr>\r\n</table>   \r\n<br>\r\n<p>Groups with the same letter are not detectably different (are in the same set) and groups that are detectably different get different letters (different sets). Groups can have more than one letter to reflect "overlap" between the sets of groups and sometimes a set of groups contains only a single treatment level (VC.0.5 is a set of size 1). Note that if the groups have the same letter, this does not mean they are the same, just that there is <strong>no evidence of a difference for that pair</strong>. If we consider the previous output for the CLD, the "a" set contains VC.0.5, the "b" set contains OJ.0.5 and VC.1, and the "c" set contains OJ.1, OJ.2, and VC.2. These are exactly the groups of treatment levels that we obtained by going through all fifteen pairwise results. And these letters can be added to a beanplot to help fully report the results and understand the sorts of differences Tukey''s HSD can detect.</p>\r\n<p><span class="code blue code-font">> beanplot(len~Treat,data=ToothGrowth,log="",col="white",method="jitter")</span></p>\r\n<p><span class="code blue code-font">> text(c(2),c(10),"a",col="blue",cex=2)</span></p>\r\n<p><span class="code blue code-font">> text(c(3,5,6),c(25,28,28),"b",col="green",cex=2)</span></p>\r\n<p><span class="code blue code-font">> text(c(1,4),c(15,18),"c",col="red",cex=2)</span></p>\r\n\r\n<p>Figure 2-19 can be used to enhance the discussion by showing that the "<strong><span class="blue">a</span></strong>" group with VC.0.5 had the lowest average tooth growth, the "<strong><span class="red">c</span></strong>" group had intermediate tooth growth for treatments OJ.0.5 and VC.1, and the highest growth rates came from OJ.1, OJ.2, and VC.2. Even though VC.2 had the highest average growth rate, we are not able to prove that its true mean is any higher than the other groups labeled with "<strong><span class="green">b</span></strong>". Hopefully the ease of getting to the story of the Tukey''s HSD results from a plot like this explains why it is common to report results using these methods instead of reporting 15 confidence intervals.</p>\r\n<figure>\r\n<img src="../meta/img/Figure2.19.jpg" alt="Figure2.19">\r\n<figcaption><em>Figure 2-19: Beanplot of tooth growth by group with Tukey''s HSD compact letter display.</em></figcaption>\r\n</figure>  \r\n<p>There are just a couple of other details to mention on this set of methods. First, note that we interpret the set of confidence intervals simultaneously: We are 95% confident that <strong>ALL</strong> the intervals contain the respective differences in the true means (this is a <strong><em>family-wise interpretation</strong></em>). These intervals are adjusted (wider) from our regular 2 sample t intervals from Chapter 1 to allow this stronger interpretation. Second, if sample sizes are unequal in the groups, Tukey''s HSD is conservative and provides a family-wise error rate that is lower than the nominal level. In other words, it fails less often than expected and the intervals provided are a little wider than needed, containing all the pairwise differences at higher than the nominal confidence level of (typically) 95%. Third, this is a parametric approach and violations of normality and constant variance will push the method in the other direction, potentially making the technique dangerously liberal. Nonparametric approaches to this problem are possible, but will not be considered here.</p> \r\n', '<p><sup><a id="28ft" href="#28top">28</a></sup>When this procedure is used with unequal group sizes it is also sometimes called Tukey-Kramer''s method.</p>\r\n  <p><sup><a id="29ft" href="#29top">29</a></sup>We often use "spurious" to describe falsely rejected null hypotheses which are also called false detections.</p>\r\n<p><sup><a id="30ft" href="#30top">30</a></sup>The plot of results usually contains all the labels of groups but if the labels are long or there many groups, sometimes the row labels are hard to see even with re-sizing the plot to make it taller in R-studio and the numerical output is useful as a guide to help you read the plot.</p>', 'Chapter 2', '2.006', '2.5', 'Academic Journal', 'Academic Journal', 'Tukey''s range test', NULL, NULL, NULL, NULL, NULL, '2015-09-02 17:07:23', NULL, NULL, NULL, NULL),
(60, 'Pair-wise comparisons for Mock Jury data', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In our previous work with the Mock Jury data, the overall ANOVA test provided only marginal evidence of some difference in the true means across the three groups with a p-value=0.067. Tukey''s HSD does not require you to find a small p-value from your overall <em>F</em>-test to employ the methods but if you apply it to situations with p-values larger than your <em>a priori</em> significance level, you are unlikely to find any pairs that are detected as being different. Some statisticians suggest that you shouldn''t employ follow-up tests such as Tukey''s HSD when there is not sufficient evidence to reject the overall null hypothesis. For the sake of completeness, we can find the pair-wise comparison results at our typical 95% family-wise confidence level in this situation, with the three confidence intervals displayed in Figure 2-20.</p>\r\n<p><span class="code blue code-font">> require(heplots)</span></p>\r\n<p><span class="code blue code-font">> require(mosaic)</span></p>\r\n<p><span class="code blue code-font">> data(MockJury)</span></p>\r\n<p><span class="code blue code-font">> lm2=lm(Years~Attr,data=MockJury)</span></p>\r\n<p><span class="code blue code-font">> require(multcomp)</span></p>\r\n<p><span class="code blue code-font">> Tm2 <- glht(lm2, linfct = mcp(Attr = "Tukey"))</span></p>\r\n<p><span class="code blue code-font">> confint(Tm2)</span></p>\r\n<p><span class="code code-font">&#8195;&#8195;Simultaneous Confidence Intervals</span></p>\r\n<p><span class="code code-font">Multiple Comparisons of Means: Tukey Contrasts</span></p>\r\n<p><span class="code code-font">Fit: lm(formula = Years ~ Attr, data = MockJury)</span></p>\r\n<p><span class="code code-font">Quantile = 2.3749</span></p>\r\n<p><span class="code code-font">95% family-wise confidence level</span></p>\r\n<table class="code code-font">\r\n<tr><td>Linear Hypotheses:</td></tr>\r\n<tr><td></td><td>Estimate</td><td>lwr</td><td>upr</td></tr>    \r\n<tr><td>Average - Beautiful == 0</td><td>-0.3596</td><td>-2.2968</td><td>1.5775</td></tr>\r\n<tr><td>Unattractive - Beautiful == 0</td><td>1.4775</td><td>-0.4729</td><td>3.4278</td></tr>\r\n<tr><td>Unattractive - Average == 0</td><td>1.8371</td><td>-0.1257</td><td>3.7999</td></tr>\r\n</table>\r\n<p><span class="code blue code-font">> old.par <- par(mai=c(1.5,2.5,1,1)) #Makes room on the plot for the group names</span></p>\r\n<p><span class="code blue code-font">> plot(Tm2)</span></p>\r\n<p><span class="code blue code-font">> cld(Tm2)</span></p>\r\n<table class="code code-font">\r\n<tr><td>Beautiful</td><td>Average</td><td>Unattractive</td></tr>\r\n<tr><td>"a"</td><td>"a"</td><td>"a"</td></tr>\r\n</table>\r\n<figure>\r\n<img src="../meta/img/Figure2.20.jpg" alt="Figure2.20">\r\n<figcaption><em>Figure 2-20: Tukey''s HSD confidence interval results at the 95% family-wise confidence level.</em></figcaption>\r\n</figure>\r\n<p>At the family-wise 5% significance level, there are no pairs that are detectably different - they all get the same letter of "a". Now we will produce results for the reader that thought a 10% significance was suitable for this application before seeing any of the results. We just need to change the confidence level or significance level that the CIs or tests are produced with inside the functions. For the <span class="code-font">confint</span> function, the <span class="code-font">level</span> option is the confidence level and for the <span class="code-font">cld</span>, it is the family-wise significance level.</p>\r\n<p><span class="code blue code-font">> confint(Tm2,level=0.9)</span></p>\r\n<p><span class="code code-font">&#8195;&#8195;Simultaneous Confidence Intervals</span></p>\r\n<p><span class="code code-font">Multiple Comparisons of Means: Tukey Contrasts</span></p>\r\n<p><span class="code code-font">90% family-wise confidence level</span></p>\r\n<table class="code code-font">\r\n<tr><td></td><td>Estimate</td><td>lwr</td><td>upr</td></tr>   \r\n<tr><td>Average - Beautiful == 0</td><td>-0.3596</td><td>-2.0511</td><td>1.3318</td></tr>\r\n<tr><td>Unattractive - Beautiful == 0</td><td>1.4775</td><td>-0.2255</td><td>3.1804</td></tr>\r\n<tr><td>Unattractive - Average == 0</td><td>1.8371</td><td>0.1233</td><td>3.5510</td></tr>\r\n</table>\r\n<p><span class="code blue code-font">> old.par <- par(mai=c(1.5,2.5,1,1)) #Makes room on the plot for the group names</span></p>\r\n<p><span class="code blue code-font">> plot(confint(Tm2,level=.9))</span></p>\r\n<p><span class="code blue code-font">> cld(Tm2,level=0.1)</span></p>\r\n<table class="code code-font">\r\n<tr><td>Beautiful</td><td>Average</td><td>Unattractive</td></tr>\r\n<tr><td>"ab"</td><td>"a"</td><td>"b"</td></tr>\r\n</table>\r\n<figure>\r\n<img src="../meta/img/Figure2.21.jpg" alt="Figure2.21">\r\n<figcaption><em>Figure 2-21: Tukey''s HSD 90% family-wise confidence intervals.</em></figcaption>\r\n</figure>\r\n<p>With family-wise 10% significance and 90% confidence levels, the <em>Unattractive</em> and <em>Average</em> picture groups are detected as being different but the <em>Average</em> group is not detected as different from <em>Beautiful</em> and <em>Beautiful</em> is not detected to be different from <em>Unattractive</em>. This leaves the "overlap" of groups across the sets of groups that was noted earlier. The <em>Beautiful</em> level is not detected as being dissimilar from levels in two different sets and so gets two different letters.</p>\r\n<p>The beanplot''s means (Figure 2-22) helps to clarify some of reasons for this set of results. The detection of a difference between <em>Average</em> and <em>Unattractive</em> just barely occurs and the mean for <em>Beautiful</em> is between the other two so it ends up not being detectably different from either one. This sort of overlap is actually a fairly common occurrence in these sorts of situations so be prepared a mixed set of letters for some levels.</p>\r\n<p><span class="code blue code-font">> beanplot(Years~Attr,data=MockJury,log="",col="white",method="jitter")</span></p>\r\n<p><span class="code blue code-font">> text(c(1),c(5),"ab",col="blue",cex=2)</span></p>\r\n<p><span class="code blue code-font">> text(c(2),c(4.8),"a",col="green",cex=2)</span></p>\r\n<p><span class="code blue code-font">> text(c(3),c(6.5),"b",col="red",cex=2)</span></p>\r\n<figure>\r\n<img src="../meta/img/Figure2.22.jpg" alt="Figure2.22">\r\n<figcaption><em>Figure 2-22: Beanplot of sentences with compact letter display results from 10% family-wise significance level Tukey''s HSD.</em></figcaption>\r\n</figure>', NULL, 'Chapter 2', '2.007', '2.6', 'Textbook', 'Textbook', 'F-test', NULL, NULL, NULL, NULL, NULL, '2015-09-16 14:51:51', NULL, NULL, NULL, NULL),
(61, 'Chapter Summary', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>In this chapter, we explored methods for comparing a quantitative response across <em>J</em> groups (<em>J</em> &#8805; 2), what is called the One-Way ANOVA procedure. The initial test is based on assessing evidence against a null hypothesis of no difference in the true means for the <em>J</em> groups. There are two different methods for estimating these One-Way ANOVA models: the cell-means model and the reference-coded versions of the model. There are times when either model will be preferred, but for the rest of the semester, the reference coding will be preferred (sorry!). The ANOVA <em>F</em>-statistic, often presented with underlying information in the ANOVA table, provides a method of assessing evidence against the null hypothesis either using permutations or via the <em>F</em>-distribution. Pair-wise comparisons using Tukey''s HSD provide a method for comparing all the groups and are a nice complement to the overall ANOVA results. A compact letter display was shown that enhanced the interpretation of Tukey''s HSD result. </p>\r\n<p>In the Guinea Pig example, we are left with some lingering questions based on these results. It appears that the effect of <em>dosage</em> changes as a function of the <em>delivery method</em> (OJ, VC) because the size of the differences between OJ and VC change for different dosages. These methods can''t directly assess the question of whether the effect of delivery method is the same or not across the different dosages. The next chapter splits the two variables, <em>Dosage</em> and <em>Delivery method</em> so we can consider their effects both separately and together. This allows more refined hypotheses, such as <em>is the effect of delivery method the same for all dosages</em>, to be tested. This will introduce new models and methods for analyzing data where there are two factors as explanatory variables and a quantitative response variable in what is called the Two-Way ANOVA.</p>\r\n', NULL, 'Chapter 2', '2.008', '2.7', 'Textbook', 'Textbook', 'One-way analysis of variance', NULL, NULL, NULL, NULL, NULL, '2015-08-28 01:00:26', NULL, NULL, NULL, NULL),
(62, '2.8 Summary of Important R code', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>The main components of R code used in this chapter follow with components to modify in red, remembering that any R packages mentioned need to be installed and loaded for this code to have a chance of working:</p>\r\n<li>&#8226;	<span class="code-font"><span class="red">MODELNAME</span>=lm(<span class="red">Y</span>~<span class="red">X</span>,data=<span class="red">DATASETNAME</span>)</span>\r\n<ul>\r\n<li>&#9702;	Provides numerical summaries of all variables in the data set.</li>\r\n\r\n<li>&#9702;	Here it is used to fit the reference-coded One-Way ANOVA model with Y as the response variable and X as the grouping variable, storing the estimated model object in MODELNAME.</li>\r\n</ul>\r\n</li>\r\n<li>&#8226;	<span class="code-font"><span class="red">MODELNAME</span>=lm(<span class="red">Y</span>~<span class="red">X</span>-1,data=<span class="red">DATASETNAME</span>)</span>\r\n<ul>\r\n<li>&#9702;	Fits the cell means version of the One-Way ANOVA model.</li></ul>\r\n</li>\r\n<li>&#8226;	<span class="code-font">summary(<span class="red">MODELNAME)</span>)</span>\r\n<ul>\r\n<li>&#9702;	Generates model summary information including the estimated model coefficients, SEs, t-tests, and p-values.</li></ul>\r\n</li>\r\n<li>&#8226;	<span class="code-font">anova(<span class="red">MODELNAME)</span></span>\r\n<ul>\r\n<li>&#9702;	Generates the ANOVA table but <strong>must only be run on the reference-coded version of the model</strong>.</li>\r\n<li>&#9702;	Results are incorrect if run on the cell-means model since the reduced model under the null is that the mean of all the observations is 0!</li>\r\n</ul>\r\n</li>\r\n<li>&#8226;	<span class="code-font">pf(<span class="red">FSTATISTIC</span>,df1=<span class="red">NUMDF</span>,df2=<span class="red">DENDF</span>,lower.tail=F)</span>\r\n<ul>\r\n<li>&#9702;	Finds the p-value for an observed <em>F</em>-statistic with <span class="code-font">NUMDF</span> and <span class="code-font">DENDF</span> degrees of freedom.</li></ul>\r\n</li>\r\n<li>&#8226;	<span class="code-font">par(mfrow=c(2,2)); plot(<span class="red">MODELNAME</span>)</span>\r\n<ul>\r\n<li>&#9702;	Generates four diagnostic plots including the Residuals vs Fitted and Normal Q-Q plot.</li>\r\n</ul>\r\n</li>\r\n<li>&#8226;	<span class="code-font">plot(allEffects(<span class="red">MODELNAME</span>))</span>\r\n<ul> \r\n<li>&#9702;	Plots the estimated model.</li>\r\n<li>&#9702;	Requires the <span class="code-font">effects</span> package be loaded.</li></ul>\r\n</li>\r\n<li>&#8226;	<span class="code-font">Tm2=glht(<span class="red">MODELNAME</span>,linfct=mcp(<span class="red">X</span>="Tukey"); confint(Tm2); plot(Tm2); cld(Tm2)</span>\r\n<ul>\r\n<li>&#9702;	Requires the <span class="code-font">multcomp</span> package to be installed and loaded.</li>\r\n<li>&#9702;	Can only be run on the reference-coded version of the model.</li>\r\n<li>&#9702;	Generates the text output and plot for Tukey''s HSD as well as the compact letter display.</li></ul></li>', NULL, 'Chapter 2', '2.009', '2.8', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-09-16 15:06:38', NULL, NULL, NULL, NULL);
INSERT INTO `bodymatter` (`id`, `name`, `creator`, `url`, `description`, `about`, `image`, `text`, `mentions`, `isPartOf`, `position`, `articleSection`, `publicationType`, `additionalType`, `additionalType2`, `isbn`, `genre`, `keywords`, `publisher`, `dateCreated`, `dateModified`, `datePublished`, `version`, `learningResourceType`, `inLanguage`) VALUES
(63, '2.9: Practice problems', 'Mark Greenwood and Katharine Banner', NULL, NULL, NULL, NULL, '<p>For these practice problems, you will work with the cholesterol data set from the <span class="code-font">multcomp</span> package that you should already have loaded. To load the data set and learn more about the study, use the following code:</p>\r\n<p><span class="code-font">require(multcomp)</span></p>\r\n<p><span class="code-font">data(cholesterol)</span></p>\r\n<p><span class="code-font">help(cholesterol)</span></p>\r\n<p><dd>2.1. Graphically explore the differences in the changes in Cholesterol levels for the five levels using boxplots and beanplots.</dd></p>\r\n<p><dd>2.2. Is the design balanced? </dd></p>\r\n<p><dd>2.3. Complete all 6+ steps of the hypothesis test using the parametric <em>F</em>-test, reporting the ANOVA table and the distribution of the test statistic under the null. </dd></p>\r\n<p><dd>2.4. Discuss the scope of inference using the information that the treatment levels were randomly assigned to volunteers in the study.</dd></p>\r\n<p><dd>2.5. Generate the permutation distribution and find the p-value. Compare the parametric p-value to the permutation test results.</dd></p>\r\n<p><dd>2.6. Perform Tukey''s HSD on the data set. Discuss the results - which pairs were detected as different and which were not? Bigger reductions in cholesterol are good, so are there any levels you would recommend or that might provide similar reductions?</dd></p>\r\n<p><dd>2.7. Find and interpret the CLD and compare that to your interpretation of results from 2.6.</dd></p>\r\n', NULL, 'Chapter 2', '2.010', '2.9', 'Textbook', 'Textbook', 'R (programming language)', NULL, NULL, NULL, NULL, NULL, '2015-08-28 01:01:44', NULL, NULL, NULL, NULL);

